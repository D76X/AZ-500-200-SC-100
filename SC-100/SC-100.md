# SC-100 Practice Test 139 Questions


---

## Q12X:

---

### Answer:

---

### References

---

## Q128:

Your company has a Microsoft 365 E5 license. To prevent eavesdropping on sensitive information, your company encrypts all data in motion for cloud workloads running in Azure. Additionally, network engineers have deployed DPI rules on Azure Firewall to identify and prevent attacks that attempt to exfiltrate proprietary intellectual property. Despite these controls, your company's sensitive data is still being found for sale on the dark web.
You need to recommend a solution that addresses this finding.
Which two solutions should you include in your recommendation to mitigate the risk of data exfiltration? Each correct answer presents part of the solution.

Choose the correct answers

- Define Data Loss Prevention (DLP) policies in Microsoft Purview.
- Store file encryption keys in an Azure Dedicated Hardware Security Module (HSM).
- Configure Transport Layer Security (TLS) inspection in Azure Firewall Premium.
- Implement Double Key Encryption (DKE) for sensitive data.
- Terminate encrypted sessions at the Application Gateway.

---

### Answer:
- Configure Transport Layer Security (TLS) inspection in Azure Firewall Premium.
- Terminate encrypted sessions at the Application Gateway.

You should recommend configuring Transport Layer Security (TLS) inspection in Azure Firewall Premium. TLS Inspection, also known as Secure Sockets Layer (SSL) inspection or SSL deep inspection, is a security technique that allows organizations to decrypt and inspect TLS traffic to detect threats and malicious activity. Although TLS encryption is designed to protect communications from being intercepted and read by third parties, it also ensures that organizational policies are being followed and potentially dangerous traffic is being blocked. TLS inspection can be used to prevent data leaks, compliance violations, and violations.
malware infections by inspecting encrypted traffic for sensitive data, malicious content, or other policy
You should recommend terminating encrypted sessions at the application gateway. This terminates TLS at the application gateway, which includes built-in web application firewall (WAF) functionality. Once the data has been unencrypted, it can be scanned. Application Gateway also supports end-to-end TLS, which unencrypts traffic, inspects it, and then re-encrypts it before sending it to backend servers.
You should not recommend defining data loss prevention (DLP) policies in Microsoft Purview. DLP can be used to identify sensitive information used in Microsoft 365 apps and it can prevent that information from being shared. You can use Purview to configure DLP for Microsoft 365.
You should not recommend implementing Double Key Encryption (DKE) for sensitive data. This approach would exacerbate the issue, seeing as encrypted data cannot be scanned, thereby making it easier for sensitive data to be exfiltrated. DKE is a method of encrypting data twice, using two different keys, one managed by Microsoft and another managed by you. DKE works by first encrypting the data with one key, and then encrypting the resulting ciphertext with a second key. Decryption is performed in the reverse order, with the second key being used to decrypt the ciphertext, and then the first key being used to decrypt the resulting plaintext.
You should not recommend storing file encryption keys in an Azure Dedicated Hardware Security Module (HSM). Encrypting the keys used for file encryption will not resolve the data exfiltration issue. An HSM is a physical device, typically a computer or an embedded system, that performs cryptographic functions, such as authentication, digital signing, encryption, key storage and management, and protected communications.
HSMs are used in applications where these security operations are critical to the safety or privacy of the
data. You can deploy an HSM in Azure using the Azure Dedicated HSM service.

---

### References

[Azure Firewall Premium features](https://learn.microsoft.com/en-us/azure/firewall/premium-features)   
[Overview of TLS termination and end to end TLS with Application Gateway](https://learn.microsoft.com/en-us/azure/application-gateway/ssl-overview)  
[Learn about data loss prevention](https://learn.microsoft.com/en-us/purview/dlp-learn-about-dlp)    
[What is Double Key Encryption (DKE)?](https://learn.microsoft.com/en-us/purview/double-key-encryption)   
[What is Azure Dedicated HSM?](https://learn.microsoft.com/en-us/azure/dedicated-hsm/overview)  

---

## Q127:

You have been hired to help an organization to secure their Azure landing zone design. The current design includes implementation plans for both compute and storage services.
You have been asked to suggest an overall approach that will enhance the security of the overall system. You recommend adding Azure Key Vault to the landing zone to support public key infrastructure (PKI).
Which two security requirements does your recommendation meet? Each correct answer presents part of the solution.

Choose the correct answers

- Prevent data modifications.
- Enhance data availability.
- Facilitate recovery of lost data.
- Ensure non-repudiation.
- Prevent information disclosure.

---

### Answer:
- Ensure non-repudiation.
- Prevent information disclosure.


Your recommendation will ensure non-repudiation and prevent information disclosure. Both of these are benefits provided by Public Key Infrastructure (PKI). PKI provides a framework for creating, managing, and deploying X.509 certificates that can be used to digitally sign data. A digital signature ensures non- repudiation, meaning that the signer cannot deny, or repudiate, that their signature was used. Certificates are also used on apps and web servers to facilitate encrypted communications, such as with Hypertext Transfer Protocol Secure (HTTPS). Azure Key Vault can be used to create and manage digital certificates.
PKI does not facilitate the recovery of lost data. Azure Backup can be used to provide this benefit.
PKI does not prevent data modifications. However, digital signatures can be used to detect data modifications. If signed data has been modified, the signature will be invalid.
PKI does not enhance data availability. This is typically done using data replication schemes, clustering, and other resiliency approaches. Services like Azure Load Balancer and Azure Application Gateway can be used to enhance data availability.

---

### References

[Key Vault](https://azure.microsoft.com/en-us/products/key-vault/)  
[What is PKI? And how it secures just about everything online](https://www.csoonline.com/article/567339/what-is-pki-and-how-it-secures-just-about-everything-online.html)  
[Azure Backup](https://azure.microsoft.com/en-us/products/backup/)  
[What Is a Digital Signature?](https://www.instantssl.com/digital-signature)  
[Load balancing](https://azure.microsoft.com/en-us/solutions/load-balancing-with-azure/)  


---

## Q126:

You are a security specialist for a company that has a Hybrid server estate. You currently utilize Azure Backup to manage both Azure-hosted and on-premises hosts Windows operating system (OS) virtual machines (VMS).
Your backup configuration for on-premises VMs does incremental backups and is configured for locally redundant storage (LRS) for its replication. A recent penetration test and subsequent security audit has indicated the following:
On-premises virtual machines must be protected and have replication in availability zones to guarantee data residency and resiliency in the same region.
Your manager has asked you to review the existing on-premises backup configuration to determine what needs to be done to meet these requirements.

What should you do to meet these requirements?

Choose the correct answer

- Leave the configuration as locally redundant storage (LRS).
- Configure geo-zone-redundant storage (GZRS) for the recovery vault.
- Configure zone-redundant storage (ZRS) for the recovery vault.
- Configure geo-redundant storage (GRS) for the recovery vault.

---

### Answer:
- Configure zone-redundant storage (ZRS) for the recovery vault.

You should configure zone-redundant storage (ZRS) for the recovery vault in order to meet the requirements. ZRS is an Azure redundancy configuration that replicates your data in availability zones to guarantee data residency and resiliency in the same region. It is also supports Azure Recovery Services vault.
You should not leave the configuration as locally redundant storage (LRS). LRS is an Azure redundancy configuration that allows you to protect your VMs against server rack and drive failures and it replicates your data three times within a single data center in your primary region. LRS provides at minimum 99.999999999% durability of objects over a given year. However, this does not meet the requirements from the security audit.
You should not configure geo-redundant storage (GRS) for the recovery vault. GRS is the default redundancy configuration for Azure Recovery Services vaults and it allows you to protect your data against region-wide outages. You would use GRS to replicate your data to a secondary region, which is not required by the security audit.
You should not configure geo-zone-redundant storage (GZRS) for the recovery vault. GZRS copies your data across three Azure availability zones in the primary region by utilizing ZRS and then copies your data to a single physical location in a secondary region where it uses LRS to copy your data three times within the second zone. This does not meet the requirements from the security audit.
In Azure, region redundancy is designed to offer protection against localized disasters and failures whereas availability zone redundancy gives protection against disasters on a larger geographical scale.

---

### References

[Create and configure a Recovery Services vault](https://learn.microsoft.com/en-us/azure/backup/backup-create-recovery-services-vault)  
[Azure Storage redundancy](https://learn.microsoft.com/en-us/azure/storage/common/storage-redundancy)  

---

## Q125:

Your company has a Microsoft 365 E5 license. It recently signed a contract to provide engineering services for a government entity. Due to the nature of the data that will be generated and processed, strict data handling guidelines must be followed.
You need to implement encryption key storage solutions to comply with these guidelines.
Which key type or types should you implement in each case? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

Data that is subject to eDiscovery
Bring Your Own Key (BYOK)

Keys that must be held within a defined geographical boundary
Double Key Encryption (DKE)

Keys that must be stored in your data center
Double Key Encryption (DKE)

---

### Answer:

You should use bring your own key (BYOK) protection for data that is subject to eDiscovery. By default, Microsoft 365 uses Microsoft-generated encryption keys for use with various services and the data associated with those services. In a BYOK scenario, you generate the key that will be used for these purposes. Once the key or keys have been created, you can specify them in Azure Information Protection.
You should use Double Key Encryption (DKE) for keys that must be held within a defined geographical boundary. DKE uses two different keys to encrypt each piece of data. One key is managed by Microsoft and stored in Azure. The other key is managed by you and can be stored in any location you choose. DKE can be used to protect highly sensitive data and ensure that only members of your organization can fully decrypt it.
You should also use DKE for keys that must be stored in your data center. In a DKE scenario, your organizational key can be stored in a location of your choosing. This key is typically stored in your on- premises data center and protected with a Hardware Security Module (HSM) or similar security solution.

---

### References

[Double Key Encryption](https://learn.microsoft.com/en-us/purview/double-key-encryption?view=o365-worldwide)  
[Bring your own key (BYOK) details for Azure Information Protection](https://learn.microsoft.com/en-us/azure/information-protection/byok-price-restrictions)  
[Planning and implementing your Azure Information Protection tenant key](https://learn.microsoft.com/en-us/azure/information-protection/plan-implement-tenant-key)  

---

## Q124:

Your health services company stores protected health information (PHI) in Azure Storage. The data is primarily accessed and processed in web forms or via API calls. To maintain regulatory compliance, the data must be stored and displayed using methods that maintain maximum privacy. These requirements are dependent on each use case scenario and on the employee accessing the data.
You have already implemented a granular RBAC scheme for managing and controlling data access. You must now address data display requirements.
Based on each use case below, which display method should you recommend implementing? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

To permanently replace the original data
Masking

To replace the original data with data in the same format
Tokenization

To convert the data to fixed-length, irreversible output
Hashing

---

### Answer:

To permanently replace the original data, you should recommend implementing masking. Masking permanently replaces the original data. The new data may be in the same format as the original data, but this is not a requirement. For example, a Social Security number may be masked with symbols as follows:
To replace the original data with data in the same format, you should recommend implementing tokenization. Tokenization is designed to protect data privacy by replacing the original data with data in the same format. Most tokenization methods use random character replacement and store the original-to- tokenized data mapping in an encrypted database or file. If the tokenized data is compromised, it is of little use to an attacker.
To covert the data to fixed-length, irreversible output, you should recommend implementing hashing. Hashes are often used to verify data integrity.
You should not recommend implementing encryption. Encryption uses a reversible algorithm and does not produce fixed-length output. Encryption is designed to make data readable only by those who hold a decryption key.

---

### References

[Encryption, Tokenization, Masking, and Redaction: Choosing the Right Approach](https://www.pkware.com/blog/encryption-tokenization-masking-and-redaction-choosing-the-right-approach)  
[Hashing Algorithms](https://jscrambler.com/blog/hashing-algorithms)  
[Meet PCI compliance with credit card tokenization](https://azure.microsoft.com/es-es/blog/meet-pci-compliance-with-credit-card-tokenization/)  

---

## Q123:

A customer plans to migrate their on-premises Microsoft Exchange installation to Office 365. Due to the number of mailboxes involved, you have recommended a staged migration. The customer has determined that most email communications will require protection.
You need to recommend an email protection option.
Which solution should you recommend for each scenario? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

Emails must be encrypted. Emails are sent primarily to other customers who use Gmail or Outlook.com.
Microsoft Purview Message Encryption

Emails must be encrypted. Once sent, emails cannot be printed, copied, or forwarded.
Information Rights Management (IRM)

Emails must be encrypted using PKI certificates. Messages must be signable.
Secure/Multipurpose Internet Mail Extensions (S/MIME)

---

### Answer:

For emails that must be encrypted and are sent primarily to other customers who use Gmail or Outlook.com, you should recommend Microsoft Purview Message Encryption. Purview Message Encryption is a cloud-based email encryption service offered by Microsoft. It allows businesses to send and receive encrypted emails securely, without the need for special software or hardware. Purview Message encryption is compatible with popular email services, such as Gmail, Outlook, and Yahoo!, and your company's employees can send messages to recipients using any device.
For emails that must be encrypted and cannot be printed, copied, or forwarded once sent, you should recommend Information Rights Management (IRM). Exchange Online IRM is a feature that helps administrators to protect email messages and other content by controlling the way users can access and use them. IRM uses encryption and rights-management technology to help to secure email messages and other content from unauthorized access, both while they are in transit and when they are stored on your organization's servers. IRM limits who can copy, print, or forward email content.
For emails that must signable and are encrypted using Public Key Infrastructure (PKI) certificates, you should recommend Secure/Multipurpose Internet Mail Extensions (S/MIME). S/MIME is a PKI-based cryptographic standard for email security. It allows users to send and receive encrypted and digitally signed messages. S/MIME is best known for its use with email, but it can also be used for other applications such as secure file transfer and messaging.
You should not recommend BitLocker. BitLocker is a Windows feature that can be used to encrypt fixed and portable storage media, like USB drives. BitLocker is not used to encrypt email communications and will not protect data in transit.
You should not recommend Transport Layer Security (TLS). TLS is stipulated for most Microsoft cloud services. TLS is widely used to encrypt data in motion between user browsers and web servers. TLS does not protect data at rest, including emails stored on servers or client devices.


---

### References

[Message Encryption](https://learn.microsoft.com/en-us/purview/ome)  
[Exchange Online mail encryption with AD RMS](https://learn.microsoft.com/en-us/purview/information-rights-management-in-exchange-online)  
[S/MIME for message signing and encryption in Exchange Online](https://learn.microsoft.com/en-us/exchange/security-and-compliance/smime-exo/smime-exo)  
[Best Practices for Deploying BitLocker with Intune](https://petri.com/best-practices-for-deploying-bitlocker-with-intune/)  
[What is TLS (Transport Layer Security)?](https://www.cloudflare.com/learning/ssl/transport-layer-security-tls/)  

---

## Q122:

Your company has a Microsoft 365 E5 subscription and it uses Azure Storage. You need to design a secure storage solution for X.509 certificates, API secrets, and storage account keys. You recommend using Azure Key Vault to meet this requirement.
Which storage method should you recommend for each use case below? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

Store TLS/SSL certificates and associated keys and secrets:
Vaults

Store keys in cryptographic hardware:
Managed HSM pools

Store, sync and rotate Azure Storage account keys:
Vaults

---

### Answer:

Azure Key Vault is a cloud key management service that helps you to safeguard the cryptographic keys and secrets that are used by your apps and services. It provides a centralized storage area for this type of data, therefore making it easier to manage and control its use. You can also use Key Vault to help to meet compliance requirements, such as those concerning data protection and security. Azure Key Vault publishes two container types: vaults and managed hardware security module (HSM) pools.
You should recommend using vaults to store Transport Layer Security / Secure Sockets Layer (TLS/SSL) certificates and associated keys and secrets. The primary use of TLS/SSL certificates is to encrypt information between a user's computer and the website or server that they are connecting to. This helps keep sensitive data such as passwords and credit card information safe from interception by third-parties. Azure Key Vault supports storing certificates in vaults.
You should recommend using managed HSM pools to store keys in cryptographic hardware. An HSM is a physical device, typically a computer or an embedded system that performs cryptographic functions, such as authentication, digital signing, encryption, key storage and management, and protected communications. HSMs are used in applications in which these security operations are critical to data safety or privacy.
You should recommend vaults for storing, synchronizing, and rotating Azure Storage account keys. Every Azure storage account uses an account name and an associated key for authentication. These keys can be stored in the vaults of Azure Key Vault.

---

### References

[Azure Key Vault basic concepts](https://learn.microsoft.com/en-us/azure/key-vault/general/basic-concepts)  
[How does SSL work? | SSL certificates and TLS](https://www.cloudflare.com/learning/ssl/how-does-ssl-work/)  
[About keys](https://learn.microsoft.com/en-us/azure/key-vault/keys/about-keys)  
[Azure Key Vault keys, secrets and certificates overview](https://learn.microsoft.com/en-us/azure/key-vault/general/about-keys-secrets-certificates)  


---

## Q121:

Your company uses an Azure blob to store personal health information (PHI) generated by medical monitoring equipment.
To ensure compliance with government regulations, you need to design a secure storage architecture that meets the following requirements:

- All access to the PHI must be tracked
- For auditing purposes, tracking information must be easily accessible
- Copies of audit logging information must be stored read-only

Which three actions should you include in your design? Each correct answer presents part of the solution.

Choose the correct answers

- Configure the logging blob to use blob soft delete.
- Periodically export log data to an Azure storage account.
- Store logging information using immutable storage.
- Ensure PHI logging information is sent to Azure Monitor.
- Enable blob versioning for the blob that will store logs.

---

### Answer:

- Periodically export log data to an Azure storage account.
- Store logging information using immutable storage.
- Ensure PHI logging information is sent to Azure Monitor.

Personal health information (PHI) logging information should be sent to Azure Monitor. Azure Monitor is a service that helps you to understand how your applications are performing and how they are using resources. It does this by collecting data from various sources, including Azure resources and services, such as Application Insights and Azure Storage, as well as from on-premises systems. Once the data has been collected, Azure Monitor organizes it into a series of dashboards and reports. These dashboards and reports provide insights into the health and performance of your applications, as well as providing information about the resources that they are using.
Log data should be also periodically exported to an Azure storage account. By default, Azure Monitor stores its data in a blob container named $logs. This data is not read only; therefore, to meet the requirements stated in this scenario, you must periodically export the Azure Monitor log data.
Logging information should also be stored using immutable storage. Immutable storage is an Azure Blob Storage feature that allows data to be written once when it is first stored, before making the data read only from that point forward. You can set a retention period on the read-only data, or you can keep it as read
only for an indefinite period.
Blob versioning for the blob that will store logs should not be enabled. Blob versioning can be used to keep previous versions of blob. In this scenario, deleted logging information could be recovered. However, blob versioning would not store the log data read-only.
The logging blob should not be configured to use blob soft delete. This approach is much like blob versioning in that a deleted version of the blob data can be restored. However, soft delete would not store the log data read-only.


---

### References

[Azure Monitor Logs overview](https://learn.microsoft.com/en-us/azure/azure-monitor/logs/data-platform-logs)  
[Log Analytics workspace data export in Azure Monitor](https://learn.microsoft.com/en-us/azure/azure-monitor/logs/logs-data-export?tabs=portal)  
[Store business-critical blob data with immutable storage](https://learn.microsoft.com/en-us/azure/storage/blobs/immutable-storage-overview)  
[Blob versioning](https://learn.microsoft.com/en-us/azure/storage/blobs/versioning-overview)  
[Soft delete for blobs](https://learn.microsoft.com/en-us/azure/storage/blobs/soft-delete-blob-overview)  

---

## Q120:

Your company has a Microsoft 365 E5 subscription. Employees frequently use emails to send and receive sensitive medical records, which has led to several compliance violations. In response to this issue, management has stipulated the following requirements:

- Only intended message recipients should be able to view message content.
- Employees must be able to send secure emails to recipients who use Gmail, 

Yahoo!, Outlook.com, and other popular email services.
You plan to recommend implementing Microsoft Purview Message Encryption.
You need to design a solution that meets the requirements.
What should you recommend for the company to do first?

Choose the correct answer

- Enable the Simple Certificate Enrollment Protocol (SCEP).
- Create and publish sensitivity labels.
- Define mail flow rules in the Exchange admin center.
- Verify that Azure RMS has been activated.

---

### Answer:
- Verify that Azure RMS has been activated.

You should recommend verifying the Azure Rights Management Services (Azure RMS) activation status first. Microsoft Purview Message Encryption is a cloud-based email encryption service offered by Microsoft. It allows businesses to send and receive encrypted emails securely, without the need for any special software or hardware. Purview Message encryption is compatible with popular email services, such as Gmail and Yahoo!, and your company's employees can send messages to recipients using any device.
You should not recommend defining mail flow rules in the Exchange admin center first. Mail flow rules are used to identify messages based on filters you define before taking action on these messages. Once Azure RMS has been activated, this is the next step for implementing Purview Message Encryption.
You should not recommend enabling Simple Certificate Enrollment Protocol (SCEP) first. SCEP is a certificate enrollment protocol that allows secure automated certificate management across a network. It enables devices such as laptops, smartphones, and other client devices to securely enroll in a certificate authority (CA) and receive certificates without user intervention. SCEP is not required for Purview Message
Encryption.
You should not recommend creating and publishing sensitivity labels first. Sensitivity labels are used in Microsoft Purview Information Protection to classify and apply data protection mechanisms.

---

### References

[Set up Message Encryption](https://learn.microsoft.com/en-us/purview/set-up-new-message-encryption-capabilities)  
[Mail flow rules (transport rules) in Exchange Online](https://learn.microsoft.com/en-us/exchange/security-and-compliance/mail-flow-rules/mail-flow-rules)  
[Configure infrastructure to support SCEP with Intune](https://docs.microsoft.com/en-us/mem/intune/protect/certificates-scep-configure)  
[Create and configure sensitivity labels and their policies](https://learn.microsoft.com/en-us/purview/create-sensitivity-labels)  

---

## Q119:

Your company has a Microsoft 365 E5 subscription. Microsoft 365 services and data are used in the following manner:

- End users utilize Office apps to create and edit personally identifiable information (PII)

- End users store some data in OneDrive

Due to compliance regulations, your company is required to manage data encryption keys.

You need to recommend a solution that will enable your company to manage keys used by Microsoft 365 to encrypt data at rest.

What should you recommend for your company to do first?

Choose the correct answer

- Submit a service request to activate Customer Key.
- Import the company's keys into an Azure key vault.
- Generate keys and configure Double Key Encryption (DKE).
- Modify the Purview Service Encryption configuration.

---

### Answer:
- Submit a service request to activate Customer Key.

You should recommend submitting a service request to activate Customer Key first. This task can be completed in the Fast Track portal. Once the request has been approved, you can use Customer Key to create and manage the encryption keys used for your Microsoft 365 services and resources.
You should not recommend modifying the Purview Service Encryption configuration first. Purview is a Microsoft service that helps organizations to manage and protect their data. Once Customer Key has been approved, you can use Purview to manage your company's encryption configuration.
You should not recommend generating keys and configuring Double Key Encryption (DKE) first. DKE is a method of encrypting data twice, using two different keys, one managed by Microsoft and another that you manage. DKE works by first encrypting the data with one key, and then encrypting the resulting ciphertext with a second key. Decryption is performed in the reverse order, with the second key being used to decrypt the ciphertext, and the first key being used subsequently to decrypt the resulting plain text.
You should not recommend importing the company's keys into an Azure key vault first. This can be done after Customer Key has been approved and you have generated keys. Azure Key Vault is a cloud key management service that helps you to safeguard cryptographic keys and secrets used by your apps and services. It provides a centralized storage area for this type of data, making it easier to manage and control its use. You can also use Key Vault to help to meet compliance requirements, such as those related to data protection and security.

---

### References

[Set up Customer Key](https://learn.microsoft.com/en-us/purview/customer-key-set-up)    
[Service Encryption](https://learn.microsoft.com/en-us/purview/microsoft-365-service-encryption)  
[Double Key Encryption](https://learn.microsoft.com/en-us/purview/double-key-encryption)  
[About Azure Key Vault](https://learn.microsoft.com/en-us/azure/key-vault/general/overview)  

---

## Q118:

Your company uses Azure SQL Database to store sensitive personally identifiable information (PII). Following a recent compliance-mandated penetration test, you receive a report that the system is vulnerable to injection attacks.
You need to design a solution to remediate this vulnerability.
Which recommendation should you include in your design to protect this sensitive data?

Choose the correct answer

- Implementing ledger for all data modifications and deletions
- Configuring Azure Active Directory Universal with MFA
- Replacing coded statements with parameterized queries
- Generating a customer-managed key and enabling transparent data encryption (TDE)

---

### Answer:
- Replacing coded statements with parameterized queries

You should recommend replacing coded statements with parameterized queries. Structured Query Language (SQL) injection occurs when malicious SQL statements are inserted into a web application, web form, or website field. A SQL injection attack is designed to exploit application vulnerabilities and extract, modify, or delete database information. In a parameterized query, parameters are placeholder values that are replaced by actual values when the statement is executed. This facilitates input validation and prevents executable SQL code from being injected.
You should not recommend generating a customer-managed key (CMK) and enabling transparent data encryption (TDE). TDE is a data security feature that encrypts sensitive data in SQL Server databases. TDE works by encrypting database content at the page level, prior to writing the pages to disk, which prevents unauthorized access to the data.
You should not recommend configuring Azure Active Directory Universal with multifactor authentication (MFA). When enabled, this option requires MFA for connections to the SQL engine using SQL Server Management Studio.
You should not recommend implementing ledger for all data modifications and deletions. Ledger uses cryptographic algorithms to ensure database integrity. All historical changes are stored in a ledger table and this information can be used for future auditing.

---

### References

[Develop secure applications on Azure](https://learn.microsoft.com/en-us/azure/security/develop/secure-develop)  
[Transparent data encryption (TDE)](https://learn.microsoft.com/en-us/sql/relational-databases/security/encryption/transparent-data-encryption?view=sql-server-ver16)  
[Using Microsoft Entra multifactor authentication](https://learn.microsoft.com/en-us/azure/azure-sql/database/authentication-mfa-ssms-overview?view=azuresql)  
[Ledger overview](https://learn.microsoft.com/en-us/sql/relational-databases/security/ledger/ledger-overview?view=sql-server-ver16)  

---

## Q117:

Your company has an Azure subscription and an Azure storage account container. For each file in the container, you must be able to specify read or write permissions and the IP addresses that are allowed to access the file. Additionally, some files must only be accessible during a specified timeframe.
You need to recommend a method for providing access to the files in the Azure storage account container.

What should you recommend?

Choose the correct answer

- Stored Access Policy (SAP)
- Shared Access Signatures (SAS)
- Cross-Origin Resource Sharing (CORS)
- Customer-Managed Keys (CMK)

---

### Answer:
- Shared Access Signatures (SAS)

You should recommend implementing shared access signatures (SAS). SAS are a way of providing secure access to resources in Azure Storage. By using SAS, you can grant read-only or read/write permissions to others, based on IP addresses or other criteria. Additionally, you can grant access that will only be valid for a specified date and time range. This is useful when you want to give someone temporary access to data without having to share your account credentials.
You should not recommend implementing customer-managed keys (CMK), You can store CMK in Azure
Vault and specify that they can be used to protect data encryption keys.
You should not recommend implementing Cross-Origin Resource Sharing (CORS), CORS facilitates secure, cross-domain resource access.
You should not recommend implementing stored access policy (SAP). SAP provides an additional layer of security for SAS. SAP helps to group SAS for easier management. However, SAP does not provide resource access on its own, as it is a tool for managing SAS.

---

### References

[Create shared access signatures](https://learn.microsoft.com/en-us/training/modules/configure-storage-security/3-create-shared-access-signatures)  
[Customer-managed keys for Azure Storage encryption.](https://learn.microsoft.com/en-us/azure/storage/common/customer-managed-keys-overview)  
[Cross-Origin Resource Sharing (CORS) support for Azure Storage](https://learn.microsoft.com/en-us/rest/api/storageservices/cross-origin-resource-sharing--cors--support-for-the-azure-storage-services)  
[Define a stored access policy](https://learn.microsoft.com/en-us/rest/api/storageservices/define-stored-access-policy)  


---

## Q116:

Your company plans to use Azure Blob Storage to store off-site copies of sensitive financial data. You have been asked to ensure that the company can maintain granular control over encryption operations. You recommend for your company to use customer-provided keys to meet this requirement.
You need to include a key implementation method in your recommendation.

What should you recommend?

Choose the correct answer

- Linking the key to the Azure key vault
- Enabling the key in a managed Hardware Security Module (HSM)
- Including the key in a request header
- Uploading the key to Azure Key Vault

---

### Answer:
- Including the key in a request header

You should recommend including the key in a request header. Azure Blob Storage provides a highly scalable cloud storage solution and it can be used for a variety of purposes such as backup and disaster recovery, archiving, content delivery, and big data analytics. All data stored in Azure Blog Storage is automatically encrypted with server-side encryption (SSE), which is an encryption key managed by Microsoft. If you want to encrypt data with a customer-provided key, you can do so by including the key in a request header when performing blob operations.
You should not recommend uploading the key to Azure Key Vault. This method is used for customer- managed keys (CMK), which are not the same as customer-provided keys. Customer-managed keys are used to protect blob encryption keys.
You should not recommend enabling the key in a managed Hardware Security Module (HSM). Customer- managed keys must be stored in an Azure Key Vault or in an Azure Key Vault Managed HSM.
You should not recommend linking the key to the Azure key vault. Azure Key Vault is used to store the encryption keys that are used by default for storage encryption. These keys are managed by Microsoft.

---

### References

[Azure Storage encryption for data at rest](https://learn.microsoft.com/en-us/azure/storage/common/storage-service-encryption)  
[Provide an encryption key on a request to Blob storage](https://learn.microsoft.com/en-us/azure/storage/blobs/encryption-customer-provided-keys)  
[Customer-managed keys for Azure Storage encryption](https://learn.microsoft.com/en-us/azure/storage/common/customer-managed-keys-overview)  
[About Azure Key Vault](https://learn.microsoft.com/en-us/azure/key-vault/general/overview)  

---

## Q115:

Your company, a health services provider, uses custom-developed, Azure-hosted Application Programming Interfaces (APIs) to analyze data collected from member hospitals. This information is used to improve patient care.
To maintain compliance with regulatory requirements, you need to recommend a solution that meets the following requirements:

- All data must be encrypted while in motion
- All data must be encrypted while at rest
- Encryption keys must be verifiable secure
- Keys must be stored in such a way that they cannot be extracted by an attacker

Which two tasks should you recommend to meet these requirements? Each correct answer presents part of the solution.
Choose the correct answers

- Generate HMAC-based One-Time Passwords (HOTPs) for each transaction using a secret and a counter.

- Implement Open Authorization (OAuth) and enforce JavaScript Object Notation (JSON) Web Token (JWT) based encryption on all communications.

- Generate trusted X.509 certificates for the APIs with Azure Key Vault.

- Ensure that data exchanges between security domains require Azure AD-based Security Assertion Markup Language (SAML).

- Deploy managed Hardware Security Module (HSM) pools for systems that process sensitive information.
---

### Answer:
- Deploy managed Hardware Security Module (HSM) pools for systems that process sensitive information.
- Generate trusted X.509 certificates for the APIs with Azure Key Vault.


You should recommend generating trusted X.509 certificates for the Application Programming Interfaces (APIs) with Azure Key Vault. X.509 is a standard for defining and creating certificates in Public Key Infrastructure (PKI). X.509 certificates are commonly used to encrypt data in motion, using Transport Layer Security (TLS) for example.
You should recommend deploying managed Hardware Security Module (HSM) pools for systems that process sensitive information. An HSM is a physical device, typically a computer or an embedded system, that performs cryptographic functions, such as authentication, digital signing, encryption, key storage and management, and protected communications. HSMs are used in applications where these security operations are critical to the safety or privacy of the data. Azure Key Vault offers a managed HSM service.
You should not recommend implementing OAuth and enforcing JavaScript Object Notation (JSON) Web Token (JWT) based encryption on all communications. JWTs can be used to transmit authentication information, session data, or any other type of information. The contents of a JWT are encoded as a JSON object that is then signed with a digital signature. The recipient of the token can verify the signature to ensure that the contents of the token have not been tampered with. JWTs are not used to protect data at rest.
You should not recommend generating hash-based message authentication code (HMAC) based one-time passwords (HOTPs) for each transaction using a secret and a counter. An HOTP password is generated using a shared secret, such as a username and password, and an HMAC code. The HOTP code is generated by hashing the shared secret using the cryptographic hash function. The resulting hash value is then divided by a predefined modulus to create the one-time password. The advantage of using a HMAC-based one-time password is that it provides strong authentication without requiring the user to remember any additional passwords. HOTPs are not used to provide data encryption.
You should not recommend ensuring that data exchanges between security domains require Azure AD- based Security Assertion Markup Language (SAML). SAML is a security protocol used to exchange authentication and authorization data between two parties. It is an XML-based standard, and it enables secure single sign-on (SSO) for web-based applications. This means that once a user has been authenticated by one application, they can be automatically authenticated by other applications that use the SAML protocol. SAML is not used to provide data encryption.

---

### References

[What is Azure Key Vault Managed HSM?](https://learn.microsoft.com/en-us/azure/key-vault/managed-hsm/overview)  
[ID tokens in the Microsoft identity platform](https://learn.microsoft.com/en-us/entra/identity-platform/id-tokens)  
[What's the Difference Between OTP, TOTP and HOTP?](https://www.onelogin.com/learn/otp-totp-hotp)  
[How the Microsoft identity platform uses the SAML protocol](https://learn.microsoft.com/en-us/entra/identity-platform/saml-protocol-reference)  


---

## Q114:

Your company migrates its on-premises HR management platform to Azure. There are plans to open the application's availability to employees who may be accessing the site from untrusted locations.

You design a solution that facilitates this access but you need to protect it against common web threats. All requests to the HR platform should be managed by Azure Application Gateway with WAF protection.

Based on the common web threats below, which WAF rule sets should you recommend? Your design must minimize administrative overhead. To answer, select the appropriate options from the drop-down menus.

Choose the correct options

To protect against malicious scrapers and scanners
Activate the bot protection rule set

To protect against SQL injection and other injection attacks
Activate a managed rule set

To protect against XSS and HTTP request smuggling
Activate a managed rule set

---

### Answer:

To protect against malicious scrapers and scanners, you should recommend activating the bot protection rule set. Azure Web Application Firewall (WAF) is a cloud-based security service that helps protect your web applications from common attacks such as command injection and cross-site scripting. It also provides protection against more sophisticated attacks such as session hijacking and denial of service (DoS) attacks. The WAF inspects incoming traffic to your web applications and filters out malicious requests based on rule sets. It then forwards the valid requests to your content servers. The WAF rule sets can be configured to block all traffic, allow all traffic, or take action based on rules that you define. Bot protection rules are designed to identify and block scraper and scanner bots that may maliciously try to access your content.
To protect against Structured Query Language (SQL) injection and other injection attacks, you should recommend activating a managed rule set. Managed rules protect against the most common web attacks and vulnerabilities, including SQL injection.
To protect against cross-site scripting (XSS) and Hypertext Transfer Protocol (HTTP) request smuggling, you should recommend activating a managed rule set. Managed rules protect against the most common web attacks and vulnerabilities, including XSS and HTTP request smuggling.
You should not recommend activating a custom rule set. Custom rules can be created to block or allow any activity that you define. However, creating custom rules does not minimize administrative overhead.

---

### References

[Azure Web Application Firewall on Azure Application Gateway bot protection overview](https://learn.microsoft.com/en-us/azure/web-application-firewall/ag/bot-protection-overview)  
[Web Application Firewall CRS rule groups and rules](https://learn.microsoft.com/en-us/azure/web-application-firewall/ag/application-gateway-crs-rulegroups-rules?tabs=drs21)  


---

## Q113:

Your company uses Microsoft 365 and Azure services and resources. It recently implemented a program to enhance each component of the CIA triad. You have been asked to focus on availability for two recently- deployed web applications named finance-web-app and hr-web-app.
To complete this project, you need to design a high-availability architecture for each app, based on the following 

requirements:
finance-web-app:

- The solution must support layer 7 load balancing.
- The solution must support SSL offloading.

hr-web-app:
- The solution must facilitate high availability.
- The solution must perform DNS-based load balancing.

What solution should you recommend for each app? To answer, select the appropriate solution from the drop-down menus.

Choose the correct options

- finance-web-app:
- Azure Application Gateway
- hr-web-app:
- Traffic Manager

---

### Answer:

You should recommend Azure Application Gateway for finance-web-app. Azure Application Gateway is a cloud-based layer 7 load balancing and traffic management service from Microsoft. It is designed to provide high availability and network performance for web applications deployed in Azure. Application Gateway can route traffic to different back-end pools based on rules that define how the traffic should be distributed. For example, if you have multiple web servers hosting different parts of your website, you can use Application Gateway to distribute traffic among them, according to which server can best handle the request. This ensures that your users have a good experience when using your site, as they will always be directed to the server that offers the best response time. Application Gateway supports Secure Sockets Layer (SSL) offloading, which can be used to reduce compute loads on your web app endpoints.
You should recommend Traffic Manager for hr-web-app. Azure Traffic Manager is a powerful, cloud-based traffic management service that uses Domain Name System (DNS) based load balancing to control the distribution of web traffic across your Azure deployments. By routing traffic through Azure Traffic Manager, you can improve the performance, optimize the availability, and improve the resiliency of your applications.
Azure Traffic Manager works by routing requests to the optimal endpoint, based on a configured load balancing method and monitoring experience. It uses different types of monitoring data to determine which endpoint is performing best at any given moment and routes traffic accordingly. This ensures that your users always have the best possible experience when accessing your applications.
Azure Load Balancer is a cloud-based load balancer that enables you to distribute network traffic among multiple virtual machines (VMs). By distributing network traffic, Azure Load Balancer helps you achieve high availability and scalability for your applications. Load Balancer implements layer 4 load balancing, not layer 7 load balancing as required by finance-web-app. Also, Azure Load balancer does not provide DNS based load balancing as required by hr-web-app.

---

### References

[Load-balancing options](https://learn.microsoft.com/en-us/azure/architecture/guide/technology-choices/load-balancing-overview)  
[What is Traffic Manager?](https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-overview)  
[What is Azure Application Gateway?](https://learn.microsoft.com/en-us/azure/application-gateway/overview)  
[What is Azure Load Balancer?](https://learn.microsoft.com/en-us/azure/load-balancer/load-balancer-overview)  

---

## Q112:

Refer to the exhibit.

Your company stores static images and video files in Azure Storage. Content distribution and serving is managed by Azure Front Door. You need to ensure that this design approach implements sound security practices.
What should you configure to meet the requirements indicated below? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

To restrict access to your content by region:
geo-filtering policy

o throttle requests from a client IP address:
rate limit rule

![image info](./Q112.PNG)

---

### Answer:

Azure Web Application Firewall (WAF) is a cloud-based security service that helps to protect your web applications from common attacks, such as Structured Query Language (SQL) injection and cross-site scripting. It also provides protection against more sophisticated attacks, such as session hijacking and denial of service (DoS) attacks. Azure WAF inspects incoming traffic to your web applications and filters out malicious requests. It then forwards the valid requests to your content servers. WAF policies can be configured to block all traffic, allow all traffic, or take action based on rules that you define.
To restrict access to your content by region, you should configure a geo-filtering policy. Geo-filtering policies can be used to block or allow access based on country or region.
To throttle requests from a client Internet Protocol (IP) address, you should configure a rate limit rule. Rate limiting rules are designed to throttle requests that may cause a service to become unresponsive. Requests are still allowed, but the number of requests over a specific unit of time is limited.
You should not configure a bot protection rule set. Bot protection rules are designed to identify and block bots that may maliciously try to access your content.
You should not configure an IP restriction rule. IP restriction rules are used to block or allow connections based on IP addresses or ranges.

---

### References

[Set up a geo-filtering WAF policy for your Front Door](https://learn.microsoft.com/en-us/azure/web-application-firewall/afds/waf-front-door-tutorial-geo-filtering)  
[Configure a Web Application Firewall rate limit rule using Azure PowerShell](https://learn.microsoft.com/en-us/azure/web-application-firewall/afds/waf-front-door-custom-rules-powershell)  
[Configure bot protection for Web Application Firewall](https://learn.microsoft.com/en-us/azure/web-application-firewall/afds/waf-front-door-policy-configure-bot-protection?pivots=portal)  
[Configure an IP restriction rule with a Web Application Firewall for Azure Front Door](https://learn.microsoft.com/en-us/azure/web-application-firewall/afds/waf-front-door-configure-ip-restriction?tabs=browser)  


---

## Q111:

Your company has a Microsoft 365 E5 subscription. Due to increased remote work, the company plans to implement a bring your own device (BYOD) policy. You are designing a solution that can enhance security on remote devices. Your planning includes the following considerations:

- Devices will run iOS or Android
- Some devices may be managed by third-party mobile device management (MDM) solutions

You need to recommend a solution that limits unintentional or intentional data loss.
Which two statements should you include in your recommendation? Each correct answer presents a complete solution.
Choose the correct answers

- App protection policies are compatible with third-party mobile device management (MDM) solutions.
- App protection policies can prompt for a PIN when opening an app on a device.
- App protection policies allow app deployment to third-party mobile device management (MDM) devices.
- App protection policies can prevent all data sharing between apps on a device.
- App protection policies can encrypt all locally stored device data.

---

### Answer:
- App protection policies can prompt for a PIN when opening an app on a device.
- App protection policies can prevent all data sharing between apps on a device.


App protection policies, which are part of Microsoft Intune Mobile Application Management (MAM), can prevent all data sharing between apps. App protection policies are designed to protect apps and the data associated with those apps. This allows your organization's data, such as emails or files, to be protected when accessed inside the app. App protection policies can limit data sharing or prevent sharing altogether. Additionally, app-specific data can be encrypted, which means that if the device is lost or stolen, your organization's data remains safe.
App protection policies can prompt for a PIN when opening an app. App protection policies can be applied to an app such that a PIN must be entered when the app is accessed. This is in addition to any device-level authentication that may be required. This ensures that, if a device is lost or stolen, the app data remains protected even if the device is left unlocked.
App protection policies cannot encrypt all locally stored device data. App protection policies are used to control how managed apps on a device function. Devices that your organization owns can be enrolled in Microsoft Intune, which can also be used to manage tablets, laptops, and other compute devices. However, Intune is not required, and devices enrolled in other mobile device management (MDM) platforms can also be controlled using App protection policies. App protection policies focus on apps and, although they cannot encrypt all locally stored device data, they can encrypt app-specific data.
App protection policies are not compatible with third-party MDM solutions. Microsoft recommends that App protection policies should not be used if third-party container or app management agents are also deployed on devices.
App protection policies do not allow app deployment to MDM devices. Deploying apps to devices requires that they be enrolled in an MDM. Microsoft Intune can be used for MAM and MDM.

---

### References

[App protection policies overview](https://learn.microsoft.com/en-us/mem/intune/apps/app-protection-policy)  
[How to create and assign app protection policies](https://learn.microsoft.com/en-us/mem/intune/apps/app-protection-policies)  
[Plan for mobile application management in Microsoft Intune](https://learn.microsoft.com/en-us/mem/intune/apps/app-management)  
[Microsoft Intune protected apps](https://learn.microsoft.com/en-us/mem/intune/apps/apps-supported-intune-apps)  


---

## Q110:

Your company uses Azure to host a real-time stock price app. Based on the results of a third-party penetration test, you learn that the app is vulnerable to command injection and remote file inclusion attacks.
You need to mitigate these risks while ensuring that the following requirements are met:

- Changes to application code must not be required
- Common IIS misconfigurations must be identified
- HTTP protocol anomalies must be detected

What should you do?

Choose the correct answer

- Deploy Azure Web - Application Firewall (WAF) and configure Core Rule Set (CRS) 3.1.
- Deploy Azure Web - Application Firewall (WAF) and configure a bot protection rule set.
- Deploy Azure Web - Application Firewall (WAF) with the default managed rule set.
- Deploy Azure Web - Application Firewall (WAF) and enable the CRS 2.2.9 Open Web - Application Security Project (OWASP) rule set.


---

### Answer:
- Deploy Azure Web - Application Firewall (WAF) with the default managed rule set.

You should deploy Azure Web - Application Firewall (WAF) with the default managed rule set. WAF is a cloud-based security service that helps to protect your web applications from common attacks, such as Structured Query Language (SQL) injection and cross-site scripting. It also provides protection against more sophisticated attacks, such as command injection and remote file inclusion. WAF inspects incoming traffic to your web applications and filters out malicious requests. It then forwards the valid requests to your content servers. WAF policies can be configured to block all traffic, allow all traffic, or take action based on rules that you define. By default, WAF runs CRS 3.2.
You should not deploy Azure WAF and enable the CRS 2.2.9 Open Web - Application Security Project (OWASP) rule set. To protect against command injection and remote file inclusion, you must activate CRS 3.2 or later.
You should not deploy Azure WAF and configure a bot protection rule set. Bot protection rules are designed to identify and block bots that may maliciously try to access your content.
You should not deploy Azure WAF and configure CRS 3.1. Managed rules are based on the OWASP CRS, and CRS 3.1 has been superseded by CRS 3.2. To protect against command injection and remote file inclusion, you must activate CRS 3.2 or later.

---

### References

[Web - Application Firewall DRS and CRS rule groups and rules](https://learn.microsoft.com/en-us/azure/web-application-firewall/ag/application-gateway-crs-rulegroups-rules?tabs=drs21)  
[What is Azure Web - Application Firewall?](https://learn.microsoft.com/en-us/azure/web-application-firewall/overview)  
[Configure bot protection for Web - Application Firewall](https://learn.microsoft.com/en-us/azure/web-application-firewall/afds/waf-front-door-policy-configure-bot-protection?pivots=portal)  
[Web - Application Firewall DRS rule groups and rules](https://learn.microsoft.com/en-us/azure/web-application-firewall/afds/waf-front-door-drs?tabs=drs21)  

---

## Q109:

Your company stores patient health records in Azure Storage. The data is accessed and processed with custom mobile apps hosted on Azure - App Service. To maintain data privacy and regulatory compliance, your cyber insurance provider requires that you provide proof of vulnerability mitigation.
You need to identify the attack vectors that a malicious actor may use to exploit your apps.

Which process or tool should you use to meet this requirement?

Choose the correct answer

- Threat modeling
- Regression testing
- Malware analysis
- Forensic analysis

---

### Answer:
- Threat modeling

You should use threat modeling. Threat modeling first involves identifying the man-made or naturally occurring threats that an organization is vulnerable to. Once these threats have been identified, different scoring methods are employed to quantify how likely a threat is to be exploited, the impact that a breach will cause if the threat is exploited, and the safeguards or security controls that can be used to mitigate the threat. The Microsoft Security Development Lifecycle uses STRIDE to model threats. The STRIDE threat modeling categories are, Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, and Elevation of Privilege.
You should not use malware analysis. Malware analysis is the process of identifying and evaluating the behavior of a piece of malware and it often involves the use of specialized tools. For example, you may run a suspicious email attachment in a sandboxed environment to determine the changes that the malware makes to the operating system.
You should not use forensic analysis. Computer forensic analysis is typically performed to determine the extent of a breach and the methods used during said breach, or to gather evidence to aid in the prosecution of a cybercrime.
You should not use regression testing. Regression testing is used to ensure that an application continues to function as expected after a code change has occurred. Security regression testing focuses on ensuring that new vulnerabilities have not been inadvertently introduced during the development process.

---

### References

[Threat Modeling](https://www.microsoft.com/en-us/securityengineering/sdl/threatmodeling#:~:text=There%20are%20five%20major%20threat%20modeling%20steps%3A%20Defining,refine%20your%20threat%20model%20and%20further%20reduce%20risk.)  
[Malware Analysis](https://www.crowdstrike.com/cybersecurity-101/malware/malware-analysis/)  
[What is Computer Forensics?](https://www.devry.edu/blog/what-is-computer-forensics.html)  
[Automated Regression Testing: Everything You Need To Know](https://www.testim.io/blog/automated-regression-testing/)  


---

## Q108:

Your company uses Azure API Management to manage its multi-cloud, subscription-based API platform. Clients can issue API calls to perform Al-based image recognition, and each client has a unique API key for performing such calls. Based on reporting information in Microsoft Sentinel, you suspect improper key handling.

What should you recommend your company to do to address this concern?

Choose the correct answer

- Ensure that keys are protected using cryptographic obfuscation.
- Ensure that the API endpoints require storage encryption.
- Ensure that API keys are not stored in the API configuration.
- Ensure that keys are hashed prior to connecting to the AΡΙ.

---

### Answer:
- Ensure that API keys are not stored in the API configuration.

You should recommend ensuring that - Application Programming Interface (API) keys are not stored in the API configuration. Every request to Azure API Management APIs must include a valid subscription key. However, API keys are like passwords and therefore they must be kept secure. API keys should be stored in environment variables, not in application code or configuration files.
You should not recommend ensuring that keys are hashed prior to connecting to the API. Hashing API keys will make the keys unrecoverable, but it does not solve the issue created when clients use their keys to authenticate with the API.
You should not recommend ensuring that the API endpoints require storage encryption. Storage encryption will secure API keys at rest, but not while in use.
You should not recommend ensuring that keys are protected using cryptographic obfuscation. Cryptographic obfuscation is a technique which is used to make data or code difficult to read or understand. It can be used to protect information from unauthorized access, or to make it more difficult for someone to copy or steal the data.


---

### References

[Create subscriptions in Azure API Management](https://learn.microsoft.com/en-us/training/modules/control-authentication-with-apim/2-create-subscriptions-in-apim)  
[API security best practices](https://developers.google.com/maps/api-security-best-practices)  
[Azure Data Encryption at rest](https://learn.microsoft.com/en-us/azure/security/fundamentals/encryption-atrest)  
[Differences between encryption, hashing, encoding and obfuscation](https://telefonicatech.com/en/blog/differences-between-encryption-hashing-encoding-and-obfuscation)  

---

## Q107:

Your company has Azure and Microsoft 365 subscriptions. As part of service migration, users with Azure VMs will connect to APIs running on AKS containers. The APIs will be configured to authenticate all connection attempts using OAuth 2.0.
You need to create a management report that describes the impact of OAuth 2.0 grants as it relates to API security.
What should you include in your report?

Choose the correct answer

- APIs can read sensitive data and user information.
- APIs can grant data permissions to other - APIs.
- APIs can block malicious or malformed requests.
- APIs can bypass the authentication process.

---

### Answer:
- APIs can read sensitive data and user information.

- Application Programming Interfaces (APIs) can read sensitive data and user information using OAuth 2.0 grants. The OAuth standard is a form of federated authentication. OAuth grants are most easily recognizable as mobile app permissions but they can impact web applications and APIs as well. OAuth grants enable APIs to request access to user data from other APIs or apps. For example, if an API wanted to allow users to log in using their Facebook account, the API would need to use an OAuth grant to request access to the user's Facebook data.
APIs cannot grant data permissions to other APIs using OAuth 2.0 grants. Delegated user identity is supported by the OAuth standard, but it still requires for a token to be created on behalf of the calling API.
APIs cannot block malicious or malformed requests. Services such as Azure Firewall or Azure Web - Application Firewall (WAF) can provide this protection.
APIs cannot bypass the authentication process using OAuth 2.0 grants. OAuth facilitates standards-based authentication and it is designed to make cross-platform or multi-cloud authentication easier. OAuth does not allow any user, service, or API to bypass authentication.

---

### References

[Microsoft identity platform and OAuth 2.0 authorization code flow](https://learn.microsoft.com/en-us/entra/identity-platform/v2-oauth2-auth-code-flow)  
[Microsoft identity platform and OAuth 2.0 On-Behalf-Of flow](https://learn.microsoft.com/en-us/entra/identity-platform/v2-oauth2-on-behalf-of-flow)  
[What is Azure Web - Application Firewall?](https://learn.microsoft.com/en-us/azure/web-application-firewall/overview)  S
[Set up OAuth authentication for MS Office 365](https://academy.creatio.com/docs/user/setup_and_administration/base_integrations/microsoft_email_contacts_and_calendar/set_up_oauth_authentication/set_up_oauth_authentication_for_ms_office_365)  

---

## Q106:

Your company processes classified information using specialized applications that run on hardened on- premises systems. Management would like to add compute capacity in the cloud but they are concerned about maintaining maximum security.
You need to recommend a compute solution that encrypts data in use.
Which technology should you recommend to facilitate confidential computing?

Choose the correct answer

- Software Guard Extensions (SGX) enclaves
- Azure Key Vault
- A Trusted Platform Module (TPM)
- A Dedicated Hardware Security Module (HSM)

---

### Answer:
- Software Guard Extensions (SGX) enclaves

You should recommend Software Guard Extensions (SGX) enclaves. An SGX enclave is a secure, hardware- isolated environment that runs on a specialized Central Processing Unit (CPU). SGX enclaves can be used to store and run sensitive code and data. Anything inside an enclave is protected from being accessed by any other part of the system, making it an ideal place to keep secrets safe. SGX can be used by developers to build security into their applications, so that even if the OS or platform is compromised, their data and code remain protected inside an enclave. SGX is an Intel technology and it was introduced in Intel processors in 2015. Azure confidential computing supports SGX enclaves on secure VMs that run on SGX-compatible hardware.
You should not recommend a Trusted Platform Module (TPM). A TPM is a cryptographic component that is typically installed as a discrete chip or is integrated with other chipsets to protect encryption keys.
You should not recommend a dedicated Hardware Security Module (HSM). An HSM is a physical device, typically a computer or an embedded system that performs cryptographic functions, such as authentication, digital signing, encryption, key storage and management, and protected communications. HSMs are used in applications in which these security operations are critical to the safety or privacy of the data. You can deploy an HSM in Azure using the Azure Dedicated HSM service.
You should not recommend Azure Key Vault. Azure Key Vault is a cloud key management service that helps you safeguard cryptographic keys and secrets used by your apps and services. It provides a centralized storage area for this type of data, making it easier to manage and control its use. You can also use Key Vault to help to meet compliance requirements, such as those related to data protection and security.


---

### References

[SGX enclaves](https://learn.microsoft.com/en-us/azure/confidential-computing/confidential-computing-enclaves)   
[Trusted Platform Module (TPM) Summary](https://trustedcomputinggroup.org/resource/trusted-platform-module-tpm-summary/)  
[What is Azure Dedicated HSM?](https://learn.microsoft.com/en-us/azure/dedicated-hsm/overview)  
[Azure Key Vault basic concepts](https://learn.microsoft.com/en-us/azure/key-vault/general/basic-concepts)  

---

## Q105:

Your company uses Azure Virtual Desktop (AVD) solution to support a virtual desktop infrastructure (VDI) infrastructure. All AVD VMs run Windows 11.
You need to design a solution that mitigates application-associated risks on the platform. Your solution must utilize threat intelligence so that only applications with known good reputation are allowed to run.
Which recommendation should you include in your design?

Choose the correct answer

- Deploy Microsoft Defender - Application Guard.
- Create an - AppLocker policy.
- Configure the Windows Defender - Application Control (WDAC) policy.
- Enable software restriction policies (SRP).

---

### Answer:
- Configure the Windows Defender - Application Control (WDAC) policy.

You should recommend configuring the Windows Defender - Application Control (WDAC) policy. Specifically, you should add the Enabled:Intelligent Security Graph Authorization option to the policy. WDAC uses policies to protect systems by controlling the applications, drivers, and scripts that are allowed to run on a system. Each policy is comprised of rules that allow or deny behaviors based on conditions that you specify. WDAC can be configured to use Microsoft's Intelligent Security Graph (ISG) to identify applications with known bad, known good, or unknown reputations.
You should not recommend deploying Microsoft Defender - Application Guard. - Application Guard allows you to define domains and network ranges that host trusted applications, files, and web sites. Any resource that is not trusted is opened in a Hyper-V container, or sandbox. - Application Guard is not supported for virtual desktop infrastructure (VDI) deployments.
You should not recommend creating an - AppLocker policy. - AppLocker policies can be used to limit the types of applications and files that employees are allowed to run. However, - AppLocker does not use threat intelligence to control application usage.
You should not recommend enabling software restriction policies (SRP). SRPs can be used to allow or deny applications based on attributes such as file location or hash. However, SRPs do not use threat intelligence to control application usage.


---

### References

[Authorize reputable apps with the Intelligent Security Graph (ISG)](https://learn.microsoft.com/en-us/windows/security/application-security/application-control/windows-defender-application-control/design/use-wdac-with-intelligent-security-graph)  
[Prepare to install Microsoft Defender - Application Guard](https://learn.microsoft.com/en-us/windows/security/application-security/application-isolation/microsoft-defender-application-guard/install-md-app-guard)  
[Create Your - AppLocker policies](https://learn.microsoft.com/en-us/windows/security/application-security/application-control/windows-defender-application-control/applocker/create-your-applocker-policies)  
[Software Restriction Policies Technical Overview](https://learn.microsoft.com/en-us/windows-server/identity/software-restriction-policies/software-restriction-policies-technical-overview)  

---

## Q104:

You are an IT administrator for a company that is currently designing a greenfield Microsoft 365 tenant and an Azure landing zone. As part of the Azure landing zone you want to implement Azure Virtual Desktop to facilitate users being able to work remotely.
You are in the process of documenting which tasks need to be completed in order to implement Zero Trust in the Microsoft 365 tenant.
You need to be able to define the encryption level and antivirus version that devices must meet before being allowed access to resources.

Which policy type should you configure?

Choose the correct answer

- Enrollment policy
- Device configuration profile policy
- Compliance policy
- Conditional Access policy

---

### Answer:
- Compliance policy

You should configure a compliance policy that allows you to define rules and settings that users and devices need to meet before being allowed access to resources. A compliance policy is configured within Intune and you can include actions that apply not only to devices but to user accounts as well. If the device or user does not meet these requirements or actions then it is marked as non-compliant and you have the ability to block access until the issues are resolved and it is marked as compliant. For example, you can configure the compliance policy so a device must have a specific encryption level and anti-virus version before it can be deemed compliant.
You should not configure an enrollment policy that installs a mobile device management (MDM) certificate onto the device that is enrolling. This then communicates with the Intune service and initiates policies downloading onto the device.
You should not configure a Conditional Access policy. This type of policy allows you to enforce company polices like compliance policies, profile polices and multi-factor authentication (MFA) to devices and users.
You should not configure a device configuration policy. This policy type allows you to protect devices as well as manage profiles that define settings and features that meet company policy.


---

### References

[Design configurations and operational practices for Microsoft 365](https://learn.microsoft.com/en-us/training/modules/design-solutions-secure-microsoft-365/4-design-configurations-operational-practices-microsoft-365?ns-enrollment-type=learningpath&ns-enrollment-id=learn.wwl.sc-100-design-security-solutions-applications-data)  
[Device compliance policies for your Microsoft 365 for enterprise test environment](https://learn.microsoft.com/en-us/microsoft-365/enterprise/?view=o365-worldwide)  
[Enrollment guide: Microsoft Intune enrollment](https://learn.microsoft.com/en-us/mem/intune/fundamentals/deployment-guide-enrollment)  
[Building a Conditional Access policy](https://learn.microsoft.com/en-us/entra/identity/conditional-access/concept-conditional-access-policies)  
[Create a device profile in Microsoft Intune](https://learn.microsoft.com/en-us/mem/intune/configuration/device-profile-create)  

---

## Q103:

You are a cloud architect for a company that will soon be migrating all of its on-premises estate to Azure and Microsoft 365, where you will use native services and features only. You are responsible for designing the new identity access management (IAM) solution. As part of this solution you need to deploy Zero Trust within the Microsoft 365 tenant.
Which five actions should you perform in sequence? To answer, move the appropriate actions from the list of possible actions to the answer area and arrange them in the correct order.

Create a list in the correct order

Possible actions

Implement role-based access control (RBAC).
Configure Privileged Identity Management.
Manage endpoints with Microsoft Configuration Manager.
Configure Azure Policy.

Actions in order

Configure identity and device access protection.
Enroll the devices in Intune.
Add Zero Trust identity and device access protection.
Evaluate, pilot, and deploy Microsoft 365 Defender.
Implement Microsoft Purview Information Protection.

---

### Answer:

To start the process of deploying Zero Trust in Microsoft 365 you first need to configure Zero Trust identity and device access with basic protection that requires multifactor authentication (MFA) for medium or high sign-in risk, and introduces secure password changes and app protection policies. This is done by creating device enrollment policies.
Next, you should enroll your devices into the Intune mobile device management (MDM) platform, which enables you to start protecting your endpoints with smarter controls, such as implementing compliance policies and configuration profiles. Compliance policies ensure that endpoints enrolled into Intune meet the specified compliance requirements you have set in the policy or access to resources is blocked. Configuration profiles deploy settings on the endpoint, which allow you to lock down areas of the operating system (OS) like control panel.
Then, you should implement Zero Trust identity and device access protection with enterprise policy protection, which are enhanced controls that introduce device compliance. Enterprise policy protection is facilitated by creating Conditional Access policies, which require MFA for low, medium, or high sign-in risk and compliance policies.
Next, you should evaluate, pilot, and deploy Microsoft 365 Defender. Microsoft 365 Defender is Microsoft's anti-virus and is an extended detection and response (XDR) tool, which you deploy to Windows 10 and 11 clients. It sends device information, which is then analyzed and used to detect threats or security risks. It can also be used in other parts of the Microsoft 365 environment to detect threats, such as Exchange Online for email and Azure AD for identity.
Finally, you should implement Microsoft Purview Information Protection to discover, classify, and protect sensitive data as well as prevent data loss.
Configuring Privileged Identity Management on its own is not one of the specific steps required to implement Zero Trust. However, it is one of the tasks involved within the third step as it involves implementing more Enterprise policies to protect user identity.

Managing endpoints with Microsoft Configuration Manager is not one of the specific steps related to deploying Zero Trust in Microsoft 365 as Microsoft Configuration Manager is not a Microsoft 365 or Azure Cloud-native service. It is an application that is installed on a Windows server, whether physical or virtual, and can be implemented on-premises or in Azure.
Azure Policy is not required to implement Zero Trust for a Microsoft 365 tenant. Azure Policy is an Azure- native service that helps businesses to enforce standards and to assess compliance. With Azure Policy, you create policy definitions and assign to a scope of resources.
Role-based access control (RBAC), although a component of Zero Trust it is more relating to laas and PaaS solutions. Our scenario is focusing on configuration and operational practices which is why RBAC is not the correct answer in this instance.

---

### References

[Overview - Apply Zero Trust principles to Azure laas](https://learn.microsoft.com/en-us/security/zero-trust/azure-infrastructure-overview)  
[Common security policies for Microsoft 365 organizations](https://learn.microsoft.com/en-us/security/zero-trust/zero-trust-identity-device-access-policies-common)  
[Design configurations and operational practices for Microsoft 365](https://learn.microsoft.com/en-us/training/modules/design-solutions-secure-microsoft-365/4-design-configurations-operational-practices-microsoft-365?ns-enrollment-type=learningpath&ns-enrollment-id=learn.wwl.sc-100-design-security-solutions-applications-data)  
[What is Azure Policy?](https://learn.microsoft.com/en-us/azure/governance/policy/overview)  
[What is Azure role-based access control (Azure RBAC)?](https://learn.microsoft.com/en-us/azure/role-based-access-control/overview)  

---

## Q102:

You are a security engineer for an organization that has recently migrated to Azure and Microsoft 365. You have been asked to assign three new users in the support team with the relevant accesses. The table below shows each user's access requirements:

![image info](./Q102.PNG)

You need to assign each user the relevant role, following the principle of least privilege.
Which role should you assign each support user? To answer, select the relevant role from the drop-down menu for each user.

SupportUserA
Security Administrator

SupportUserB
Security Reader

SupportUserC
Exchange Administrator

---

### Answer:

SupportUserA should be granted the Security Administrator role. The user requires read and write access to the Microsoft Secure Score portal and the Microsoft Defender for Cloud portal to create policies. The Global Admin role can fulfil this requirement; however, it would not follow the principle of least privilege. The Exchange Administrator would grant read/write access to Microsoft Secure Score but would not allow access to the Microsoft Defender for Cloud access. The User Administrator would only grant read access to Microsoft Secure Score.
SupportUserB should be granted the Security Reader role. The user requires read only access to Microsoft Secure Score and access to view the Microsoft Purview dashboard. The User Administrator role would grant access to the Microsoft Secure Score portal but not grant access to the Microsoft Purview dashboard. It would also allow access to Azure AD and so would not follow the principle of least privilege. The Security Operator role would allow both requirements for the table. However, it would also allow the user to complete more tasks, such as being able to respond to security threat alerts, which would not follow the principle of least privilege. Finally, the Security Administrator role would give the user read and write access to the Microsoft Secure Score portal and the Microsoft Purview dashboard, and so would be unsuitable.
SupportUserC should be granted the Exchange Administrator role. The user requires read and write access to Microsoft Secure Score and access to be able to manage users' email aliases. The SharePoint Administrator would enable read and write access to Microsoft Secure Score but it would not allow any access to change users' email aliases. It would actually enable the user to fully manage SharePoint Online, which would not meet the principle of least privilege. The Security Administrator role would grant read and write access to Microsoft Secure Score but not access to change users' email aliases. Finally, the Global administrator would allow the user to meet both requirements but it would not meet the principle of least privilege, and therefore it would be an unsuitable choice.

---

### References

[Microsoft Secure Score](https://learn.microsoft.com/en-us/defender-xdr/microsoft-secure-score?view=o365-worldwide)
[Azure AD built-in roles](https://learn.microsoft.com/en-us/entra/identity/role-based-access-control/permissions-reference)

---

## Q101:

You are a security analyst for a company that has an existing Azure and Microsoft 365 tenant. Your company recently hired a third-party consultancy firm to complete a security audit on the tenant. It found that the security posture of the tenant was very low and made the recommendation to enable security defaults.
The report estimates that enabling security defaults will increase your security posture by 26 points.
You need to document which preconfigured settings are activated when security defaults are enabled.
Which three actions are enabled when security defaults are enabled?

Choose the correct answers

- Enabling self-service password reset
- Designating more than one Global Admin
- Using privileged admin roles
- Requiring administrators to use multifactor authentication
- Requiring users to use multifactor authentication when necessary
- Blocking legacy authentication protocols



---

### Answer:
- Requiring administrators to use multifactor authentication
- Requiring users to use multifactor authentication when necessary
- Blocking legacy authentication protocols

When you enable security defaults within your Microsoft 365 and Azure tenant, you are enabling the following settings:

- Requiring users to use multi-factor authentication when necessary
- Requiring administrators to use multi-factor authentication
- Blocking legacy authentication protocols

Security defaults also have preconfigured settings enforcing a user to register for multi-factor authentication (MFA) and protecting secure sign-ins and against identity fraud. Enabling the security defaults will add another 26 points to your existing Secure Score. Security defaults have similar features that you can find in the sign-in risk policy and the user risk policy recommended actions.
Requiring users and administrators to use multi-factor authentication during the login process adds an additional layer of security to the Microsoft/Azure tenant. This lowers the risk of hackers being able to gain access and decreases the attack surface of your estate.
Legacy authentication protocols like IMAP and POP3 are no longer seen as being secure and have been replaced with OAUTH as the secure method/protocol for access to Microsoft 365/Azure. For this reason it is necessary to block the legacy protocols, which mitigates the risk of being hacked and decreases the attack surface of your estate.
Using privileged roles within your tenant is a Secure Score recommended action but not one that is enabled
as part of the security defaults. This only adds one point to your Secure Score and has low user impact.
Enable self-service password reset within your tenant is a Secure Score recommended action but not one that is enabled as part of the security defaults. This only adds one point to your Secure Score and has a moderate user impact.
Microsoft recommends assigning no more than five users with the Global Administrator role. Only having a single Global Admin is a risk as it introduces a single point of failure as if that user becomes unavailable there are no more Global Admins. Although it is best practice to have more than one but less than five Global Admins, this is not a security default.

---

### References

[Security defaults in Azure AD](https://learn.microsoft.com/en-us/entra/fundamentals/security-defaults)
[Microsoft Secure Score](https://learn.microsoft.com/en-us/defender-xdr/microsoft-secure-score?view=o365-worldwide)
[Assess your security posture with Microsoft Secure Score](https://learn.microsoft.com/en-us/defender-xdr/microsoft-secure-score-improvement-actions?view=o365-worldwide)  
[Microsoft Secure Score data storage and privacy](https://learn.microsoft.com/en-us/defender-xdr/secure-score-data-storage-privacy?view=o365-worldwide)  

---

## Q100:

You are a Security Engineer for a company who has a hybrid estate with both on-premises and Azure- hosted resources. A recent penetration test on the Azure tenant has highlighted multiple security gaps that need attention to increase the overall security posture. You recommend implementing Microsoft native security services.
You need to design a solution that utilizes the different Microsoft native cloud security services. Your solution should cover all the highlighted security gaps.
Which Microsoft native cloud service covers each of the highlighted security gaps? To answer, drag the appropriate service to the correct security gap. Each service may be used once, more than once, or not at all.

Drag and drop the answers

Defender for Identity
Defender for Cloud - Apps
Defender for Office 365
Defender Vulnerability Mgmt

Identify, detect, and investigate advanced threats to users and groups.
Defender for Identity

Safeguard against malicious threat posed by email messages.
Defender for Office 365

Enable intelligent risk-based assessments of applications.
Defender for Cloud - Apps

Enable asset visibility and intelligent assessment of multiple OS.
Defender Vulnerability Mgmt

---

### Answer:

There are a number of Microsoft native security services that combine to offer a pre-breach and post- breach enterprise defense. They enable you to detect, prevent, investigate, and respond to threats across your entire estate. This includes endpoints, IAM, email, and applications.
Microsoft Defender for Identity is part of the Microsoft native security services. It allows for cloud-based identity protection that identifies, detects, and investigates advanced threats, compromised identities, and malicious insider actions.
Microsoft Defender for Office 365 is part of the Microsoft native security services. It allows you to safeguard against malicious threats posed by email messages, links, and collaboration tools.
Microsoft Defender for Cloud - Apps is part of the Microsoft native security services. It enables intelligent risk-based assessments as well as asset visibility and built-in remediation tools for applications.
Microsoft Defender for Vulnerability Mgmt (Management) is part of the Microsoft native security services. It allows asset visibility and intelligent assessment of multiple OS.

---

### References

[What is Microsoft Defender for Cloud?](https://learn.microsoft.com/en-us/azure/defender-for-cloud/defender-for-cloud-introduction)  
[Design solutions for securing Microsoft 365](https://learn.microsoft.com/en-us/training/modules/design-solutions-secure-microsoft-365/)  
[What is Microsoft Defender for Identity?](https://learn.microsoft.com/en-us/training/modules/design-solutions-secure-microsoft-365/)  
[Microsoft Defender for Office 365 security product overview](https://learn.microsoft.com/en-us/training/modules/design-solutions-secure-microsoft-365/)  
[What is Microsoft Defender Vulnerability Management](https://learn.microsoft.com/en-us/defender-vulnerability-management/defender-vulnerability-management?view=o365-worldwide)  
[Microsoft Defender for Cloud - Apps overview](https://learn.microsoft.com/en-us/defender-cloud-apps/what-is-defender-for-cloud-apps) 

---

## Q099:

You are a Cloud Security engineer for a company who has recently migrated all its workloads and resources to Azure and Microsoft 365. A recent security audit has found that the Azure tenant has a very low security score and has recommended that Microsoft Defender for Cloud be turned on.
Part of the security report also made the following recommendation: 'The organization must be safeguarded against malicious threat posed by email messages and links.'
You need to recommend a Microsoft 365 Defender protection service to meet the recommendation.

Which Microsoft 365 Defender service should you recommend?

Choose the correct answer

-  Defender for Identity
-  Defender for Endpoint
-  Defender for Cloud - Apps
-  Defender for Office 365

---

### Answer:
-  Defender for Office 365

You should recommend Defender for Office 365. Defender of Office 365 is a service that safeguards your organization from malicious threats posed by emails messages, links, and collaboration tools.
You should not recommend Defender for Endpoint. Defender for Endpoint is a service that enables
preventative protection, post-breach detection as well as automated investigation and response for client devices.
You should not recommend Defender for Identity. Defender for Identity is a service that identifies, detects and investigates advanced threats and finds compromised identities.
You should not recommend Defender for Cloud - Apps. Defender for Cloud - Apps is a service that enables deep visibility, strong data controls, and enhanced threat protection to cloud applications.

---

### References

[What is Microsoft 365 Defender?](https://learn.microsoft.com/en-us/defender-xdr/microsoft-365-defender?view=o365-worldwide)  
[Design solutions for securing Microsoft 365](https://learn.microsoft.com/en-us/training/modules/design-solutions-secure-microsoft-365/)  

---

## Q098:

Your company has a Microsoft 365 subscription and an Azure subscription.
Microsoft 365 Defender has been deployed. Senior management wants to utilize security KPIs to measure improvements in company-wide security operations. You suggest, and management has agreed, to use Microsoft Secure Score to assist in assessing the company's security posture. However, they still have questions about improvement action statuses.
What is the impact of setting an improvement action's status to Risk accepted?

Choose the correct answer

- The improvement action is not implemented.
- The improvement action is mitigated via a partner.
- The improvement action process is started.
- The improvement action is planned for future implementation.

---

### Answer:
- The improvement action is not implemented.

Changing an improvement action's status to Risk accepted means that the improvement action is not implemented. In risk management, accepting a risk means that an organization has chosen to accept the risk presented by a threat or vulnerability. The decision to accept a risk should be made based on risk assessment techniques. For example, Microsoft Secure Score may recommend that all server disks should be encrypted with BitLocker, but it is determined that this will cause major performance issues. The organization may determine that performance is more important than disk encryption and accept the risk.
When a risk is accepted, the improvement action is not planned for future implementation. This happens when an improvement action's status is set to Planned.
When a risk is accepted, the improvement action is not mitigated via a partner. This happens when an improvement action's status is set to Resolved through a third party.
When a risk is accepted the improvement action process is not started. You can complete an action by choosing the Manage option, which will take you to the configuration, or select the Share option to obtain a link to the page where the action can be implemented.

---

### References

[Assess your security posture with Microsoft Secure Score](https://learn.microsoft.com/en-us/defender-xdr/microsoft-secure-score-improvement-actions)  
[Microsoft Secure Score](https://learn.microsoft.com/en-us/defender-xdr/microsoft-secure-score)  
[Examine Microsoft Secure Score](https://learn.microsoft.com/en-us/training/modules/examine-microsoft-secure-score/)  
[Track your Microsoft Secure Score history and meet goals](https://learn.microsoft.com/en-us/defender-xdr/microsoft-secure-score-history-metrics-trends)  

---

## Q097:

You are an IT administrator for a global organization. You are responsible for backup and recovery for the entire hybrid environment. You currently use Azure Backup to manage backups for Azure-hosted virtual machines (VMs) as well as files and folders. The Microsoft Azure Recovery Services (MARS) agent is installed on all of the virtual machines.
The development team has recently deployed the following VMs on premises:

| VM Name             | OS Type             |
|----------------------|---------------------|
| Server01              | Windows Server 2022  |
| Server02              | Windows Server 2022  |
| Server03              | CentOS               |
| Server04              | Windows Server 2019  |
| Server05              | CentOS               |
| Server06              | Debian               |

You need to onboard the on-premises VMs into the existing Azure Backup schedule.
Which VMs can you onboard into the existing Azure Backup schedule?

- Server01, Server02, Server03, Server04, Server05, and Server06
- Server01, Server02, and Server04
- Server01, Server02, and Server06
- Server03 and Server05

---

### Answer:
- Server01, Server02, and Server04

You can onboard Server01, Server02, and Server04 into the existing Azure Backup schedule. It is only possible to backup on-premises Windows machines directly to Azure using the Azure Backup server and the Microsoft Azure Recovery Services (MARS) agent. Linux VMs are not supported with the MARS agent for on-premises VMs. Microsoft Azure is a simple, secure, and cost-effective solution to back up data that is stored on premises and in the cloud. It utilizes the MARS agent to back up data from on-premises machines to a backup Recovery Services vault in Azure.
You cannot onboard Server01, Server02, and Server06 into the existing Azure Backup schedule. Although Server01 and Server02 run Windows OS and are supported by the MARS agent, Server06 is a Linux Debian OS VM, and is therefore not supported by this agent.
You cannot onboard Server03 and Server05 into the existing Azure Backup schedule. Both VMs run Linux CentOS, which is not supported by the MARS agent.
You cannot onboard Server01, Server02, Server03, Server04, Server05, and Server06 into the existing Azure Backup schedule. Server03, Server05, and Server06 all run Linux OS, and are therefore not supported by the MARS agent. These cannot be onboarded into the existing Azure Backup schedule. Server01, Server02, and Server04 could be onboarded because they run Windows OS, and are therefore supported by the MARS agent.


---

### References

[Configurations for secure backup and restore](https://learn.microsoft.com/en-us/training/modules/design-resiliency-strategy-common-cyberthreats-like-ransomware/4-configurations-secure-backup-restore?ns-enrollment-type=learningpath&ns-enrollment-id=learn.wwl.sc-100-design-solutions-best-practices-priorities)  
[What is the Azure Backup service?](https://learn.microsoft.com/en-us/azure/backup/backup-overview)  
[Support matrix for backup with the Microsoft Azure Recovery Services (MARS) agent](https://learn.microsoft.com/en-us/azure/backup/backup-support-matrix-mars-agent)  

---

## Q096:

Your company utilizes Azure services to host web app workloads for its payment processing system. Following a breach that exploited a well-known vulnerability in Linux, you have been asked to design a solution that allows the company to continue utilizing Azure services but improves the security posture of its web presence. To meet this goal, you recommend your company to migrate workloads, such as payment and notification APIs, to Azure Functions.
You need to describe the impact of this design approach.
For each of the following statements, select Yes if the statement is true. Otherwise, select No.

The company is not required to manage infrastructure for the - Application Programming Interfaces (APIs).
Yes

The company's app secrets are stored in highly-secure Hardware Security Modules (HSMs).
No

The company can deploy - Application Programming Interface (API) workloads using hardened containers.
No

The company's web assets are stored on content delivery networks (CDNs), not on virtual machine (VM) instances.
No

The company only pays for resources when code is being executed.
Yes

---

### Answer:

With Azure Functions, the company is not required to manage infrastructure for the - Application Programming Interfaces (APIs). Azure Functions is a serverless computing platform that allows you to run code without having to worry about provisioning or managing servers.
With Azure Functions, the company's app secrets are not stored in highly-secure Hardware Security Modules (HSMs). HSMs are physical devices which are used to protect certificates, secrets, passwords, and other sensitive keys. HSMs are compatible with Azure Key Vault, but do not integrate directly with Azure Functions.
With Azure Functions, the company does not deploy API workloads using hardened containers. The Functions service takes care of all underlying infrastructure. A container is a self-contained, isolated environment in which an application can run. Containers are similar to virtual machines (VMs), but unlike VMs, containers do not have their own guest operating system. Instead, containers share the same kernel as the host operating system and run directly on the host's hardware.
With Azure Functions, the company's web assets are not stored on content delivery networks (CDNs). A CDN is a system of nodes that store or cache copies of digital files and make them available to users on demand. When a user requests a file from a CDN, the file is delivered to the user from the closest node, which can improve download speeds and reduce web traffic.
With Azure Functions, the company only pays for resources when code is being executed. Functions can be triggered by a variety of events, including timers, HTTP requests, or other cloud-based events. You can write your functions in a variety of languages, including C#, F#, and JavaScript. As functions are triggered by events, you only pay for the resources you use when your code is actually running.

---

### References

[Azure Functions overview](https://learn.microsoft.com/en-us/azure/azure-functions/functions-overview?pivots=programming-language-csharp)  
[Securing Azure Functions](https://learn.microsoft.com/en-us/azure/azure-functions/security-concepts?tabs=v4)    
[What is a container?](https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/what-is-a-container/)  
[What is a content delivery network on Azure?](https://learn.microsoft.com/en-us/azure/cdn/cdn-overview)  
[What is Azure Dedicated HSM?](https://learn.microsoft.com/en-us/azure/dedicated-hsm/overview)

---

## Q095:

A company deploys a containerized application using Azure Kubernetes Service (AKS). When a critical production bug that renders the app unresponsive is discovered, the company's development team uses Azure Pipelines to deploy a fix. However, the fix opens up a vulnerability that is quickly exploited by an attacker, causing a major outage. During the investigation of the incident, you discover that the development team overlooked code errors in the fix that made the app vulnerable to code injection attacks.

You need to help the company improve and secure its DevOps process while minimizing testing overhead.
Which two solutions should you recommend to mitigate the risk of undetected vulnerabilities in application code? Each correct answer presents a complete solution.

Choose the correct answers

The development team should distribute source code and employ Static - Application Security Testing (SAST).
The development team should implement regression testing procedures.
The development team should perform Interactive - Application Security Testing (IAST) before releasing app updates.
The development team should add fuzzing to the development pipeline.
The development team should implement Continuous Integration/Continuous Delivery (CI/CD) to manage app updates.

---

### Answer:
The development team should implement regression testing procedures.
The development team should add fuzzing to the development pipeline.

You should recommend that the development team add fuzzing to the development pipeline. Fuzzing is an automated process that sends random or malformed data to an application in an attempt to trigger unplanned behaviors or failures. This approach can be used to discover buffer overflow and other vulnerabilities in which an application does not properly process input. Fuzzing is essentially a form of brute force attack that can help to identify security holes in an application that may otherwise go undetected. Fuzzing is also referred to as fuzz testing, and Microsoft's OneFuzz GitHub project can be used to help to support this process.
You should recommend that the development team implement regression testing procedures. Regression testing is used to ensure that an application continues to function as expected after the code has been changed. Security regression testing focuses on ensuring that new vulnerabilities have not been inadvertently introduced during the development process. It should be part of an overall security testing strategy and should be performed whenever changes are made to the application whether part of a new release, a patch, or an upgrade. Security regression testing often includes automated techniques such as fuzzing.
You should not recommend distributing source code and employing Static - Application Security Testing (SAST). During static analysis, code is manually reviewed, often line by line, to discover vulnerabilities. Although time consuming, static analysis can uncover vulnerabilities that might be missed by automated analysis methods. However, SAST does not minimize testing overhead.
You should not recommend performing interactive application security testing (IAST) before releasing app updates. IAST is an approach to application security testing that combines the use of both automated and manual testing techniques. By combining these two approaches, IAST can provide greater coverage and insight into the security of an application than either technique could alone. However, IAST does not minimize testing overhead.
You should not recommend implementing Continuous Integration/Continuous Delivery (CI/CD) to manage app updates. CI/CD is designed to ensure that functional code can be deployed at any time during the development process. Azure Pipelines provides CI/CD functionality.

---

### References

[A brief introduction to fuzzing and why it's an important tool for developers](https://www.microsoft.com/en-us/research/blog/a-brief-introduction-to-fuzzing-and-why-its-an-important-tool-for-developers/)  
[SAST, DAST, IAST, and RASP: how to choose?](https://www.ptsecurity.com/ww-en/analytics/knowledge-base/sast-dast-iast-and-rasp-how-to-choose/)  
[What is Azure Pipelines?](https://learn.microsoft.com/en-us/azure/devops/pipelines/get-started/what-is-azure-pipelines?view=azure-devops)  

---

## Q094:

Your financial services company processes client transactions using a web app hosted on Azure - App Service. You determine that an attacker would be able to breach the service and steal sensitive data, due to a compromised private key having a cascading effect on all user encryption keys.
To mitigate this risk, you need to enhance cryptographic security by implementing a trust model.
Which two actions should you recommend the app developers carry out to achieve this? Each correct answer presents part of the solution.

Choose the correct answers

- Issue a master certificate to a root CA.
- Escrow user certificates with a third party.
- Issue a certificate to a subordinate CA.
- Issue user certificates from a subordinate CA.
- Pin user certificates with multiple CAs.


---

### Answer:
- Issue a certificate to a subordinate CA.
- Issue user certificates from a subordinate CA.

You should recommend issuing a certificate to a subordinate certificate authority (CA) and then issuing user certificates from a subordinate CA. A Public Key Infrastructure (PKI) trust model is a system in which a trusted authority issues digital certificates that verify the identity of a website or other online entity. The certificates are then used to create an encrypted connection between the two parties, ensuring that information passed between them is not compromised by third parties. There are several different types of PKI trust models, but the most common is the hierarchical trust model. In this model, each CA is responsible for issuing certificates to subordinate CAs, which then issue certificates to websites or other online entities. This creates a tree-like hierarchy in which each CA is ultimately responsible for the security of the certificates it issues. You can use use Active Directory Certificate Services (AD CS) to create and manage PKI certificates.
You should not recommend issuing a master certificate to a root CA. In PKI, a root CA becomes a root of trust for a certificate hierarchy and does not require a master certificate. A root of trust is a physical or logical security construct that is used to establish a chain of trust in PKI.
You should not recommend escrowing user certificates with a third party. Key escrow and management is a system in which cryptographic keys are held by a third party on behalf of two other parties. The third party, known as a key escrow, is responsible for safeguarding the keys and making them available to the parties when needed.
You should not recommend pinning user certificates with multiple CAs. Certificate pinning involves the use of a pinned certificate, l.e. a certificate that is known to be trusted by the client. When a client connects to a web server, it compares the server's presented certificate against the list of pinned certificates.

---

### References

[How to Setup Active Directory Certificate Services (PKI) in Azure, AWS, GCP (Certificate Authority)](https://cloudinfrastructureservices.co.uk/how-to-setup-active-directory-certificate-services-in-azure-aws-gcp-ad-cs-pki/)  
[What is Root of Trust?](https://cpl.thalesgroup.com/faq/hardware-security-modules/what-root-trust)  
[What is Key Escrow? - Store Cryptographic Keys](https://jumpcloud.com/blog/key-escrow)  
[Certificate and Public Key Pinning](https://owasp.org/www-community/controls/Certificate_and_Public_Key_Pinning)  

---

## Q093:

Your company plans to migrate a web app to Azure. The web app processes financial data, and due to the sensitive nature of the data being stored and processed, any data kept in Azure Storage must be encrypted using app-specific keys. When the data is accessed, it must be unencrypted using the app-specific key and then re-encrypted before being sent to its destination.
Which of the following should you recommend based on the stated requirements? To answer, select the appropriate options in the answer area.

Choose the correct options

To generate and manage certificates:
Implement Key Vault.

To unencrypt and re-encrypt Storage data:
Encrypt the data with the destination node's public key.

---

### Answer:

To generate and manage certificates, you should recommend implementing Azure Key Vault. Azure Key Vault is a cloud key management service that helps you to safeguard the cryptographic keys and secrets that are used by your apps and services. It provides a centralized storage area for this type of data, making it easier to manage and control its use. You can also use Azure Key Vault to help to meet compliance requirements, such as those concerning data protection and security. Azure Key Vault supports the creation and management of Public Key Infrastructure (PKI) certificates.
To unencrypt and re-encrypt Storage data, you should recommend encrypting the data with the destination node's public key. PKI keys come in asymmetric pairs, a public key and a private key, which means that when one key is used to encrypt data, the corresponding key is used to decrypt that same data. The public key is shareable and it is embedded in an X.509 certificate. The private key is not sharable. In this scenario, using the destination node's public key to encrypt data means that the data can only be decrypted using the corresponding private key, which only the destination node holds.
You should not recommend using Azure Managed Hardware Security Module (HSM) to generate and manage certificates. An HSM is a physical device, typically a computer or an embedded system, that performs cryptographic functions such as authentication, digital signing, encryption, key storage and management, and protected communications. HSMs are used in applications where these security operations are critical to data safety or privacy.
You should not recommend using secrets to generate and managed certificates. Secrets can be compared to passwords and are often used for - Application Programming Interface (API) authentication or similar purposes.


---

### References

[Get started with Key Vault certificates](https://learn.microsoft.com/en-us/azure/key-vault/certificates/certificate-scenarios)  
[Cryptography with Alice and Bob](https://wordtothewise.com/2014/09/cryptography-alice-bob/)  
[Azure Key Vault keys, secrets and certificates overview](https://learn.microsoft.com/en-us/azure/key-vault/general/about-keys-secrets-certificates)  
[What is Azure Key Vault Managed HSM?](https://learn.microsoft.com/en-us/azure/key-vault/managed-hsm/overview)  

---

## Q092:

Your company uses Azure Kubernetes Service (AKS) for container orchestration. You have been tasked with maximizing AKS security based on the following requirements:

- Inbound and outbound network traffic must be controlled
- Confidential processes must run in a hardware-based Trusted Execution Environment (TEE)

As part of this assignment, you create a file with the following content:

```
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: backend-policy
  namespace: development
spec:
  podSelector:
   matchLabels:
   app: webapp
  role: backend
  ingress: []
```

Which tasks should you complete for the following elements of your AKS security plan? To answer, select the appropriate options from the drop-down menus.

To apply rules to control traffic flow
Use kubectl to apply the named manifest.

To run confidential processes in a TEE
Deploy enclave-aware containers.


---

### Answer:

To apply rules that will control traffic flow, you should use kubectl to apply the named manifest. The file that you created in this question is a Yet Another Markup Language (YAML) formatted Azure Network Policy. These policies contain rules that control the traffic that is sent to and from pods in an Azure Kubernetes Service (AKS) cluster. By default, AKS pods can send and receive traffic without restrictions. Once defined, the YAML manifest creating your network rules can be applied using the kubectl apply -f <policy name>.yaml command.
Kubectl is a tool which is used for managing Kubernetes clusters. With kubectl, you can configure and manage your Kubernetes cluster, deploy applications to your cluster, and view the status of your applications. You can also use kubectl to troubleshoot your applications and locate potential problems.
To run confidential processes in a Trusted Execution Environment (TEE), you should deploy enclave-aware containers. AKS containers use Software Guard Extensions (SGX) enclaves to provide a TEE for container processes. An SGX enclave is a secure, hardware-isolated environment that runs on a specialized Central Processing Unit (CPU). Anything inside an enclave is protected from access by any other part of the system, making it an ideal method for ensuring confidential computing.
You do not need to create an Azure Network Policy or define policy rules in YAML. This has already been done, as evidenced by the YAML manifest shown in the scenario.
You do not need to run each application instance in a dedicated pod. This is typically the default function provided by a Kubernetes pod, and pods and containers typically have a 1:1 relationship. In this scenario, this step is not necessary and would not necessarily increase platform security.

---

### References

[Secure traffic between pods using network policies in Azure Kubernetes Service (AKS)](https://learn.microsoft.com/en-us/azure/aks/use-network-policies)  
[Enclave Aware Containers with Intel SGX](https://learn.microsoft.com/en-us/azure/confidential-computing/enclave-aware-containers)  
[Kubernetes core concepts for Azure Kubernetes Service (AKS)](https://learn.microsoft.com/en-us/azure/aks/concepts-clusters-workloads)  

---

## Q091:

You have been hired as a security architect by an organization that owns multiple Azure subscriptions. Recently, the company migrated its core REST APIs and websites to Azure laas. However, the efficient and effective management of the migrated platforms has become an overwhelming task for the organization given that it only maintains minimal IT staff. As a result, a recent attack overwhelmed the company's web workloads and resulted in excessive latency for customers. The subsequent slow web page load times caused the organization to lose revenue.

You need to implement solutions that fulfill the following requirements:

- Web workloads must scale up automatically based on workload.
- REST APIs and websites must be protected from DDoS.
- Integration with Azure DevOps must be supported.

Which solutions should you implement? 
To answer, select the appropriate solutions from the drop-down menus.

Choose the correct options

To support workload scaling, DevOps integration, and minimize administrative overhead:
Azure - App Service

To protect workloads from DDoS:
Azure CDN

---

### Answer:


You should implement Azure Content Delivery Network (Azure CDN) to protect workloads from Distributed Denial of Service (DDoS) attacks. Azure CDN offers developers a global network of servers that can be used to cache content and deliver it to users. This content can include images, media files, and application files. When you use the Azure CDN, your content is cached on servers that are located close to your users, which improves the availability, performance and reliability of your applications. DDoS protection is an inherent feature of Azure CDN.
You should not implement Azure Functions. Azure Functions is a great way to run small pieces of code in the cloud, without having to worry about maintaining a server. You can use Azure Functions to perform a range of functions such as processing images, sending notifications and processing payments. Furthermore, since functions are triggered by events, you only pay for the resources that you use when your code is actually running.
You should not implement Azure Spring - Apps. Formerly known as Azure Spring Cloud, this is a cloud-native microservices platform that helps you securely and quickly build, deploy, and manage Spring Boot-based applications on Azure. It offers built-in support for service discovery, config management, failover/high availability, monitoring, metering, and logging.
You should not implement Virtual Machine Scale Sets. A Virtual Machine Scale Set is a pool of identical virtual machines (VMs) in Azure, with autoscale settings that enable the VMs to increase or decrease in number automatically, based on demand. This enables you to run large-scale services without having to manually provision and manage individual VMs.


---

### References

[Azure security baseline for Content Delivery Network](https://learn.microsoft.com/en-us/security/benchmark/azure/baselines/content-delivery-network-security-baseline)  
[- App Service overview](https://learn.microsoft.com/en-us/azure/app-service/overview)  
[Azure Functions overview](https://learn.microsoft.com/en-us/azure/azure-functions/functions-overview?pivots=programming-language-csharp)  
[What is Azure Spring - Apps?](https://learn.microsoft.com/en-us/azure/spring-apps/enterprise/overview)  
[Virtual Machine Scale Sets documentation](https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/)  

---

## Q090:

Your company is planning to migrate its Internet of things (IoT) provisioning, monitoring, and management to Azure IoT Hub. In order to enhance security operations for lot devices, sensors which have been located in remote locations will be connected to the Defender for lot portal. You need to make recommendations for on-premises firewall configurations to ensure that the sensors are migrated successfully.

Which port should you recommend for each lot application protocol? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

For AMQP communications:
5671

For AMQP over WebSockets:
443

For MQTT communication:
8883

For MQTT over WebSockets:
443

---

### Answer:

You should recommend the following ports:

- For AMQP communications: 5671
- For AMQP over WebSockets: 443
- For MQTT communications: 8883
- For MQTT over WebSockets: 443

Advanced Message Queuing Protocol (AMQP) is commonly used in Internet of Things (IoT) communications, and it uses port 5671. AMQP is more robust than MQ Telemetry Transport (MQTT), it offers a broader set of features, and it can take advantage of connection multiplexing. AMQP over WebSockets operates over port 443.
Like AMQP, MQTT is also a common lot application protocol. MQTT was designed to be lightweight, both operationally and from a code footprint standpoint. It is ideally suited to environments where latency may be introduced due unreliable communication methods. MQTT operates natively over port 8883. MQTT over WebSockets operates over port 443.
HTTPS (Hypertext Transfer Protocol Secure) is a common Internet protocol traditionally used to transfer data between clients and webservers. However, its use has been expanded to include a variety of other scenarios, including IoT. HTTPS operates over port 443.
Port 80, also known as HTTP, is not used for any of the lot applications as it is generally used for unsecure web browsing and does not support lot applications.

---

### References

[Methods for connecting sensors to Azure](https://learn.microsoft.com/en-us/azure/defender-for-iot/organizations/architecture-connections)  
[Choose a device communication protocol](https://learn.microsoft.com/en-us/azure/iot-hub/iot-hub-devguide-protocols)  

---

## Q089:

Your company uses Azure-based virtual machines (VMs) and SQL Managed Instances to support its e- commerce platform. To reduce the attack surface presented by the platform, the company plans to migrate all compute operations to a Docker-based installation.
You need to ensure that the new platform is secure by minimizing the risk of unknown vulnerabilities.
Which two design requirements should you recommend? Each correct answer presents part of the solution.

Choose the correct answers

- Integrate the platform with Microsoft Defender for Cloud.
- Create an endpoint security policy in Microsoft Endpoint Manager.
- Require that all images come from a private trusted registry.
- Configure hypervisor policies that only allow trusted processes.
- Implement full-disk encryption on each VM.

---

### Answer:
- Integrate the platform with Microsoft Defender for Cloud.
- Require that all images come from a private trusted regisstry.

You should recommend requiring that all images come from a private registry. Docker is a popular application containerization ecosystem. Containers provide many of the same benefits as virtual machines (VMS) and are designed to be portable and largely self-contained. They share a host operating system that manages kernel and device driver access. Containers are often stored and shared via public and private container registries. In many cases, public registries do not verify or enforce container security, which means that unwanted or even malicious apps or services may be installed in these containers. Your company should use Docker Trusted Registry or Azure Container Registry for image storage and retrieval.
You should also recommend integrating the platform with Microsoft Defender for Cloud. Microsoft Defender for Cloud is a security service that helps protect your organization's data and devices not only in Azure, but on-premises and with other cloud providers like Google and AWS. It provides comprehensive protection against malware, advanced threats, and malicious activity. Defender also provides security features for Docker containers.
You should not recommend configuring hypervisor policies that only allow trusted processes. Docker and other containerization platforms do not rely on hypervisors. They run using an application on a host system.
You should not recommend creating an endpoint security policy in Microsoft Endpoint Manager. Endpoint Manager is a Microsoft tool that helps enterprise customers manage devices and keep them secure. It provides a unified console for managing all types of devices, including Windows PCs, macOS, IOS, and Android devices. Endpoint Manager is not used to manage Docker containers.
You should not recommend implementing full-disk encryption on each VM. This approach would work for a VM-based deployment. However, Docker uses containers, not VMs.


---

### References

[Security considerations for Azure Container Instances](https://learn.microsoft.com/en-us/azure/container-instances/container-instances-image-security)  
[Overview of Microsoft Defender for Containers](https://learn.microsoft.com/en-us/azure/defender-for-cloud/defender-for-containers-introduction)  
[What is a hypervisor?](https://www.redhat.com/en/topics/virtualization/what-is-a-hypervisor)  
[Manage endpoint security in Microsoft Intune](https://learn.microsoft.com/en-us/mem/intune/protect/endpoint-security)
[Best Practices for Deploying BitLocker with Intune](https://petri.com/best-practices-for-deploying-bitlocker-with-intune/)   

---

## Q088:

Your company uses lot flow valves at remote water treatment facilities. The devices are monitored by network sensors that are supplied by different vendors. Each vendor uses different public clouds. You want to consolidate monitoring and enhance security.
You need to recommend a multi-cloud connectivity method that will allow the devices to be protected by Microsoft Defender for loT. Your solution requires predictable throughput.

Which recommendation should your solution include?

Choose the correct answer

- Create a Private Link service with an ARM template.
- Define a Point-to-Site (P2S) VPN gateway connection.
- Use Bicep to create an Azure ExpressRoute circuit.
- Set up a private endpoint using the Azure portal.

---

### Answer:
- Use Bicep to create an Azure ExpressRoute circuit.

You should recommend using Bicep to create an Azure Express Route circuit. Microsoft Defender for lot can be used to monitor security for Internet of Things (IoT) devices. To connect devices from multiple public clouds while ensuring predictable throughput, you should use Azure Express Route. Azure Express Route lets you extend your on-premises and other cloud networks into the Microsoft cloud over a secure, private connection. You can create hybrid applications and architectures that include both cloud and on-premises services, and you can use Express Route to bypass the public internet and improve network performance. Bicep is a human-readable language that can be used to deploy Azure resources.
You should not recommend defining a Point-to-Site (P2S) Virtual Private Network (VPN) gateway connection. P2S VPN connections are designed to connect a single endpoint to an Azure virtual network.
You should not recommend creating a Private Link service with an ARM template. A Private Link service is a
link to one of your services or resources hosted in Azure.
You should not recommend setting up a private endpoint using the Azure portal. An Azure private endpoint is a network interface that connects you privately and securely to a service powered by Azure Private Link.


---

### References

[Configure proxy settings on an OT sensor](https://learn.microsoft.com/en-us/azure/defender-for-iot/organizations/connect-sensors)  
[Quickstart: Create an Express Route circuit with private peering using Bicep](https://learn.microsoft.com/en-us/azure/expressroute/quickstart-create-expressroute-vnet-bicep?tabs=CLI)  
[Remote work using Azure VPN Gateway Point-to-site](https://learn.microsoft.com/en-us/azure/vpn-gateway/work-remotely-support)  
[Quickstart: Create a private link service by using an ARM template](https://learn.microsoft.com/en-us/azure/private-link/create-private-link-service-template)  
[Quickstart: Create a private endpoint by using the Azure portal](https://learn.microsoft.com/en-us/azure/private-link/create-private-endpoint-portal?tabs=dynamic-ip)  

---

## Q087:

You are in charge of IT Security Operations for an organization that currently manages its PCs, Servers, and mobile devices with Microsoft Configuration Manager. You have a hybrid infrastructure and utilize Update Management to automate security updates to Azure-hosted virtual machines.

Your have the following services configured within your environment:

- Azure Automation Update Management is added to your Azure Automation account
- Microsoft Configuration Manager
- Log Analytics Workspace with Update Management enabled

Your manager wants you to integrate Update Management with Microsoft Configuration Manager so you can use this Azure native service to report and update Windows servers and pre-stage software update deployments. Currently the security updates are not received from Microsoft Configuration Manager.
You need to integrate Update Management with Microsoft Configuration Manager.
What is a prerequisite before this can happen?

Choose the correct answer

- Configuring the Windows Agent to communicate with Windows Server Update Service (WSUS)
- Hybrid-joining on-premises servers and end user devices
- Configuring Microsoft Configuration Manager to manage security updates
- Giving the Windows Agent access to Microsoft Updates

---

### Answer:
- Giving the Windows Agent access to Microsoft Updates

You should give the Windows Agent access to Microsoft Updates. The Windows Agent needs to be either configured to communicate with a Windows Server Update Services (WSUS) server or have access to Microsoft Update if they do not receive security updates from Microsoft Configuration Manager. In this scenario, there is no existing WSUS server and the security updates are not received from Microsoft Configuration Manager. This means that the only correct configuration is to give the Windows Agent access to Microsoft Updates. This will allow you report and update managed Windows servers by creating and pre-staging software update deployments.
You should not configure the Windows Agent to communicate with Windows Server Update Service (WSUS), WSUS is the Windows Server service that is traditionally used in on-premises environments to patch and update Windows operating systems (OS) on servers and client devices. There is no WSUS server in this scenario.
You should not configure Microsoft Configuration Manager to manage security updates. Microsoft Configuration Manager is the Windows application that is traditionally installed on a Windows on-premises server to manage Windows clients, deploy and manage Windows 10 and manage updates to client devices.
Servers and end user devices do not need to be hybrid-joined in order to integrate Microsoft Configuration Manager and Update Management for on-premises resources. If you needed to use Microsoft Intune to manage security updates for on-premises resources, you would need to ensure they were hybrid-joined; however, in this scenario, it is not a prerequisite.


---

### References

[Security updates](https://learn.microsoft.com/en-us/training/modules/design-resiliency-strategy-common-cyberthreats-like-ransomware/5-security-updates?ns-enrollment-type=learningpath&ns-enrollment-id=learn.wwl.sc-100-design-solutions-best-practices-priorities)  
[Windows Server Update Services (WSUS)](https://learn.microsoft.com/en-us/windows-server/administration/windows-server-update-services/get-started/windows-server-update-services-wsus)  
[What is Configuration Manager?](https://learn.microsoft.com/en-us/windows-server/administration/windows-server-update-services/get-started/windows-server-update-services-wsus)  

---

## Q086:

Your company has a Microsoft 365 E5 subscription and several Azure subscriptions. To reduce the risk of compromised devices and the loss of sensitive data, the company plans to enroll user devices in Microsoft Intune. All devices run Windows 10 or Windows 11.
As each department has different device requirements and policies, you need to recommend a multi- faceted enrollment strategy.
Which enrollment method should you recommend based on each device's attributes? To answer, select the appropriate options in the answer area.

Choose the correct options

The device uses a device enrollment manager (DEM) account. 
Automatic enrollment only

The device is a bring your own device (BYOD) device. 
Automatic enrollment or co-management

The device is managed using Configuration Manager.
Co-management only

---

### Answer:

You should recommend Intune automatic enrollment for devices that use a device enrollment manager (DEM) account. A DEM account is an Azure Active Directory (Azure AD) user that can be used to enroll devices in Microsoft Intune. This is typically done as a bulk enrollment, which requires you to create a provisioning package with Windows Configuration Designer (WCD). A DEM account user requires an assigned Intune license. You cannot perform bulk enrollment for bring your own device (BYOD) devices.
You should recommend automatic enrollment or co-management for the enrollment of bring your own device (BYOD) devices with Intune. A BYOD device is typically an employee's personal device that they also use for work purposes. When a BYOD device is enrolled with Intune, it does not require a device wipe. Once enrolled, the device is associated with an AD user account.
You should recommend co-management to enroll devices in Intune if you also use Configuration Manager to manage a device. Using this method, devices already enrolled in your on-premises Configuration Manager deployment can be co-enrolled in Intune.
You should not recommend bulk enrollment. Bulk enrollment is the ability to enroll multiple devices at once into Microsoft Intune. When you use bulk enrollment, all the required settings and configurations are automatically applied to each device.

---

### References

[Enrollment guide: Enroll Windows client devices in Microsoft Intune](https://learn.microsoft.com/en-us/mem/intune/fundamentals/deployment-guide-enrollment-windows)  
[Add device enrollment managers](https://learn.microsoft.com/en-us/mem/intune/enrollment/device-enrollment-manager-enroll)  
[What is co-management?](https://learn.microsoft.com/en-us/mem/configmgr/comanage/overview)  
[Bulk enrollment for Windows devices](https://learn.microsoft.com/en-us/mem/intune/enrollment/windows-bulk-enroll)  

---

## Q085:

A solutions architect has created a Virtual Network to support a web application that will run an Azure VM. Currently, the VM has outbound internet access. The architect must ensure that the VM is accessible from the internet using standard web services, and all other services should be prohibited. Any VMs added to the Virtual Network at a later time must not be accessible from the internet.
You need to recommend a solution that meets these requirements.
Which two steps should you include in your recommendation? Each correct answer presents part of the solution.

Choose the correct answers

- Deploy Azure Firewall and create an application rule.
- Assign a public IP address to the web server's network interface.
- Create an application security group and assign a public IP.
- Create a NSG and define inbound rules for web traffic.
- Deploy a NAT gateway and configure the VM's private IP.

---

### Answer:
- Assign a public IP address to the web server's network interface.
- Create a NSG and define inbound rules for web traffic.

You should recommend assigning a public IP address to the web server's network interface. A resource must be assigned or associated with a public IP address in order to be internet-accessible. Once the IP address has been assigned, the architect should create a network security group (NSG) and define inbound rules for web traffic. An NSG is a virtual networking element that enables you to control the inbound and outbound traffic to resources in a virtual network using IP addresses, protocols, and ports. NSGs can be used to close off parts of your network to all traffic, or they can be used to allow specific types of traffic while blocking all other traffic.
You should not recommend creating an application security group (ASG) and assigning a public IP. An ASG is a logical grouping of Azure resources that allows you to manage their security policies as a single unit. In this scenario, you would need to associate the VM network interface with the ASG, and the ASG could then be referenced by the NSG.
You should not recommend deploying a Network Address Translation (NAT) gateway and configuring the VM's private IP. An Azure NAT is a NAT gateway that typically sits between public and private networks and allows privately addressed nodes to access and be accessed by publicly addressed nodes. In this scenario, you would need to create a rule that links a public IP on an Azure NAT to the VM's private IP.
You should not recommend deploying Azure Firewall and creating an application rule. Azure Firewall is a Next-Generation Firewall (NGFW) with full Intrusion Prevention System (IPS) capabilities. Azure Firewall uses application rules to define internet resources that can be accessed from a subnet.


---

### References

[Public IP addresses](https://learn.microsoft.com/en-us/azure/virtual-network/ip-services/public-ip-addresses)
[Create, change, or delete a network security group](https://learn.microsoft.com/en-us/azure/virtual-network/manage-network-security-group?tabs=network-security-group-portal)  
[Azure - - Application Security Group (ASG) Overview](https://medium.com/awesome-azure/azure-application-security-group-asg-1e5e2e5321c3)  
[What is Azure NAT Gateway?](https://learn.microsoft.com/en-us/azure/nat-gateway/nat-overview)  
[Introduction to Azure Firewall](https://learn.microsoft.com/en-us/training/modules/introduction-azure-firewall/)  

---

## Q084:

Your company has an active Microsoft 365 subscription. Employees use laptops running Windows 10 or Windows 11.
You need to recommend a solution to silently enable BitLocker on employee systems.
Which process or task should you include in your recommendation?

Choose the correct answer

- Submitting a Customer Key activation request in the FastTrack portal.
- Creating an endpoint security policy in Microsoft Intune
- Running an Intune device encryption report to verify Trusted Platform Module (TPM) versions.
- Defining a multi-workload data encryption policy (DEP) in PowerShell.

---

### Answer:
- Creating an endpoint security policy in Microsoft Intune

You should recommend creating an endpoint security policy in Microsoft Intune. Intune is a Microsoft tool that helps enterprise customers manage devices and keep them secure. It is a cloud-based service that provides a unified console for managing all types of devices, including Windows PCs, macOS, iOS, and Android devices. Endpoint Manager can help you deploy and manage apps, policies, and settings on your devices. To silently enable BitLocker on employee devices, you should create an endpoint security policy.
You should not recommend defining a multi-workload data encryption policy (DEP) in PowerShell. A DEP defines a key hierarchy that is used to encrypt your data in Microsoft 365 or other Microsoft cloud services. DEP does not apply to non-cloud resources, such as employee laptops.
You should not recommend submitting a Customer Key activation request in the Fast Track portal. You can use Customer Key to create and manage encryption keys used for your Microsoft 365 services and resources. Customer Key is used with DEP to create an encryption hierarchy.
You should not recommend running an Intune device encryption report to verify Trusted Platform Module (TPM) versions. BitLocker requires TPM 1.1 or 2.0. You can run a device encryption report to verify if employee laptops meet this requirement, but this step is optional.

---

### References

[Manage BitLocker policy for Windows devices with Intune](https://learn.microsoft.com/en-us/mem/intune/protect/encrypt-devices)  
[Manage Customer Key](https://learn.microsoft.com/en-us/purview/customer-key-manage)  
[Set up Customer Key](https://learn.microsoft.com/en-us/purview/customer-key-set-up)  

---

## Q083:

Your company deploys VDI for all employees in Azure. Each employee has a dedicated VM running Windows 11 Enterprise. All systems are joined to Microsoft Azure AD. To increase security and meet regulatory compliance requirements, management would like to implement BitLocker for all VDI instances.
You need to recommend a tool that facilitates BitLocker deployment but does not require for an agent to be installed. Encryption should be manageable at the OS level.

Which tool should you recommend to meet these requirements?

Choose the correct answer

- Microsoft Endpoint Configuration Manager
- Microsoft Intune
- Azure Storage Server-Side Encryption
- Microsoft Defender for Storage

---

### Answer:
- Microsoft Intune

You should recommend using Microsoft Intune. Microsoft Intune is a cloud-based service that helps you to manage and secure your devices, apps, and data. It provides mobile device management (MDM), app management, and security services for businesses of all sizes. Intune provides several policy and profile templates that you can use to enable and manage BitLocker on Windows 10 and Windows 11 devices.
You should not recommend using Microsoft Endpoint Configuration Manager (ECM). ECM is an on- premises platform that can be used to manage PCs, mobile devices, and servers. Administrators can use ECM to distribute software updates, patches, and applications, configure settings and security policies, and track the location of devices on the network. ECM cannot be used to manage BitLocker on Azure VMs.
You should not recommend using Azure Storage Server-Side Encryption (SSE). SSE automatically encrypts data in Azure using Advanced Encryption Standard (AES) 256-bit encryption. SSE is enabled by default and it cannot be disabled. SSE is not manageable at the operating system (OS) level.
You should not recommend using Microsoft Defender for Storage. Defender for Storage can be used to protect Azure Storage resources from malware and other threats.

---

### References

[Manage BitLocker policy for Windows devices with Intune](https://learn.microsoft.com/en-us/mem/intune/protect/encrypt-devices)  
[Plan for BitLocker management](https://learn.microsoft.com/en-us/mem/configmgr/protect/plan-design/bitlocker-management) 
[Server-side encryption of Azure Disk Storage](https://learn.microsoft.com/en-us/azure/virtual-machines/disk-encryption)  
[Enable and configure Microsoft Defender for Storage](https://learn.microsoft.com/en-us/azure/defender-for-cloud/defender-for-storage-introduction)  

---

## Q082:

Your company has a Microsoft Defender for Business subscription. All employees have company-provided laptops running one of the following operating systems:

- Windows 11
- Windows 10 (version 1607) or later

You need to recommend a secure internet access design.
Which security control should you include in your recommendation for each security requirement? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

Block access to social networking and chat sites:
Web content filtering

Block access to phishing sites:
Web threat protection

---

### Answer:

To block access to social networking and chat sites, you should recommend using web content filtering. Web content filtering is the process of blocking, censoring, or monitoring internet content. Schools and businesses often use web content filters to block inappropriate content from being accessed by students or employees. Microsoft Defender content filtering can be used to restrict access to websites that contain pornography, violence, racism, homophobia or other objectionable or undesirable material. Content filtering policies identify blocked content based on categories.
To block access to phishing sites, you should recommend using web threat protection. Web threat protection is a process or technique used to protect web-based systems and applications from malware or other malicious activity. Microsoft Defender uses machine learning (ML) and other advanced techniques for identifying sites that contain malware or exploits, are known phishing sites, or otherwise have a low reputation.
You should not recommend using custom indicators. You can use custom indicators to block content based on parameters you specify. For example, you could block a known malicious file based on the file's hash.

---

### References

[Web content filtering](https://learn.microsoft.com/en-us/defender-endpoint/web-content-filtering)  
[Protect your organization against web threats](https://learn.microsoft.com/en-us/defender-endpoint/web-threat-protection)  
[Create indicators](https://learn.microsoft.com/en-us/defender-endpoint/manage-indicators)

---

## Q081:

Your company uses baselines to ensure a strong security posture on server and client endpoints. Microsoft releases a posture update that includes settings that address recent ransomware infection tools, tactics, and procedures. You have tested the proposed settings and verified that there are no changes that will negatively impact operations.
You need to make a recommendation to the security administration team about what to use in order to deploy the updated baseline across the enterprise.

What should you recommend?

Choose the correct answer

- Microsoft Intune
- Microsoft Purview
- Microsoft Operational Security Assurance (OSA)
- Windows Autopilot

---

### Answer:
- Microsoft Intune

You should recommend using Microsoft Intune to deploy the updated baseline enterprise-wide. Microsoft security baselines are predefined settings that provide a secure configuration for computers in your organization. Security baselines include recommended rules, policies, and configurations for the operating system, applications, and devices. Microsoft maintains security baselines for Windows 10 and 11, Windows Server, Microsoft Office, and Microsoft Edge. You can also create your own custom security baselines, or copy and modify the Microsoft baselines to fit your organization's specific needs. Microsoft Intune is the component that Microsoft Endpoint Manager uses for Mobile Device Management (MDM).
You should not recommend using Windows Autopilot. Windows Autopilot is a zero-touch deployment solution for fleets of devices. With Windows Autopilot, the bulk of the deployment process is handled by Microsoft and your devices are automatically configured with the appropriate settings after they have been connected to the network. Autopilot is not used to manage security baselines.
You should not recommend using Microsoft Purview. Purview is a Microsoft service that helps organizations to manage and protect their data. It provides centralized data discovery and cataloging capabilities that can help your company to ensure compliance with regulations such as the General Data Protection Regulation (GDPR). Purview also includes features for data classification and risk assessment, making it a comprehensive solution for data governance.
You should not recommend using the Microsoft Operational Security Assurance (OSA) framework. OSA is a set of best practices for guidance in increased operational security in cloud-based deployments. The OSA framework supplements Azure trust principles and it can be used by organizations to assess their current state of operational security, identify gaps, and prioritize remediation efforts.

---

### References

[Updating your Security baselines in Microsoft Endpoint Manager to a newer version](https://www.vansurksum.com/2021/02/04/updating-your-security-baselines-in-microsoft-endpoint-manager-to-a-newer-version/) 
[Overview of Windows Autopilot](https://www.vansurksum.com/2021/02/04/updating-your-security-baselines-in-microsoft-endpoint-manager-to-a-newer-version/)  
[What's available in the Microsoft Purview governance portal?](https://learn.microsoft.com/en-us/purview/governance-solutions-overview)  
[Microsoft Operational Security practices](https://learn.microsoft.com/en-us/purview/governance-solutions-overview)  

---

## Q080:

Your company receives a letter from an auditor indicating that many user endpoints lack the configurations required for regulatory compliance. The auditor has granted a 60-day remediation window, beyond which your company will incur weekly fines until compliance is met.

You need to recommend a solution that meets the following requirements:

- Framework-based standards must be enforced across all production Windows 10 and Windows 11 systems.
- Non-production test devices on segmented networks should be excluded from the enforcement.
- Administrative overhead must be minimized.

Which solution should you recommend?

Choose the correct answer

- Deploy baselines using the Policy Analyzer.
- Create and deploy profiles in Intune.
- Set security descriptors with the SCT.
- Import framework settings using LGPO.

---

### Answer:
- Create and deploy profiles in Intune.
You should recommend creating and deploying profiles in Intune. Intune profiles can be used to deploy and manage security baselines for Windows 10 and Windows 11 devices. These baselines are based on industry-accepted security frameworks and have been tested by Microsoft. Baselines include Group Policy and other system settings that can be applied to both new and existing systems. To deploy Intune profiles, sign in to Microsoft Endpoint Management and access Endpoint security > Security baselines.
You should not recommend setting security descriptors using the Security Compliance Toolkit (SCT). The SCT is a set of tools and guides that helps organizations to assess, benchmark, and deploy Microsoft security technologies. It is designed to help organizations simplify and streamline their security evaluation and deployment processes, by providing a centralized location for all of the resources that they need. The kit includes tools for threat modeling, security best practices checklists, assessment tools, and more. As it relates to this scenario, the SCT provides tools for designing and testing security-related settings, but it is not used to deploy and manage those settings.
You should not recommend deploying baselines using the Policy Analyzer. The Group Policy Analyzer is a free, open-source tool that helps you to visualize, analyze, and troubleshoot Group Policy Objects (GPOs). It allows you to view the resulting settings of a GPO and compare a system against a baseline. As it is a stand- alone tool, Policy Analyzer is only used to evaluate and test settings on a single computer. It is not used to widely distribute and manage GPOs. Policy Analyzer is part of the SCT.
You should not recommend importing framework settings using the Local Group Policy (LGPO) utility. It is not possible to effectively use LGPO to widely distribute GPOs. The LGPO.exe command-line tool is designed to manage Local Group Policy, which is Group Policy on a single machine. LGPO is part of the SCT.

---

### References

[Use security baselines to configure Windows devices in Intune](https://learn.microsoft.com/en-us/mem/intune/protect/security-baselines)  
[Security baselines](https://learn.microsoft.com/en-us/windows/security/operating-system-security/device-management/windows-security-configuration-framework/windows-security-baselines)
[Microsoft Security Compliance Toolkit - How to use](https://learn.microsoft.com/en-us/windows/security/operating-system-security/device-management/windows-security-configuration-framework/security-compliance-toolkit-10)  
[New & Updated Security Tools](https://techcommunity.microsoft.com/t5/microsoft-security-baselines/new-amp-updated-security-tools/ba-p/1631613)  

---

## Q079:

Reset Options Hide Answer
Your company deploys Azure-based virtual machines (VMs) for use by cloud administrators. All VMs run Windows 11. Administrators must be able to access the instances remotely so that they can manage other Azure resources. However, access to the VMs over port 3389 has been expressly forbidden. You deploy Azure Bastion on the same virtual network (VNet) as the VMs.

What should you recommend for users to do next?

Choose the correct answer

- Connect to a target virtual machine (VM) via the Azure portal.
- Create an OpenVPN connection to Bastion.
- Create a Secure Socket Tunneling Protocol (SSTP) connection to a target virtual machine (VM).
- Connect to a target virtual machine (VM) using mstsc.exe.

---

### Answer:
- Connect to a target virtual machine (VM) via the Azure portal.

You should recommend connecting to a target virtual machine (VM) via the Azure portal. This will use Azure Bastion, which provides secure, Transport Layer Security (TLS) protected remote access to your Azure VMs from anywhere in the world. Bastion enables you to establish a secure connection to your VMs without having to deploy and manage a Virtual Private Network (VPN) or expose VMs with public IP addresses. In this scenario, once Bastion has been deployed, administrators can connect to the Bastion host using TLS, where they will have Remote Desktop Protocol (RDP) connectivity to the Azure VMs.
You should not recommend creating a Secure Socket Tunneling Protocol (SSTP) connection to a target VM. SSTP is a type of VPN protocol that uses TLS for tunneling. SSTP is used to connect to a VPN gateway, not to Azure Bastion.
You should not recommend creating an OpenVPN connection to Bastion. OpenVPN is an open-source project that includes a VPN client. OpenVPN is not used to connect to Azure Bastion.
You should not recommend connecting to a target VM using mstsc.exe. Mstsc.exe is the executable for the Microsoft Remote Desktop Protocol (RDP) client. In this question, connectivity to the default RDP port, 3389, has been blocked.

---

### References

[Create an RDP connection to a Windows VM using Azure Bastion](https://learn.microsoft.com/en-us/azure/bastion/bastion-connect-vm-rdp-windows)  
[What is Azure Bastion?](https://learn.microsoft.com/en-us/azure/bastion/bastion-overview)  
[What Is SSTP?](https://www.proofpoint.com/us/threat-reference/sstp)  
[mstsc](https://learn.microsoft.com/en-us/windows-server/administration/windows-commands/mstsc)  

---

## Q078:

Your company provides remote workers with laptops. An auditor reports that the laptops do not meet the minimum security requirements defined by Azure security benchmarks. As a result, the company purchases Microsoft Defender for Endpoint licenses.
You need to implement a secure endpoint configuration strategy that meets the following requirements:

- Users must be protected from web-based threats.
- Protection for Microsoft Edge, Firefox, and Chrome must be provided.
- Users must be prevented from accessing exploit and phishing sites.
- Devices must be protected wherever they are connected.

What should you do?

Choose the correct answer

- Enable network protection.
- Configure a proxy server.
- Deploy web protection.
- Create custom indicators.

---

### Answer:
- Enable network protection.

You should enable network protection. Network protection is part of the Microsoft Defender for Endpoint platform. Network protection protects users from accessing domains that host malicious content or that have poor scores for their reputation. This includes phishing sites and sites known to host malware or other exploits. Network protection can also identify and block behavior related to known indicators of compromise (loCs), such as command and control (C2) attacks.
You should not create custom indicators. You can use custom indicators in Microsoft Defender for Endpoint to block access to specific domains or Uniform Resource Locators (URLs), to block unknown or untrusted certificates, or to detect and block specific files.
You should not deploy web protection. Web protection relies on network protection to protect browser activity. You can enable web protection by creating a web protection profile in the Endpoint Manager admin center.
You should not configure a proxy server. Unlike many web protection services, Defender for Endpoint does not rely on proxy servers to scan and filter traffic. Protection happens on the endpoint and protects browser and application traffic.

---

### References

[Protect your network](https://learn.microsoft.com/en-us/defender-endpoint/network-protection)  
[Create indicators](https://learn.microsoft.com/en-us/defender-endpoint/manage-indicators)  
[Protect your organization against web threats](https://learn.microsoft.com/en-us/defender-endpoint/web-threat-protection)
[Microsoft Defender for Endpoint](https://learn.microsoft.com/en-us/defender-endpoint/microsoft-defender-endpoint)  

---

## Q077:

Your company migrates a legacy HR management system to Azure-based virtual machines (VMs) that run a custom web server. You receive an alert that a would-be attacker has attempted a downgrade attack against the system.
You need to identify a mitigation solution. Data-in-motion must be protected.
What should you do to meet these requirements?

Choose the correct answer

- Configure input validation.
- Disable TLS 1.0 support.
- Rekey SSL certificates.
- Implement challenge tokens.

---

### Answer:
- Disable TLS 1.0 support.

You should disable Transport Layer Security (TLS) 1.0 support. Downgrade attacks take advantage of a vulnerability in the way that Secure Sockets Layer (SSL) 3.0 and TLS 1.0 encrypt data. These types of attack work by intercepting the encrypted data as it is being transmitted between the client and server, and then decrypting it in order to read it. TLS 1.2 is immune to downgrade attacks.
You should not configure input validation. Input validation is used to ensure that data entered on a web form does not include illegal characters or other malicious content. Input validation can be used to mitigate Cross-Site Scripting (XSS), buffer overflow, and other attacks. Services like Azure - Application gateway and Azure Front Door can be used to enforce input validation.
You should not identify the rekeying of SSL certificates. Certificate rekeying is the process of renewing a digital certificate with a new key pair. This is done to maintain the security of the certificate and to keep the private key from becoming compromised. Rekeying can also be done to change the algorithms used by the certificate.
You should not implement challenge tokens. Challenge tokens are used to mitigate attacks like cross-site request forgery (CSRF). In CSRF, an attacker lures a user into clicking on a malicious link while the user is logged on to a target website. Challenge tokens ensure that a request is originated by a user and not a malicious link.

---

### References

[What is a downgrade attack and how to prevent it](https://encyclopedia.kaspersky.com/glossary/downgrade-attack/#:~:text=A%20downgrade%20attack%20is%20an,in%2Dthe%2Dmiddle%20attack.)  
[Input Validation Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Input_Validation_Cheat_Sheet.html)  
[Rekey a Certificate](https://sslmate.com/help/cmdline/rekey_revoke)  
[Cross-Site Request Forgery Prevention Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html)  


---

## Q076:

You are a Solution Architect for an organization that is planning the migration of all its workloads and resources to an Azure subscription that includes PaaS and laaS services.
Before the migration you need to ensure that the tenant meets not only Microsoft best practices but security best practices as well. You plan to use the Microsoft Cloud Security Benchmark controls in order to meet security best practices.
The first control you need to implement is protection of identity and authentication systems.
Which three common security controls should you implement to achieve this? Each correct answer presents part of the solution.

Choose the correct answers

- Monitor and audit strong authentication for all privileged access.
- Restrict privileged roles and accounts.
- Monitor and audit high risk activities.
- Use managed application identities.
- Enforce strong passwordless authentication.

---

### Answer:
- Monitor and audit strong authentication for all privileged access.
- Restrict privileged roles and accounts.
- Monitor and audit high risk activities.

Identity management (IM) controls are part of the Microsoft Cloud Security Benchmark, and are just one of the many security controls you need to address. Protecting identity and authentication systems is the IM-2 security principle, which includes the following common security controls:

- Restrict privileged roles and accounts
- Require strong authentication for all privileged access
- Monitor and audit high risk activities

Using managed application identities is the security principle from IM-3: Manage application identities securely and automatically.
Enforcing strong passwordless authentication controls is the security principle from IM-6: Use Strong authentication controls.

---

### References

[Security Control: Identity management](https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-identity-management)  
[Evaluate security postures by using benchmarks](https://learn.microsoft.com/en-us/training/modules/design-solutions-security-posture-management-hybrid-multicloud-environments/)  

---

## Q075:

Your company uses on-premises SQL Servers. To reduce costs and management overhead, the company plans to migrate these databases to Azure. Based on an initial analysis of how each database is used, you have recommended the use of the following Azure services:
• Azure SQL Database
• Azure SQL Managed Instance
You need to evaluate and identify methods for enhancing database security for data that will be stored in the Azure databases.
Which feature should you implement to ensure that your company's databases are secure? To answer, drag the appropriate feature to each requirement. Each feature may be used once, more than once, or not at all.

Drag and drop the answers

Always Encrypted
Ledger
TDE
TDS

To encrypt data and log files
TDE

To maintain a history of all database changes over time
Ledger

To prevent database admins from accessing sensitive data
Always Encrypted

---

### Answer:

To encrypt data and log files, you should recommend implementing Transparent data encryption (TDE). TDE is a data security feature that encrypts sensitive data in SQL Server databases. TDE works by encrypting database content at the page level, prior to writing the pages to disk, which prevents unauthorized access to the data. TDE is available in all editions of SQL Server 2016 and higher, including Azure-hosted SQL Databases and SQL Managed Instances.
To maintain a history of all database changes over time, you should recommend implementing ledger. Ledger uses cryptographic algorithms to ensure database integrity. All historical changes are stored in a ledger table and this information can be used for future auditing.
To prevent database admins from accessing sensitive data, you should recommend implementing Always Encrypted. Always Encrypted protects data by encrypting and decrypting it at the client. This means the data is encrypted before it is sent to the SQL database engine. As a result, even database administrators and other privileged system users cannot read the data.
You should not recommend implementing Tabular Data Stream (TDS). TDS is a communication protocol used by data-centric applications to transfer data between systems. Microsoft SQL implementation uses TDS to facilitate client-to-server connectivity.

---

### References

[Transparent data encryption (TDE)](https://learn.microsoft.com/en-us/sql/relational-databases/security/encryption/transparent-data-encryption?view=sql-server-ver16)  
[Ledger overview](https://learn.microsoft.com/en-us/sql/relational-databases/security/ledger/ledger-overview?view=sql-server-ver16)  
[TDS 8.0](https://learn.microsoft.com/en-us/sql/relational-databases/security/networking/tds-8?view=sql-server-ver16)  

---

## Q074:

Your company has Defender for Cloud - Apps and Azure Active Directory P1 licenses. Additionally, your company uses Azure AD as its sole IdP. In response to recent account breaches, you have been asked to design a security solution that mitigates the risks associated with cloud application usage.
You need to recommend a solution that controls data travel and identifies application risks before they lead to data loss.
What Defender for Cloud - Apps component should you use for each security control requirement? To answer, drag the appropriate component to the matching security control requirement. Each component may be used once, more than once, or not at all.

Drag and drop the answers

Anomaly detection policy
Cloud Discovery
Conditional Access - App Control
Data encryption policy

To prevent the downloading of sensitive documents on unmanaged devices
Conditional Access - App Control

To create an app risk report based on uploaded firewall logs
Cloud Discovery

To identify logons to an account that may indicate impossible travel
Anomaly detection policy

---

### Answer:

Conditional Access - App Control can be used to prevent downloading of sensitive documents on unmanaged devices. Microsoft Defender for Cloud - Apps is a Cloud Access Security Broker (CASB) platform that can be used to protect Azure and other cloud resources. It provides you with the ability to centrally manage and monitor the security of your cloud apps, as well as to investigate and respond to incidents. The Conditional Access - App Control component uses reverse proxy technology to mediate access to your organization's resources. This component can identify files that contain sensitive information and can prevent those files from being downloaded on unmanaged devices that may not be properly secured.
Cloud Discovery can be used to create an app risk report based on uploaded firewall logs. Cloud Discovery ingests point-in-time or real-time traffic logs from firewalls and proxy servers. Cloud Discovery then analyzes the traffic and identifies the apps that your users are using to access the internet. Each app is
scored based on known risk factors that the app introduces to your organization.
Anomaly detection policy can be used to identify logons to an account that may indicate impossible travel. Defender for Cloud - Apps performs User and Entity Behavior Analytics (UEBA) to detect anomalous user behavior that may indicate malicious activity. Anomaly detection is a powerful security control that measures activity against a behavior baseline. For example, if a user normally logs on between the hours of 9:00 AM and 9:00 PM, then suddenly logs on from a new Internet Protocol (IP) address at 3:00 AM, Defender for Cloud - Apps can be configured to generate an alert.
You should not use data encryption policy (DEP) in these situations. A DEP defines a key hierarchy that is used to encrypt your data in Microsoft 365 or other Microsoft cloud services.

---

### References

[Protect apps with Microsoft Defender for Cloud - Apps Conditional Access - App Control](https://learn.microsoft.com/en-us/defender-cloud-apps/proxy-intro-aad)  
[Set up Cloud Discovery](https://learn.microsoft.com/en-us/defender-cloud-apps/set-up-cloud-discovery)  
[Anomaly detection policies in Defender for Cloud - Apps](https://learn.microsoft.com/en-us/defender-cloud-apps/anomaly-detection-policy)  
[Manage Customer Key](https://learn.microsoft.com/en-us/purview/customer-key-manage)  

---

## Q073:

Your company has Azure subscriptions that are used in testing and production environments. You have been asked what your company can do to increase the Secure Score for the production environments.
Your security team provides the results of a security audit and you need to review the findings and determine how they might impact your Secure Score.
For each of the following statements, select Yes if the statement is true. Otherwise, select No.


Using customer-managed keys to encrypt data in SQL Managed Instances will improve your Secure Score.
No

Changing an improvement action to the Risk accepted status will NOT reduce your Secure Score.
Yes

Based on Secure Score, you can use Defender for Cloud to automatically delete resources with security misconfigurations.
No

---

### Answer:

Using customer-managed keys (CMKs) to encrypt data in SQL Managed Instances will not improve your Secure Score. SQL supports transparent data encryption (TDE), which is a data security feature that encrypts sensitive data in SQL Server databases. TDE works by encrypting database content at the page level, prior to writing the pages to disk, which prevents unauthorized access to the data. Although using CMKs with TDE increases data security, it will not improve your Secure Score.
Changing an improvement action to the Risk accepted status will not reduce your Secure Score. Accepting a risk indicates that you have evaluated the improvement action and have determined that the cost or complexity of implementing a control is too high, or that the control is not needed.
Based on Secure Score, you cannot use Defender for Cloud to automatically delete resources with security misconfigurations. Defender for Cloud can be used to enforce remediation steps for security misconfigurations, but it will not delete resources.

---

### References

[Secure score](https://learn.microsoft.com/en-us/azure/defender-for-cloud/secure-score-security-controls)   
[Azure SQL transparent data encryption with customer-managed key](https://learn.microsoft.com/en-us/azure/azure-sql/database/transparent-data-encryption-byok-overview?view=azuresql)  
[Assess your security posture with Microsoft Secure Score](https://learn.microsoft.com/en-us/defender-xdr/microsoft-secure-score-improvement-actions)  

---

## Q072:

You use Microsoft Defender for Cloud to evaluate the security posture of your company's Azure deployments.
You need to determine how the recommended mitigations or controls will impact the posture.
Which Secure Score component will each recommendation improve? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

Configure services to listen only on allowed ports: 
Restrict unauthorized network access.

Implement JIT network accesscontrol: 
Secure management ports.

Place VMs in NSGs: Secure management ports.

Protect VNets with Azure Firewall: Restrict unauthorized network access.

---

### Answer:

Microsoft Defender for Cloud is a security service that helps to protect your organization's data and devices, not only in Azure, but also on-premises and with other cloud providers such as Google and AWS. It provides comprehensive protection against malware, advanced threats, and malicious activity. Its security recommendations feature provides prioritized recommendations that can result in security score improvements for your company's cloud resources.
Configuring services to listen only on allowed ports will improve your "restrict unauthorized network access" Secure Score component. Using non-standard service ports complicates configuration. Additionally, a service may inadvertently be configured to use a port that is less protected at the network border.
Implementing just-in-time (JIT) network access control will improve your "secure management ports" Secure Score component. With JIT, every access attempt to specified ports on a VM must be approved manually. Each request comes with a lifespan, after which the ports are no longer reachable.
Placing VMs in network security groups (NSGs) will improve your "secure management ports" Secure Score component. An NSG is a virtual networking element that enables you to control the inbound and outbound traffic to resources in a virtual network using IP addresses, protocols, and ports. NSGs can be used to close off parts of your network to all traffic, or they can be used to allow specific types of traffic while blocking all other traffic.
Protecting VNets with Azure Firewall will improve your "restrict unauthorized network access" Secure Score component. Azure Firewall is a Next-Generation Firewall (NGFW) with full Intrusion Prevention System (IPS) capabilities.

---

### References

[Secure score](https://learn.microsoft.com/en-us/azure/defender-for-cloud/secure-score-security-controls)  
[Implement Just-in-time VM access](https://learn.microsoft.com/en-us/training/paths/manage-security-operations-new/)  
[Create, change, or delete a network security group](https://learn.microsoft.com/en-us/azure/virtual-network/manage-network-security-group?tabs=network-security-group-portal)  
[What is Azure Firewall?](https://learn.microsoft.com/en-us/azure/firewall/overview)  

---

## Q071:

You have Azure and Microsoft 365 subscriptions. Additionally, you use Microsoft Defender for Cloud - Apps to protect resources in your multi-cloud environment. You have configured Microsoft Sentinel to ingest data from Azure-based and non-Azure-based log sources. You want to ensure that your security team is alerted when Sentinel detects different types of potentially malicious behavior. Specifically, you need to track the following:
Seemingly innocuous events that may indicate exploit chaining.
• Events generated by other security platforms, such as Microsoft Defender.
Any other potentially suspicious behaviors.
You need to solve a series of situations by creating threat detection rules in Microsoft Sentinel.
Which rule template should you use for each situation? To answer, select the appropriate rule templates from the drop-down menus.

Choose the correct options

Correlate low-impact events and alerts:
Fusion

Process alerts generated by Defender for Cloud - Apps: 
Microsoft Security

Detect a user logging in after hours:
Anomaly

---

### Answer:

To correlate low-impact events and alerts, you should use a Fusion rule template. Fusion uses artificial intelligence (AI) and machine learning (ML) to correlate suspicious activities. Al and ML algorithms analyze data from multiple sources (including Azure Active Directory, Security Center, and other Microsoft services) to correlate events and alerts which, individually, may not indicate a compromise. Many advanced attackers use a tactic known as exploit chaining that follows the pattern of multiple minor activities that collectively lead to a major breach.
To process alerts generated by Defender for Cloud - Apps, you should use a Microsoft Security rule template. This allows Sentinel to create incidents using alert input from other Microsoft security products and platforms.
To detect a user logging in after hours, you should use an Anomaly rule template. Anomalous behavior is behavior that is out of the ordinary for a user or system. Sentinel uses Anomaly rules to identify patterns of behavior that could indicate a security incident. These behaviors may not be covered by existing rules and would otherwise go unnoticed.
You should not use a near-real-time (NRT) rule template. NRT rules are checked every minute. These are designed to generate alerts as close to real-time as possible. This is useful in scenarios where an immediate incident response may significantly reduce the impact of an event.


---

### References

[Advanced multistage attack detection in Microsoft Sentinel](https://learn.microsoft.com/en-us/azure/sentinel/fusion)  
[Automatically create incidents from Microsoft security alerts](https://learn.microsoft.com/en-us/azure/sentinel/create-incidents-from-alerts)  
[Use customizable anomalies to detect threats in Microsoft Sentinel](https://learn.microsoft.com/en-us/azure/sentinel/soc-ml-anomalies)  
[Detect threats out-of-the-box](https://learn.microsoft.com/en-us/azure/sentinel/threat-detection)  
[What is Microsoft 365 Defender?](https://learn.microsoft.com/en-us/defender-xdr/microsoft-365-defender?view=o365-worldwide)  

---

## Q070:

Your company has an Azure subscription. To assess your cloud infrastructure compliance, you enable Microsoft Defender for Cloud with enhanced security features for your company's subscription.
You need to ensure that when compliance assessment fails, the Information Security Officer is notified via email.
Which two steps should you complete to meet this requirement? Each correct answer presents part of the solution.

Choose the correct answers

- Create a logic app.
- Create a dashboard.
- Add a workflow automation.
- Define a policy.
- Enable a recommendation.

---

### Answer:
- Create a logic app.
- Add a workflow automation.

You should create a logic app and add a workflow automation. Microsoft Defender for Cloud is a security service that helps protect your organization's data and devices not only in Azure, but on-premises and with other cloud providers like Google and AWS, as well. By creating a logic app in Azure Logic - Apps, you can configure a Defender for Cloud workflow automation to trigger on a compliance assessment failure and run the specified app.
You do not need to create a dashboard. Defender for Cloud includes a pre-defined regulatory compliance dashboard that reports on the continuous environment assessments it performs automatically.
You should not define a policy. An Azure policy is a rule, or policy definition that you can use to control how resources are created and configured in Azure.
You should not enable a recommendation. Defender for Cloud can evaluate your infrastructure against the policies you have defined and provide recommendations for remediating any vulnerabilities or misconfigurations that are discovered.

---

### References

[Tutorial: Improve your regulatory compliance]()
[What is Azure Logic - Apps?](https://learn.microsoft.com/en-us/azure/logic-apps/logic-apps-overview)  
[Automate responses to Microsoft Defender for Cloud triggers](https://learn.microsoft.com/en-us/azure/defender-for-cloud/workflow-automation)  
[Understand Azure Policy effects](https://learn.microsoft.com/en-us/azure/governance/policy/concepts/effect-basics)  

---

## Q069:

Your company has Microsoft 365 and Azure subscriptions. Recently, your company acquired a subsidiary that processes sensitive Protected Health Information (PHI) in an on-premises data center.
You need to design a secure, compliant Azure architecture that can be used to host some components of the subsidiary's platform, including VMs and containers. Compliance must be assessable and enforceable on an ongoing basis.
Which recommendation should you include in your design?

Choose the correct answer

- Minimize complexity by hardening nodes with a common configuration.
- Deploy and configure host-based firewalls on all VMs and containers.
- Evaluate each component using a framework-based benchmark.
- Install and configure endpoint detection and response (EDR) on each node.

---

### Answer:
- Evaluate each component using a framework-based benchmark.

You should recommend evaluating each component using a framework-based benchmark. You can do this by enabling Microsoft Defender for Cloud for your Azure subscription. Defender for Cloud is a security service that can protect your organization's data and devices not only in Azure, but on-premises and with other cloud providers like Google and AWS. This service includes a regulatory compliance dashboard that continually assesses and reports compliance with framework-based benchmarks, including the National Institute of Standards and Technology (NIST) and others.
You should not recommend minimizing complexity by hardening nodes with a common configuration. Unless nodes host the same content and are essentially clones of one another, they should not use a common configuration. Defender for Cloud can assist with identifying and remediating misconfigurations that lead to vulnerabilities.
You should not recommend deploying and configuring host-based firewalls on all VMs and containers. This approach could be part of a defense-in-depth security architecture. However, a firewall alone will not ensure a system's security or regulatory compliance. Azure Firewall and network security groups (NSGs) can be used to project VMs, containers, and other Azure resources.
You should not recommend installing and configuring endpoint detection and response (EDR) on each node. Like host-based firewalls, EDR is an important part of a defense-in-depth strategy. However, EDR alone will not ensure compliance checking and enforcement. Microsoft Defender for Endpoint can provide EDR functionality.

---

### References

[Tutorial: Improve your regulatory compliance](https://learn.microsoft.com/en-us/azure/defender-for-cloud/regulatory-compliance-dashboard)  
[Manage your cloud security posture with Microsoft Defender for Cloud](https://learn.microsoft.com/en-us/training/modules/m365-security-azure-security-center/manage-cloud-posture)  
[Azure Firewall vs Network Security Group (NSG)](https://darawtechie.com/2019/09/05/azure-firewall-vs-network-security-group-nsg/)  
[Microsoft Defender for Endpoint](https://learn.microsoft.com/en-us/defender-endpoint/microsoft-defender-endpoint)  


---

## Q068:

Your company deploys resources with multiple cloud providers, including Azure and AWS. The security team utilizes Microsoft Defender for Endpoint and Microsoft Defender for Cloud - Apps to protect both these cloud resources and the employees who access them. As the security team manager, you have been alerted to an incident in which a polymorphic virus has infiltrated a file server VM and is infecting local files.
Which phase of the incident response cycle should your team activate?

Choose the correct answer

- Analysis
- Postmortem
- Preparation
- Containment

---

### Answer:
- Containment

Your team should activate the containment phase of the incident response lifecycle. During this phase you take steps to isolate the affected systems, therefore limiting the damage that can be caused by the incident. This may involve taking systems offline, quarantining files, or performing other measures to prevent the further spread of the problem. The goal is to contain the incident and minimize its impact. In this scenario, the infected VM should be disconnected from the network. Depending on the framework used, the containment phase may or may not include eradication and recovery components.
Your team should not activate the postmortem phase. The postmortem phase is when organizations analyze what went well and what did not go well during their response to a security incident. This analysis can help organizations to improve their processes and ensure that they are better prepared for future incidents. It is also important to review and learn from near misses, as these can provide valuable warning signs that an organization's security posture may be at risk. This phase is also referred to as the lessons-learned or post- incident activity phase.
Your team should not activate the analysis phase. The analysis phase is when you attempt to identify what happened and what caused it. This is usually done by looking at system logs, application logs, and any other potentially relevant data. Once you have a good idea of what happened, you can start working on containing the damage and preventing further harm.
Your team should not activate the preparation phase. In the preparation phase, you should take steps to establish an incident response team and develop clearly defined roles and responsibilities for each member of the team. During this phase, you will also define incident response processes and procedures.

---

### References

[Microsoft security incident management: Post-incident activity](https://learn.microsoft.com/en-us/compliance/assurance/assurance-sim-post-incident-activity)  
[Security Control v3: Incident response](https://learn.microsoft.com/en-us/security/benchmark/azure/security-controls-v3-incident-response)  
[Incident response with Microsoft 365 Defender](https://learn.microsoft.com/en-us/defender-xdr/incidents-overview)  
[Investigate incidents in Microsoft 365 Defender](https://learn.microsoft.com/en-us/defender-xdr/investigate-incidents)  
[What is Microsoft 365 Defender?](https://learn.microsoft.com/en-us/defender-xdr/microsoft-365-defender?view=o365-worldwide) 
[Microsoft Defender for Cloud - Apps overview](https://learn.microsoft.com/en-us/defender-cloud-apps/what-is-defender-for-cloud-apps)  

---

## Q067:

Your company uses a combination of on-premises, Google GCP, Amazon AWS, and Azure resources. You have recommended implementing Microsoft Defender for Cloud for Cloud Security Posture Management (CSPM). However, management has clarified their request to include a requirement for Azure to be used to provide customized system hardening tasks that can be sorted by priority.
You need to recommend a Microsoft Defender for Cloud feature that fulfills this requirement.

Which feature should you recommend?

Choose the correct answer

- Defender for Cloud security alerts
- Defender for Cloud security initiatives
- Defender for Cloud security recommendations
- Defender for Cloud secure scores

---

### Answer:
- Defender for Cloud security recommendations

You should recommend using Defender for Cloud security recommendations. Microsoft Defender for Cloud is a security service that helps protect your organization's data and devices not only in Azure, but on- premises and with other cloud providers like Google and AWS. It provides comprehensive protection against malware, advanced threats, and malicious activity. Security recommendations give prioritized recommendations that can provide measure security score improvements for your company's cloud resources.
You should not recommend using Defender for Cloud secure scores. A secure score is a metric that provides a percentage-based score to represent the security posture of your organization's cloud environment. Security scores are simple, point-in-time calculations.
You should not recommend using Defender for Cloud security alerts. Defender for Cloud gathers log and other information from all the sources you specify. Defender then uses advanced analysis to detect threats and generate actionable alerts.
You should not recommend using Defender for Cloud security initiatives. Initiatives are Azure Policy collections used to support a cloud security goal. By grouping initiatives, you can track and manage complex configuration tasks more easily.

---

### References

[Find recommendations that can improve your security posture](https://learn.microsoft.com/en-us/azure/defender-for-cloud/review-security-recommendations)  
[Secure score](https://learn.microsoft.com/en-us/azure/defender-for-cloud/secure-score-security-controls)  
[Manage and respond to security alerts in Microsoft Defender for Cloud](https://learn.microsoft.com/en-us/azure/defender-for-cloud/managing-and-responding-alerts)
[What are security policies, initiatives, and recommendations?](https://learn.microsoft.com/en-us/azure/defender-for-cloud/security-policy-concept)  


---

## Q066:

Your company deploys cloud workloads in Azure and multi-tenant public clouds. You have to migrate a sensitive on-premises application to the cloud. However, management is concerned about process level security on the database and transaction processing servers given that these cloud resources are hosted on shared hypervisors.
You need to design a solution that mitigates this risk.
Which recommendation should you include in your design?

Choose the correct answer

- Move sensitive processes to a trusted execution environment (TEE) platform.
- Deploy Azure web application firewall (WAF) and ensure that Open Web - Application Security Project (OWASP) core rule sets are enabled.
- Move all database and transaction processing servers to the same network security group (NSG).
- Implement managed Hardware Security Module (HSM) pools for servers running sensitive processes.

---

### Answer:
- Move sensitive processes to a trusted execution environment (TEE) platform.


You should recommend moving sensitive processes to a trusted execution environment (TEE) platform. A TEE platform is a form of security enclave in which running processes and their associated memory storage locations are isolated and data in use is encrypted. Trusted execution is a feature available on modern processors. Modern hypervisors also support virtual machine isolation using trusted execution. Azure supports TEE via its Software Guard Extension (SGX) enclaves service.
You should not recommend implementing managed Hardware Security Module (HSM) pools for servers running sensitive processes. An HSM is a physical device, typically a computer or an embedded system, which performs cryptographic functions, such as authentication, digital signing, encryption, key storage and management, and protected communications. HSMs are used in applications where these security operations are critical to the safety or privacy of the data. Azure Key Vault offers a managed HSM service.
You should not recommend deploying Azure web application firewall (WAF) and ensuring that Open Web - Application Security Project (OWASP) core rule sets are enabled. Azure WAF can protect web applications from common exploits using OWASP's core rule sets. These rules detect and block attacks such as path traversal and cross-site scripting (XSS).
You should not recommend moving all database and transaction processing servers to the same network security group (NSG). An NSG is a virtual networking element that enables you to control the inbound and outbound traffic to resources in a virtual network using IP addresses, protocols, and ports. NSGs can be used to close off parts of your network to all traffic, or they can be used to allow specific types of traffic while blocking all other traffic.

---

### References

[SGX enclaves](https://lens.google.com/search?ep=subb&hl=en-IT&re=df&p=AbrfA8qT-_w_Pa6tBhMxNlyIQrvhVJwCZh6mjuxr2FyPezsIgzJgOv1xWEpI-Y5GRRdMkR1sfTm_s2GE8ozUYASaPfIOimzGfjHg830ZV8TnTeKvtwTM_QK06V3PlwpPbjRk9JeHUbpMhmUm2Hr-bjatmG36qn70CpOwjXl9ElGB95C5d8Je5EjXqUbXQJUmr75-SOFj3LR6HhcuiRYchDiJEIFXbgsAMOPCW7WRHsoXSuiWGAEMOsuJTUOLLS40LvG1gxdrejsTYH5nk8uG5FnasavF0WqZg8kGZLxWZtVa2rtCir-ohMpHBzCLp0oddvTR3LCaGQ%3D%3D#lns=W251bGwsbnVsbCxudWxsLG51bGwsbnVsbCxudWxsLG51bGwsIkVrY0tKR0ZsWkRkbU9XUXlMV1F6TXpFdE5Ea3hZUzA1TlRKaExUYzROMkUwTmpFMVlUUXlNQklmWXpsMmNVMXlVSEIyWkhOU1RVbG5SM0JuU1V4dVVESnZUSFV6TWtGNGF3PT0iLG51bGwsbnVsbCxudWxsLDIsbnVsbCxbbnVsbCxudWxsLG51bGwsW251bGwsW1szOTE5LDMzMDJdLFsyMTI1Nyw5Mzg3NV1dXV1d)  

[What is Azure Key Vault Managed HSM?](https://learn.microsoft.com/en-us/azure/key-vault/managed-hsm/overview)  
[Web - Application Firewall DRS and CRS rule groups and rules](https://learn.microsoft.com/en-us/azure/web-application-firewall/ag/application-gateway-crs-rulegroups-rules?tabs=drs21)  

[Network security groups](https://learn.microsoft.com/en-us/azure/virtual-network/network-security-groups-overview)  

---

## Q065:

Your organization has implemented defense in depth methodology by deploying Microsoft Defender for Endpoint on Azure VMs and by configuring Azure Firewall to filter the traffic that is sent between sensitive network subnets. However, due to a recent acquisition, employees are now communicating with VMs that are not hosted in Azure.
You need to ensure that the hybrid system stays secure by improving detection capabilities. This includes passively monitor the traffic sent between VMs.
Which technology or method should you recommend?

Choose the correct answer

- Micro-segmentation
- Network Terminal Access Point (TAP)
- Sandbox
- Port mirror

---

### Answer:
- Network Terminal Access Point (TAP)

You should recommend your organization to use an Azure virtual network Terminal Access Point (TAP) to passively monitor traffic sent between VMs. Azure virtual network TAP is a method of mirroring network traffic to a monitoring device for further analysis. The device, which is also known as a collector, typically uses packet capture (PCAP) technology to capture and record each network packet, including headers and payloads. This approach can be used to provide enhanced traffic analysis and intrusion detection without interrupting active flows.
You should not recommend your organization to use a port mirror. Port mirroring is a feature which is offered by physical network switches, firewalls, and other devices in which all traffic is copied from a source port to a destination port. On most physical network devices, port mirroring can be enabled by using the Switch Port Analyzer (SPAN) protocol.
You should not recommend your organization to use micro-segmentation. Micro-segmentation is an architecture where system components, processes, and network elements are physically or logically containerized. In Azure, VNets are the basic building block for network segmentation.
You should not recommend your organization to use a sandbox. Sandboxes provide an isolated environment that can be used in a variety of situations. For example, security analysts can use a sandbox to execute and then monitor the behavior of a suspicious file or application. Windows 10 and 11 support this method via the Windows Sandbox feature.

---

### References

[Virtual network TAP](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-tap-overview)  
[TAP vs SPAN](https://www.garlandtechnology.com/tap-vs-span)  
[Segmentation strategies](https://learn.microsoft.com/en-us/azure/well-architected/security/segmentation)  
[Windows Sandbox](https://learn.microsoft.com/en-us/windows/security/application-security/application-isolation/windows-sandbox/windows-sandbox-overview)  

---

## Q064:


Your company uses Microsoft Purview for data discovery, classification, and risk assessment. In response to new government regulations, the company plans to use Purview to manage compliance risks.
You need to explain the benefits and uses of Compliance Score.
How would you define each of the Compliance Score components? To answer, drag the appropriate component to the correct component definition. Each component may be used once, more than once, or not at all.

Drag and drop the answers

Assessment
Control
Group
Template


Component definition | Component

Defines how configurations, processes and people are managed
Control

Groups the actions that are required to fulfill a regulation, standard or law
Assessment

Organizes assessments by standard, organizational teams, or service
Group

---

### Answer:

A control defines how configurations, processes, and people are managed. As it relates to security and compliance, controls are used to mitigate risks, which in turn helps your organization to meet the requirements of a standard or regulation. Compliance Score calculates a score based on two control categories: Microsoft-managed controls and customer-managed controls. You can increase your compliance score through effective control implementation, configuration, and management.
An assessment groups the actions which are required to fulfill a regulation, standard or law. Assessments reference the service or services that are affected by a configuration, as well as the controls that ensure that the service or services are compliant.
A group organizes assessments by standard, organizational teams, or service. Groups make locating assessments easier. You can group assessments according to your chosen attributes: by team, year, standard, or service.
The template component is not used in this question. Templates are preconfigured assessments. You can use assessment templates as they are, or you can customize them for your organization.

---

### References

[Analyze the Microsoft compliance score](https://learn.microsoft.com/en-us/training/modules/explore-plan-compliance-microsoft-365/?ns-enrollment-type=learningpath&ns-enrollment-id=learn.wwl.implement-data-governance-microsoft-365-intelligence)  

[Compliance score calculation](https://learn.microsoft.com/en-us/purview/compliance-manager-scoring)    

[Microsoft Purview Compliance Manager](https://learn.microsoft.com/en-us/purview/compliance-manager)  


---

## Q063:

Your company uses Microsoft Defender for Cloud to monitor and maintain compliance for Azure-based workloads. Your company deploys resources in other hybrid-cloud environments and it has implemented a custom risk management system to allow compliance status tracking and remediation actions to be performed across these diverse environments.
You need to design a solution that facilitates the continuous export of regulatory compliance data.
Which export option should you recommend for each of the requirements stated below? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

Export at the resource group level:
Configure export by using the Defender REST API.

Export to Azure Logic - Apps:
Configure export by using the Defender REST API.

---

### Answer:

To export Microsoft Defender for Cloud data at the resource group level, you should use Defender's Representational State Transfer - Application Programming Interface (REST API). Defender for Cloud offers three methods to configure the continuous export of regulatory compliance and other data; however, only the REST API option allows exports at the resource group level. The other two options, Azure Policy and the Azure portal, only support exports at the subscription level. Exporting compliance and other Defender for Cloud data might be useful in scenarios in which you use a custom risk management system that ingests and analyzes such data.
You should also use the Defender REST API when your company needs to export data to Azure Logic - Apps. Azure Logic - Apps is a cloud-based platform that enables you to create, monitor, and manage workflows across your organization. Workflows can be triggered by events such as messages being sent to a queue, or files being added to a folder. Logic - Apps makes it easy to integrate your favorite Software as a service (SaaS) applications with each other, and with on-premises systems. You can also use Logic - Apps to automate common tasks, such as the sending of notifications or emails.
You should not recommend configuring the exports by implementing Azure Policy. Azure Policy is a service in Azure that you can use to create, assign and manage policy definitions. Policy definitions specify which resources will be validated against the desired conditions. You can use Azure Policy to prevent unwanted resources from being deployed, check for adherence to company standards, assess compliance with internal policies, and find resources that are not compliant with security best practices. Azure Policy gates the deployment of non-compliant resources, allowing you to enforce your compliance posture across your organization.
You should not recommend configuring the exports via the Azure portal. You can use the Azure portal to configure the continuous export of security alerts, recommendations, findings, and other data. However, you cannot use this option to export at the resource group level or to Azure Logic - Apps.

---

### References

[Continuously export Microsoft Defender for Cloud data](https://learn.microsoft.com/en-us/azure/defender-for-cloud/continuous-export)  
[What is Azure Logic - Apps?](https://learn.microsoft.com/en-us/azure/logic-apps/logic-apps-overview)  

---

## Q062:

Your company has active Azure and Microsoft 365 subscriptions and it uses Microsoft Purview Compliance Manager. You need to improve the company's compliance posture by implementing both generalized and specific mitigation actions.
You need to meet a set of requirements.

Which actions should you implement? To answer, select the appropriate actions from the drop-down menus.

Choose the correct options

Implement detective actions:
Perform regulatory compliance audits.

Improve your compliance score by exactly nine points: 
Implement a preventative discretionary action.

---

### Answer:

To implement detective actions, you should perform regulatory compliance audits. Compliance manager supports detective, corrective, and preventative actions. Detective actions aim to detect and identify behaviors or conditions that increase risk, such as clients not running the latest antivirus updates. Regulatory audits can be used to detect this type of risk.
You should not execute incident response playbooks. An incident response is a corrective action that aims to reduce the impact of a breach or exploit. Incident responses cannot be used to detect risk.
You should not implement separation of duties policies. This is a preventative action that aims to prevent conditions where fraud might occur. Separation of duty policies are not designed to detect risk.
Microsoft Compliance Manager assigns a score to all actions, depending on their level of risk. To improve your compliance score by exactly nine points, you should implement a preventative discretionary action. Preventative discretionary actions rely on a user for compliance and aim to prevent a breach or eliminate risk.
You should not implement a corrective discretionary action. This type of action relies on a user to take action in order to reduce the impact of a breach or exploit. A corrective discretionary action will only improve your compliance score by one point.
You should not implement a detective mandatory action. This type of action cannot be bypassed and it aims to detect behaviors or conditions that increase risk. This type of action will only improve your compliance
score by three points.

---

### References

[Compliance score calculation](https://learn.microsoft.com/en-us/purview/compliance-manager-scoring)
[Microsoft Purview Compliance Manager](https://learn.microsoft.com/en-us/purview/compliance-manager)  
[Analyze the Microsoft Compliance Score](https://learn.microsoft.com/en-us/training/modules/explore-plan-compliance-microsoft-365/)  

---

## Q061:

Your company has multiple Azure subscriptions. You enable Microsoft Defender for Cloud on subscriptions that host sensitive workloads. Your plan is to use Defender for Cloud to evaluate infrastructure compliance for these workloads to prepare for regulatory audits.
You need to identify how each Defender for Cloud component will be used to support this goal.
For each stated purpose, which element should you identify? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

Used to control specific security conditions using rules: Security policies
Used to group rules for a specific purpose or goal: Security initiatives
Used to identify remediation prerequisites: Security recommendations

---

### Answer:

Security policies are used in Microsoft Defender for Cloud and they use rules to control specific security conditions. Security policies are created in Azure Policy. Each policy, formatted using JSON, contains a policy definition, or rule, that can be used to perform granular configuration management. For example, one built-in Azure policy enforces Transport Layer Security (TLS) 1.2 for Azure Active Directory (Azure AD) communications.
Security initiatives are used to group rules for a specific purpose or goal. Grouping rules, or policy definitions, simplifies the tasks of assigning and managing Azure Policy. A security initiative contains at least two policy definitions.
Security recommendations are used to identify remediation prerequisites. Defender for Cloud can evaluate your infrastructure against the policies you have defined and provide recommendations for remediating any vulnerabilities or misconfigurations that are discovered. Defender provides prerequisite, alternative, and dependent recommendations.
Security posture is not used in these scenarios. Security posture can be determined by evaluating your secure score in Defender for Cloud.

---

### References

[What are security policies, initiatives, and recommendations?](https://learn.microsoft.com/en-us/azure/defender-for-cloud/security-policy-concept)  
[Tutorial: Improve your regulatory compliance](https://learn.microsoft.com/en-us/azure/defender-for-cloud/regulatory-compliance-dashboard)  
[Secure score](https://learn.microsoft.com/en-us/azure/defender-for-cloud/secure-score-security-controls)  

---

## Q060:

Your company uses Azure Policy. You have been asked to use a policy to prevent the accidental deletion of resource groups.
You need to ensure that your policy template JSON prevents resource groups from being deleted.
How should you complete the partial snippet? To answer, select the appropriate options from the drop- down menus.

```
"then": {
"effect": M deployIfNotExists",
"details": {
"type": "Microsoft.Authorization/locks",
"existenceCondition": {
"field": "Microsoft.Authorization/locks/level",
"equals": "CanNotDelete"
"roleDefinitionIds":[
"/providers/Microsoft.Authorization/roleDefinitions/8e3af-2fe"
1,
{
deployment": {
"properties": {
"mode": "incremental",
template": {
"$schema": "/schemas/2015-01-01/deploymentTemplate.json",
"contentVersion": "1,0,0,0",
"resources": [
{
"type": "Microsoft.Authorization/locks",
"apiVersion": "2017-04-01",
"name": "Lock-Delete-ProdRG",
"properties": {
"level": "CanNotDelete",
"notes": "Prevent deletion of the Production Resource Group"
}
```

---

### Answer:

The deployIfNotExists property defines an effect for a policy and stipulates that if the condition identified by the policy is met, the provided deployment should be applied.
The deployment property specifies a configuration action or actions that should be deployed. In this scenario, the deployment will set the CanNotDelete property on a resource group. This property is required for deployIfNotExists policies.
The template defines the logic and settings that will be deployed. This property is required for deployIfNotExists policies.
You should not specify the audit property. This property defines an effect and can be used to identify non- compliant resources and log an event without affecting the resource state.
You should not specify the templateinfo property. This property is used by other policy effects, such as audit, to identify a source template. This property is not used for deployIfNotExists policies.


---

### References:

[Understand Azure Policy effects](https://learn.microsoft.com/en-us/azure/governance/policy/concepts/effect-basics)
[Building your Azure Policies - Part 1](https://msftplayground.com/2022/03/building-your-azure-policies-part-1/)  
[What is Azure Policy?](https://learn.microsoft.com/en-us/azure/governance/policy/overview)  

---

# Q059:

Your company uses Azure Policy to detect and identify non-compliant resources. Management wants to enhance policy usage so that non-compliance can be remediated.
You need to design a solution that can automate remediation, where possible.
Which two Azure Policy effects should you recommend? Each correct answer presents part of the solution.

Choose the correct answers

- deployIfNotExists
- disabled
- modify
- audit
- deny

---

### Answer:
- deployIfNotExists
- modify

You should recommend implementing the deployIfNotExists and modify Azure Policy effects. A policy is a collection of conditions and settings that you can use to control how resources are created and managed in Azure. For example, you can use policies to require certain authentication methods for resources or to configure maximums for resource sizes. You can also use policies to automatically apply updates to resources or even delete resources that do not meet policy requirements. By creating policies that use the deployIfNotExists or modify effects, you can identify non-compliant resources and then initiate a process, based on a template, to remediate that condition.
You should not recommend implementing the disabled Azure Policy effect. This effect can be used during testing to disable a specific policy assignment.
You should not recommend implementing the audit Azure Policy effect. This effect can be used to identify
non-compliant resources and log an event without affecting the resource state.
You should not recommend implementing the deny Azure Policy effect. This effect can be used to prevent the creation or updating of a resource that would cause a constraint violation.

---

### References:

[Remediate non-compliant resources with Azure Policy](https://learn.microsoft.com/en-us/azure/governance/policy/how-to/remediate-resources?tabs=azure-portal)  
[Tutorial: Create and manage policies to enforce compliance](https://learn.microsoft.com/en-us/azure/governance/policy/tutorials/create-and-manage)  
[Understand Azure Policy effects](https://learn.microsoft.com/en-us/azure/governance/policy/concepts/effect-basics)  
[What is Azure Policy?](https://learn.microsoft.com/en-us/azure/governance/policy/overview)  


---

## Q058:

Your company has a Microsoft 365 subscription, and your employees use Exchange Online to collaborate with customers, vendors, and government agencies. Despite implementing strict data access and usage permissions, a security analyst discovers that personally identifiable information (PII) is still being sent by email.
To comply with privacy regulations, you need to introduce controls that address this finding.
Which two actions should you include in your data exfiltration prevention solution? Each correct answer presents part of the solution.

Choose the correct answers

- Configure Exchange clients to use Secure/Multipurpose Internet Mail Extensions (S/MIME).
- Create a custom sensitive information type in the Compliance center.
- Configure Azure Disk Encryption (ADE) and store keys in Key Vault.
- Create an Exchange discovery mailbox.
- Create a Data Loss Prevention (DLP) policy in Microsoft Purview.

---

### Answer:
- Create a custom sensitive information type in the Compliance center.
- Create a Data Loss Prevention (DLP) policy in Microsoft Purview.

You should create a custom sensitive information type in the Compliance center. Microsoft Purview allows you to use regular expressions to define custom sensitive information types. Regular expressions, or regex, are part of powerful, highly customizable language that can be used to search for and extract information from log files, documents, and emails. For example, the following regular expression could be used to locate any email with an embedded Social Security number:
^(210001666) [0-8][0-9]{2}-(2100) [0-9]{2}-(?10000) [0-9]{4}$
You should also create a Data Loss Prevention (DLP) policy in Microsoft Purview. DLP can be used to identify sensitive information used in Microsoft 365 apps and it can prevent that information from being shared. Your DLP policy will include the custom sensitive information type.
You should not configure Exchange clients to use Secure/Multipurpose Internet Mail Extensions (S/MIME). S/MIME is a Public key infrastructure (PKI)-based cryptographic standard for email security. It allows users to send and receive encrypted and digitally signed messages. S/MIME is best known for its use with email, but it can also be used for other applications such as secure file transfer and messaging. S/MIME will not prevent data exfiltration. As S/MIME encrypts emails and attachments, it may make exfiltration easier since email contents will be unreadable by DLP processes.
You should not create an Exchange discovery mailbox. A discovery mailbox is created to hold the output of eDiscovery activities. In Exchange, eDiscovery is a feature that allows administrators to search email and other content in Exchange mailboxes. eDiscovery can be used to find specific items or emails, or to collect content for review. eDiscovery can be used to gather information for legal proceedings, or for internal investigations.
You should not configure Azure Disk Encryption (ADE) and store keys in Key Vault. ADE is a feature of Microsoft Azure that allows you to encrypt your Windows and Linux Infrastructure-as-a-Service (laaS) virtual machine disks. ADE uses the industry standard BitLocker feature of Windows and the dm-crypt feature of Linux to provide encryption at rest for your disks.

---

### References:

[Create custom sensitive information types in the compliance portal](https://learn.microsoft.com/en-us/purview/sit-create-a-custom-sensitive-information-type?tabs=purview)  
[Learn about data loss prevention](https://learn.microsoft.com/en-us/purview/dlp-learn-about-dlp)  
[S/MIME for message signing and encryption in Exchange Online](https://learn.microsoft.com/en-us/exchange/security-and-compliance/smime-exo/smime-exo)  
[Create a discovery mailbox in Exchange Online](https://learn.microsoft.com/en-us/purview/ediscovery-create-draft-collection)  
[Azure Disk Encryption for Windows VMs](https://learn.microsoft.com/en-us/azure/virtual-machines/windows/disk-encryption-overview)  

---

## Q057:

Your company stores Personally identifiable information (PII) and Protected health information (PHI) in Microsoft 365 and Azure. Compliance requirements stipulate that this type of data must receive special handling.
You need to design a solution that will protect this data while in motion and at rest.

What should you recommend your company to do?

Choose the correct answer

- Configure a Data Loss Prevention (DLP) policy for sensitive documents.
- Deploy X.509 certificates on servers and configure Transport Layer Security (TLS).
- Define sensitivity labels and configure protection settings.
- Enable BitLocker on all file servers and user's workstations.

---

### Answer:
- Define sensitivity labels and configure protection settings.

You should recommend defining sensitivity labels and configuring protection settings. This can be done in Microsoft Purview. You can create sensitivity labels based on a classification system that works for your organization. For example, you may define sensitivity labels for Private or Confidential information. You can then configure the protection settings that are applied with each label, including requiring data encryption. Users can assign labels to documents manually, or you can configure labels to be applied automatically.
You should not recommend deploying X.509 certificates on servers and configuring Transport Layer Security (TLS). TLS is stipulated for most Microsoft cloud services. TLS is widely used to encrypt data in motion
between user browsers and web servers. However, TLS does not protect data at rest.
You should not recommend enabling BitLocker on all file servers and user's workstations. BitLocker is a Windows feature that can be used to encrypt fixed and portable storage media such as USB drives. BitLocker will not protect files in transit. You can use Microsoft Intune to enable and configure BitLocker for Windows devices.
You should not recommend configuring a Data Loss Prevention (DLP) policy. DLP can be used to identify sensitive information used in Microsoft 365 apps and prevent this information from being shared. You can use Purview to configure DLP for Microsoft 365.

---

### References:

[Restrict access to content by using sensitivity labels to apply encryption](https://learn.microsoft.com/en-us/purview/encryption-sensitivity-labels)  
[What is TLS (Transport Layer Security)?](https://www.cloudflare.com/learning/ssl/transport-layer-security-tls/)  
[Best Practices for Deploying BitLocker with Intune](https://petri.com/best-practices-for-deploying-bitlocker-with-intune/)  
[Learn about data loss prevention](https://learn.microsoft.com/en-us/purview/dlp-learn-about-dlp)  

---

## Q056:

You are a security architect for a company that has a hybrid infrastructure hosted both on premises and in Microsoft/the Azure cloud platform. As part of a project to improve the overall security posture of the environment, you need to design a Zero Trust policy enforcement solution to facilitate access control for assets, ensuring it adheres to the enterprise access model.
Which part of the enterprise access model should you include in your solution?

Choose the correct answer

- Management plane
- User access
- Data plane
- Control plane

---

### Answer:

The enterprise access model helps organizations to adopt a more robust privileged access strategy and has multiple layers and workloads.
Zero Trust policy enforcement aligns with the control plane. The control plane is at the top of the enterprise access model and facilitates unified strategy and policy, and has identity as the primary mechanism to control access for assets.
Asset management and monitoring of platforms aligns with the management plane. This is created when enterprise IT manages hybrid infrastructure that is hosted in the cloud, on-premises, or with a third-party provider.
Data storage, applications, and websites align with the data plane. Every plane within the enterprise access model has control of the data and workloads due to their functions. Users also access the data plane to access applications and web resources.
User access is the mechanism used for employees, partners, and third parties to gain access to the data and applications which align with the data plane. This includes gaining access via user accounts and end-user devices.

---

### References:

[Enterprise access model](https://learn.microsoft.com/en-us/security/privileged-access-workstations/privileged-access-access-model)  


---

## Q055:

You are a third line engineer for an organization that has recently migrated all its infrastructure to the cloud across multiple cloud vendors. The security team has recently enabled Microsoft Entra Permissions Management and the third line engineering team has been tasked with onboarding the following:

- An Azure subscription
- An Amazon Web Services (AWS) account
- A Google Cloud Platform (GCP) project

You need to grant the relevant permissions on the Azure subscription to ensure that the team can perform the relevant tasks to onboard Azure.
Which permission should you grant the third line engineering team on the Azure subscription?

Choose the correct answer

- Microsoft.Authorization/policyAssignments/write
- Microsoft.Authorization/roleAssignments/write
- Microsoft.Authorization/roleAssignments/read
- Microsoft.Authorization/roledefinitions/write

---

### Answer:
- Microsoft.Authorization/roleAssignments/write

You should assign the Microsoft. Authorization/roleAssignments/write permission to the third line engineering team to ensure that they have the relevant permissions to complete the onboarding tasks. This is
a pre-requisite for the onboarding of Azure into the Microsoft Entra Permissions Management platform.
You should not assign the Microsoft.Authorization/roleAssignments/read to the third line engineering team. The read access will not be sufficient to complete the onboarding tasks of Azure into the Microsoft Entra Permissions Management platform, as it will only grant read access and not write access.
You should not assign Microsoft. Authorization/policyAssignments/write to the third line engineer team. This will grant write permissions to policy assignments, which is not a requirement when onboarding Azure into the Microsoft Entra Permissions Management Platform.
You should not assign Microsoft.Authorization/roledefinitions/write to the third line engineer team. This will grant write permissions to role definitions, which is not a requirement when onboarding Azure into the Microsoft Entra Permissions Management Platform.
Microsoft Entra is Microsoft's new identity and access management (IAM) dashboard that includes all the identity services including Azure Active Directory (Azure AD), privileged identity management (PIM), Conditional Access policies, and identity governance.

---

### References:

[Onboard a Microsoft Azure subscription](https://learn.microsoft.com/en-us/entra/permissions-management/onboard-azure)  
[Enable Microsoft Entra Permissions Management in your organization](https://learn.microsoft.com/en-us/entra/permissions-management/onboard-enable-tenant)  
[What's Microsoft Entra Permissions Management?](https://learn.microsoft.com/en-us/entra/permissions-management/overview)  
[Assign Azure roles using the Azure portal](https://learn.microsoft.com/en-us/azure/role-based-access-control/role-assignments-portal)  

---

## Q054:

You are a security analyst for a company that is planning on migrating its infrastructure to Azure AD, including its current identity access management (IAM) platform. You have been asked to work alongside the architects team to design the cloud infrastructure entitlement management (CIEM) solution that will be deployed before the migration.
You need to define the Permissions Management discover use case.
For each of the following statements, select Yes if the statement is true. Otherwise select No.

Statement | Yes | No

This use case allows you to use permissions usage analytics to view permissions risk for all identities, actions, and resources.
Yes

This use case allows you to automate the deletion of permissions unused for the past 90 days.
No

This use case allows you to unify access policies across identity as a service (laas) platforms.
No

---

### Answer:

The discover use case allows you to use permissions usage analytics to view permissions for all identities, actions, and resources. By looking at the difference between the permissions that have been granted and the permissions that are being used you can evaluate whether a specific user can be assigned fewer privileges in alignment with what they are actually using.
The discover use case does not allow you to automate the deletion of permissions unused for the past 90 days. You can automate permission management within the remediate use case by utilizing Azure AD features like just-in-time (JIT) access to Azure AD and Azure resources.
The discover use case does not allow you to unify access policies across identity as a solution (laaS) platforms. This comes under the monitor use case with which customers can detect anomalous activities with machine learning-powered alerts and create detailed forensic reports.

---

### References:

[Design a solution for cloud infrastructure entitlement management (CIEM)](https://learn.microsoft.com/en-us/training/modules/design-solutions-secure-privileged-access/5-design-solution-cloud-infrastructure-entitlement-management)  


---

## Q053:

You are a solutions architect for an organization that is planning a migration to Azure. You have been tasked with designing a solution to secure privileged access. You decide to utilize the enterprise access model.
You need to define how to split the following different elements of the estate into the Active Directory (AD Tier model):
.
Networking and Access Control
User Access (Internal and external)
IT Management functions
Workload plane for per-workload Management
At which level of the enterprise access model should you work in the following scenarios? To answer, drag the appropriate tier value to each scenario description. A tier may be used once, more than once, or not at all.

Drag and drop the answers

Tier 0
Tier 1
Tier 2

To enforce your Zero Trust policy: 
Tier 0

To facilitate your partners accessing applications in your tenant:
Tier 2

To manage assets and the protective monitoring of your estate:
Tier 1

To create applications and websites to store business value
Tier 1

---

### Answer:

Tier 0 includes the control plane, which oversees all aspects of access control. This includes networking. You should enforce your Zero Trust policy at this level as identity is a control method as well. It is important to implement a centralized access control policy within this tier. Tier O represents the highest level of privilege and control in the environment. It includes centralized identity and access management functions. Typically, Tier O is responsible for managing and controlling administrative access to critical infrastructure components and services. This tier encompasses tasks such as user and group management, access policies, and privileged identity management. Tier O is focused on maintaining the security and integrity of the entire environment.
Tier 1 is split into two areas, which allows for increased clarity and accountability. First is the Management plane, which includes enterprise-wide IT management functions. It provides administrative access to manage various services and resources within the environment. It includes functions related to application and resource management, such as creating and configuring virtual machines, creating websites, managing storage accounts, setting up networking components, and deploying applications. It is responsible for day- to-day operations, monitoring, and troubleshooting of resources. It enables authorized administrators to manage specific services and perform necessary tasks while maintaining a controlled access level. The second is per-workload/data management, which is mainly performed by the IT team but can also sometimes be performed by business units. Accessing workloads and data in tier 1 requires administrative privileges.
Tier 2 is also split into two areas that ensure coverage for application access and the various partner and customer models. First, there is user access, which has B2B and B2C access scenarios. The second area is app access to facilitate API access pathways. Tier 2 is intended for general user access and workloads that do not require administrative privileges. It represents the user-facing layer of the environment, where regular users interact with applications and services. This tier includes end-user access to applications, websites, and other workloads. Tier 2 focuses on providing a secure and controlled environment for users to access their necessary resources and perform their tasks without having administrative control or direct access to underlying infrastructure.

---

### References:

[Least privileged roles by task in Azure Active Directory](https://learn.microsoft.com/en-us/entra/identity/role-based-access-control/delegate-by-task)  
[Enterprise access model](https://learn.microsoft.com/en-us/security/privileged-access-workstations/privileged-access-access-model)  

---

## Q052:

Your company has Azure and Microsoft 365 subscriptions. The company uses Azure AD Privileged Identity Management (PIM) to manage, control, and monitor access to privileged accounts and resources.
You need to recommend a strategy for creating and assigning Azure AD roles in PIM.
Which configuration options should you recommend for each of the requirements? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

Users should be required to successfully complete MFA as part of role activation :
Select the Eligible option.

Activated roles should only manage resources in a specific department :
Select the Administrative unit option.

---

### Answer:

To ensure that users are required to successfully complete Multi-factor Authentication (MFA) as part of role activation, you should recommend selecting the Eligible option. When an Azure AD Privileged Identity Management (PIM) role assignment is configured as eligible, the user will be required to perform an action as part of role activation. This action could include requesting approval from another designated user, providing a justification, or completing MFA.
To ensure that activated roles only manage resources within a specific department, you should recommend selecting the Administrative unit option. Administrative units are custom-defined scopes that allow you to logically partition Active Directory administrative tasks. For example, you could define an administrative unit for each department within your company.
You should not recommend selecting the Active option. An active assignment is the opposite of an eligible assignment. Active assignments do not require additional authentication actions to be performed.
You should not recommend selecting the Assignment starts option. This allows you to define a time-bound
assignment and would be useful for specifying a start and end date for a contractor.
You should not recommend selecting the Subscription option. This is a scoping option for a role assignment. A subscription-scoped assignment can be used to manage resources throughout an Azure subscription.

---

### References:

[Assign Azure AD roles in Privileged Identity Management](https://learn.microsoft.com/en-us/entra/id-governance/privileged-identity-management/pim-how-to-add-role-to-user)  
[Create or delete administrative units](https://learn.microsoft.com/en-us/entra/identity/role-based-access-control/admin-units-manage?tabs=ms-powershell)  
[Exercise assign Azure Active Directory roles in Privileged Identity Management](https://learn.microsoft.com/en-us/training/modules/plan-implement-privileged-access/5-assign-azure-active-directory-roles-privileged-identity-management)  
[Plan a Privileged Identity Management deployment](https://learn.microsoft.com/en-us/entra/id-governance/privileged-identity-management/pim-deployment-plan)  


---

## Q051:

Your company has an Azure AD Premium P2 license. Recently, it was discovered that an Exchange Online administrator used a permanent role assignment to export mailbox data. Management has asked that all role assignments are compliant with Zero Trust security initiatives.
You need to design an Azure AD Privileged Identity Management (PIM) solution that helps meet this goal.
Which two statements should you include in your recommendation? Each correct answer presents part of the solution.

Choose the correct answers

- Role activation can require justification or approval, but not both.
- Active role assignments require at least one activation step prior to use.
- Active role assignment creation can be configured to require Multi-factor Authentication (MFA).
- Permanent role assignments are required for privileged Azure AD tasks.
- Permanent role assignments can be assigned as active or eligible.

---

### Answer:
- Active role assignment creation can be configured to require Multi-factor Authentication (MFA).
- Permanent role assignments can be assigned as active or eligible.

Active role assignment creation can be configured to require Multi-factor Authentication (MFA). Azure AD Privileged Identity Management (PIM) helps organizations manage, control, and monitor access to privileged accounts and resources. With Azure AD PIM, organizations can grant Just-in-Time (JIT) access to privileged accounts and role-based access controls (RBAC), as well as providing auditing and reporting on all actions taken with those accounts. This helps reduce the risk of accidental or unauthorized misuse of privileged accounts, while still allowing administrators to work securely and efficiently.
Permanent role assignments can be assigned as active or eligible. An active assignment is one that the user can utilize at any time. Active assignments do not require the user to first activate the assignment.
Permanent role assignments are not required for privileged Azure AD tasks. Azure AD PIM supports both permanent and eligible role assignments. Both assignment types can be used for privileged Azure AD tasks.
Active role assignments do not require any activation steps prior to use. Active roles can be used at any time, without requiring the user to perform activation steps. Eligible role assignments must be activated prior to use.
Role activation can require justification, approval, or any combination of other activation options. Additional activation options include Azure MFA and ticket creation. An activation duration can also be specified.

---

### References:

[Configure Azure AD role settings in Privileged Identity Management](https://learn.microsoft.com/en-us/entra/id-governance/privileged-identity-management/pim-how-to-change-default-settings)  
[What is Azure AD Privileged Identity Management?](https://learn.microsoft.com/en-us/entra/id-governance/privileged-identity-management/pim-configure)  


---

## Q050:

Your client has an Azure AD Premium 2 subscription. The client suffered a breach when an attacker used brute-force password guessing tools to compromise an actively used privileged account.
You need to identify methods which enhance user account related risk detection.
Which action should you recommend to the client?

Choose the correct answer

- Use Azure ID Identity Protection to detect when a single browser signs-in across tenants in different countries.

- Use Azure ID Identity Protection to identify credentials leaked prior to password hash synchronization (PHS) configuration.

- Use Azure ID Identity Protection to detect atypical travel for regularly used Virtual Private Network (VPNs).

- Use Azure ID Identity Protection to detect sign-ins that use incorrect user credentials.

---

### Answer:
- Use Azure ID Identity Protection to detect when a single browser signs-in across tenants in different countries.

You should recommend using Azure ID Identity Protection to detect when a single browser signs-in across tenants in different countries. Azure AD Identity Protection is a cloud-based identity security service that helps you to protect your on-premises and cloud-based users from malicious or accidental access to your resources. This service provides you with a comprehensive set of tools to help to prevent, detect, and respond to identity-related threats. You can use Azure Active Directory (Azure AD) Identity Protection to:

- Monitor and protect critical user accounts.
- Take advantage of machine learning techniques to detect suspicious activities.

Receive alerts about potential threats.
Respond quickly to incidents.
You should not recommend using Azure ID Identity Protection to detect sign-ins that use incorrect user credentials. Identity protection does not identify failed sign-ins using incorrect credentials as a sign-in risk. Only sign-in attempts with valid credentials are evaluated and given a risk score. In this scenario, you could recommend using Azure AD sign-in logs to track failed sign-in attempts.
You should not recommend using Azure ID Identity Protection to detect atypical travel for regularly used VPNs. Atypical travel uses IP geolocation information to detect sign-ins involving impossible travel. However, Identity Protection purposely ignores logons for regularly used Virtual Private Network (VPN) connections that would generate false positives.
You should not recommend using Azure ID Identity Protection to identify credentials leaked prior to password hash synchronization (PHS) configuration. Identity Protection will not use raw credentials to identify credential leaks. Once PHS is enabled, you will be notified if credentials leaks are detected by Microsoft.

---

### References:

[What is Identity Protection?](https://learn.microsoft.com/en-us/entra/id-protection/overview-identity-protection)  
[What are risk detections?](https://learn.microsoft.com/en-us/entra/id-protection/concept-identity-protection-risks)  
[Quickstart: Analyze sign-ins with the Azure AD sign-ins log](https://learn.microsoft.com/en-us/entra/identity/monitoring-health/quickstart-analyze-sign-in)  
[Sign-in logs in Azure Active Directory](https://learn.microsoft.com/en-us/entra/identity/monitoring-health/concept-sign-ins)  


---

## Q049:

Your client, an online printing company, aims to expand its business to individual customers. The company already has a web app and uses Azure to manage accounts for business customers.
You need to design an authentication solution that will allow individual customers to sign-up for printing services using accounts from popular social identity providers. These accounts should be manageable with user flows. You recommend for the client to use Azure AD B2C to meet this requirement.
Which component should you include for each design element? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

Azure AD B2C account type that will be used for individual customers : 
Consumer

Component required to register the company's web application : 
Client secret

---

### Answer:

Azure Active Directory business-to-costumer (Azure AD B2C) consumer accounts will be used for individual customers. Azure AD B2C supports three account types: consumer accounts, guest accounts, and work accounts. Guest accounts can be invited to an Azure AD B2C tenancy for sharing administrative tasks, while users with work accounts can perform cross-tenant-level administration. Consumer accounts are manageable using custom policies and user flows.
A client secret will be required to register the company's web application with Azure AD B2C. Client secrets can be compared to an application password. The secret is stored in your application code and facilitates the customer receiving an authorization token during the sign-in process.
You should not include a resource owner password credentials (ROPC) policy in your recommendation. ROPC flow policies allow users to supply their password directly to an application. In this scenario, users need to be authenticated by social identity providers. Your application does not have access to the identity provider's authentication database and a user supplying the password they use with a social identify provider will not facilitate authentication.
You should not include a user flow in your recommendation. User flows are used to define the sign up or sign in processes for your client's web app. User flows are not required to register the company's web app with a social identity provider and will not meet the stated requirement.

---

### References:

[Technical and feature overview of Azure Active Directory B2C](https://learn.microsoft.com/en-us/azure/active-directory-b2c/technical-overview)  
[Tutorial: Register a web application in Azure Active Directory B2C](https://learn.microsoft.com/en-us/azure/active-directory-b2c/tutorial-register-applications?tabs=app-reg-ga)  
[Tutorial: Create user flows and custom policies in Azure Active Directory B2C](https://learn.microsoft.com/en-us/azure/active-directory-b2c/tutorial-create-user-flows?pivots=b2c-user-flow)  

---

## Q048:

Your client interacts with its customers using custom-built mobile apps. Current authentication and authorization information is stored in individually-maintained Azure-based databases. The client has asked you to design a solution that allows authentication and authorization to be centralized. You recommend that your client deploy Azure AD and implement OAuth 2.0 for authorization.
You need to help your client identify the process that is performed by each OAuth 2.0 party.
Which process should you identify for each of the roles? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

Authorization server: Gives scoped access to a protected resource.
Client: Requests access to a protected resource.
Resource owner: Authorizes access to a protected resource.
Resource server: Uses access tokens to accept requests.

---

### Answer:

OAuth 2.0 is a standards-based framework that facilitates federated access for applications and web services. OAuth 2.0 can support third-party, federated authentication in scenarios where an application does not have built-in authentication mechanisms. Additionally, OAuth 2.0 can be used to obtain third-party designated access to protected resources. For example, a calendar app can be granted permissions to access a user's Google calendar via OAuth 2.0.
The Authorization server gives scoped access to a protected resource. The authorization server, or OAuth 2.0 server, authenticates resource owners, and validates and requests resources. Based on the result of these activities, the authorization server issues a token to the client.
The Client, which can be a Web - App or a Web API, requests access to a protected resource from an authorization server. In the above example, the calendar app is a client.
The Resource owner authorizes access to a protected resource. When an application needs to access a resource, such as a third-party calendar, the resource owner is prompted to authorize the request. The resource owner is typically an end-user.
The Resource server uses access tokens to accept requests. The resource server hosts the protected resource, such as a user's calendar.

---

### References:


[OAuth 2.0 and OpenID Connect (OIDC) in the Microsoft identity platform](https://learn.microsoft.com/en-us/entra/identity-platform/v2-protocols)  
[Authentication vs. authorization](https://learn.microsoft.com/en-us/entra/identity-platform/authentication-vs-authorization)  

---

## Q047:

Your company completes deployment of compute and storage resources in Azure. The company uses Active Directory (AD) on-premises, and the system administration team is currently testing directory synchronization using Azure AD Connect. Management wants to ensure account security by monitoring account usage and alerting of suspicious behavior.
You need to design a solution that identifies risky account behavior. You plan to recommend that the system administration team create identity protection policies using Azure AD Identity Protection.
Which policy condition should you recommend setting for each of the suspicious behaviors? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

Behavior consistent with known attack patterns: User risk
An anomalous token condition: Sign-in risk
Suspicious inbox rules: Sign-in risk

---

### Answer:

The user risk condition should be set in an identity protection policy in order to detect behavior that is consistent with known attack patterns. Known attack patterns are based on threat intelligence gathered by Microsoft and other sources. These attack patterns are sometimes referred to as an attacker's tactics, tools, and procedures (TTPs).
The sign-in risk condition should be set in an identity protection policy in order to detect an anomalous token condition. An anomalous token condition might include the replay of a token from a suspicious IP, or malformed data in the token itself. These findings may indicate that an attacker is attempting to spoof an authentication token.
The sign-in risk condition should be set in an identity protection policy in order to detect suspicious inbox rules. When an account is compromised, an attacker may create inbox rules that delete non-delivery reports, sign-in notifications, or other emails that might alert the account owner to suspicious behavior.
Azure AD Identity Protection is a cloud-based identity security service that helps you protect your on- premises and cloud-based users from malicious or accidental access to your resources. This service provides you with a comprehensive set of tools to help prevent, detect, and respond to identity-related threats.

---

### References:

[What is risk?](https://learn.microsoft.com/en-us/entra/id-protection/concept-identity-protection-risks)  
[Risk-based access policies](https://learn.microsoft.com/en-us/entra/id-protection/concept-identity-protection-policies)  

---

## Q046:

Your company uses Microsoft Defender for Cloud to help manage security for resources in an Azure subscription. To prepare for an upcoming security audit by a government agency, you want to ensure that your company's secure score is as high as possible.
You need to identify the controls that will have the greatest impact on your company's secure score.
Which two controls should you recommend to get the highest secure score? Each correct answer presents part of the solution.

Choose the correct answers

- Enable MFA for users that manage the Azure subscription.
- Install system updates on internet-facing web servers.
- - Ensure that improper security configurations have been resolved.
- Remediate outstanding vulnerabilities on internet-facing servers.
- Place internet-facing web servers in network security groups (NSGs).

---

### Answer:
- Enable MFA for users that manage the Azure subscription.
- Place internet-facing web servers in network security groups (NSGs).

You should recommend enabling Multi-factor Authentication (MFA) for users that manage the Azure subscription and place internet-facing web servers in network security groups (NSGs). Each of these options can increase your secure score by a maximum of 10 points. Secure score is a metric that provides a percentage-based score to represent the security posture of your organization's cloud environment. Security scores are simple, point-in-time calculations.
MFA is a security process that requires two or more forms of verification from independent sources to grant access. MFA is an important security measure because it makes it much more difficult for attackers to gain access to accounts or systems. Even if an attacker knows (or guesses) a victim's password, they would still need another form of verification, such as a physical token or a one-time code to gain access. There are many different ways to implement MFA, but the most common approach is to use something you know (like a password) plus something you have (like a smartphone) as the two factors of authentication.
A network security group (NSG) is a virtual networking element that enables you to control the inbound and outbound traffic to resources in a virtual network using IP addresses, protocols, and ports. NSGs can be used to close off parts of your network to all traffic, or they can be used to allow specific types of traffic
while blocking all other traffic.
You should not recommend installing system updates on internet-facing web servers to maximize the secure score. Installing system updates reduces the risk of vulnerabilities on a system. Keeping systems up-to-date can increase your score by a maximum of six points.
You should not recommend remediating outstanding vulnerabilities on internet-facing servers to maximize the secure score. Addressing vulnerabilities will reduce the attack surface on your systems. This activity can increase your score by a maximum of six points.
You should not recommend ensuring that improper security configurations have been resolved to maximize the secure score. This activity is closely related to remediating outstanding vulnerabilities and it can increase your score by a maximum of four points.

---

### References:

[Secure score](https://learn.microsoft.com/en-us/azure/defender-for-cloud/secure-score-security-controls)  
[How it works: Azure AD Multi-Factor Authentication](https://learn.microsoft.com/en-us/entra/identity/authentication/concept-mfa-howitworks)  
[Create, change, or delete a network security group](https://learn.microsoft.com/en-us/azure/virtual-network/manage-network-security-group?tabs=network-security-group-portal)  
[Security Control: Vulnerability Management](https://learn.microsoft.com/en-us/security/benchmark/azure/security-control-vulnerability-management)  


---

## Q045:

Your company has an Azure AD Premium P1 subscription.
You need to design a solution that evaluates sign-on signals as part of the authentication decision process. During the initial testing phase of the project, users will be granted access, but accounts with elevated privileges will require multi-factor authentication (MFA).
Which two tasks should you include in your project plan for this initial testing phase? Each correct answer presents part of the solution.

Choose the correct answers

- Define a custom role for administrator accounts.
- Deploy a conditional access policy from a template.
- Specify an assignment that includes built-in roles.
- Create an application control policy in Microsoft Defender.
- Add all privileged accounts to an administrative unit.

---

### Answer:
- Deploy a conditional access policy from a template.
- Specify an assignment that includes built-in roles.

You should include the following two tasks in your project plan:

- Deploy a conditional access policy from a template.
- Specify an assignment that includes built-in roles.

Conditional Access is a security feature that helps you control how users access your Azure resources. With Conditional Access, you can define the conditions under which users are allowed to access your resources and the actions they can take once they have accessed them. You can create your own custom Conditional Access policies, or you can create a policy from a template. In this scenario, the best choice would be the Require multi-factor authentication (MFA) for admins template. As part of creating a Conditional Access policy, you can specify the built-in roles the policy applies to.
You should not add all privileged accounts to an administrative unit. Administrative units are custom-defined scopes that allow you to logically partition Azure AD administrative tasks. However, Conditional Access policies cannot be scoped to administrative units.
You should not define a custom role for administrator accounts. Roles form a basic building block in Azure role-based access control (RBAC) and facilitate functional-based groupings for permissions assignments. However, custom roles are not supported by Conditional Access policies.
You should not create an application control policy in Microsoft Defender. Windows Defender - Application Control (WDAC) allows you to create a Windows environment where only authorized applications can run on client computers. This helps protect your systems from malicious or unapproved software.

---

### References:

[Common Conditional Access policy: Require MFA for administrators](https://learn.microsoft.com/en-us/entra/identity/conditional-access/howto-conditional-access-policy-admin-mfa)  
[Create or delete administrative units](https://learn.microsoft.com/en-us/entra/identity/role-based-access-control/admin-units-manage?tabs=ms-powershell)  
[Azure custom roles](https://learn.microsoft.com/en-us/azure/role-based-access-control/custom-roles)  
[Windows Defender - Application Control and - AppLocker Overview](https://learn.microsoft.com/en-us/windows/security/application-security/application-control/windows-defender-application-control/wdac-and-applocker-overview)


---

## Q044:

Your company uses Azure AD for authentication. In an effort to mitigate the risk of lost passwords, you have been assigned a project to design a passwordless authentication scheme. You are provided with the following project information:

| Environment | Requirements |
|-------------|--------------|
| Windows 10/11 laptops | No additional hardware required |
| Android smartphones   |  - |
| iOS smartphones       |  - |


Which two solutions should you recommend to support passwordless authentication? Each correct answer presents part of the solution.

Choose the correct answers

- Microsoft Authenticator app
- Server PKI certificates
- FIDO2 security keys
- Azure AD secured SAS
- Windows Hello for Business

---

### Answer:
- Microsoft Authenticator app
- Windows Hello for Business

You should recommend using the Windows Hello for Business and Microsoft Authenticator apps for this project. As the name indicates, passwordless authentication does not require you to enter a password when authenticating against Azure Active Directory (Azure AD).
Windows Hello for Business is a new security feature that allows you to sign in to your Windows 10/11 devices with a fingerprint, face, or PIN. With Windows Hello for Business, you can unlock your device, access company resources, and authenticate applications without having to introduce a password.
Microsoft Authenticator is an app that helps you sign in to websites, Azure AD, and apps with your
Microsoft account. It generates security codes that are used for two-step verification, and it works with phones running Android or iOS.
You should not recommend using FIDO2 security keys for this project. FIDO2 security keys are physical devices that you can use in addition to your password to log in to websites and apps. They work by generating a unique authentication code that is valid for a single login session. This code changes with each login, so if someone else gets their hands on your key they will not be able to access your account. According to this scenario, your solution must not require any additional hardware, so, although FIDO2 security keys are supported by Azure AD, they cannot be used in this scenario.
You should not recommend using server Public Key Infrastructure (PKI) certificates for this project. PKI certificates are digital certificates that use public-key cryptography to prove the identity of a user or computer. They are used in a variety of applications, including email, file sharing, and secure Web browsing.
You should not recommend using Azure AD secured shared access signatures (SAS) for this project. SAS is used to provide secure access to resources in Azure Storage. By using SAS, you can grant read-only or read/write permissions to others for a specified amount of time. This is useful when you want to give someone temporary access to data without having to share your account credentials.

---

### References:

[Passwordless authentication options for Azure Active Directory](https://learn.microsoft.com/en-us/entra/identity/authentication/concept-authentication-passwordless)  
[Enable passwordless security key sign-in](https://learn.microsoft.com/en-us/entra/identity/authentication/how-to-enable-passkey-fido2)  
[What is a PKI certificate?](https://www.primekey.com/wiki/what-is-a-pki-certificate/)  
[Grant limited access to Azure Storage resources using shared access signatures (SAS)](https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview)  


---

## Q043:

Your company has multiple Azure subscriptions that it uses to host custom-built applications for clients. A new manufacturing customer has been onboarded using a new subscription and the required workload components have been deployed. The customer must evaluate the deployment for compliance with ISO 27001.
You need to assist the customer with this process. You begin by enabling Microsoft Defender for Cloud on the customer's subscription and checking compliance with Azure CIS.

Which task should you perform to evaluate the subscription's security posture against ISO 27001?

Choose the correct answer

- Enable enhanced security features for the subscription.
- Assign the Azure Security Benchmark to the subscription.
- Add a standard in Microsoft Defender for Cloud.
- Publish the ISO 27001 blueprint in Azure Blueprints.

---

### Answer:
- Add a standard in Microsoft Defender for Cloud.

You should add a standard in Microsoft Defender for Cloud. International Organization for Standardization (ISO) 27001 is an information security standard that outlines a framework of controls and best practices for managing an organization's data and assets, with the goal of preventing information security incidents. When the ISO 27001 standard is added, the subscription's compliance with the standard will be displayed and manageable in the Defender for Cloud dashboard.
Although it is required for posture evaluation, you do not need to enable enhanced security features for your subscription. In this scenario, this step was completed as part of checking compliance with the Azure Center for Internet Security (CIS) standard. Once enhanced security features are enabled, Azure CIS, ISO 27001, and other popular standards can be used to evaluate security posture.
You should not assign the Azure Security Benchmark to the subscription. This occurs automatically when you enable Defender for Cloud for a subscription. The Azure Security Benchmark evaluates a subscription against industry best-practices gleaned from other frameworks, as well as Microsoft's own security research.
You should not publish the ISO 27001 blueprint in Azure Blueprints. Azure Blueprints is a service that helps you deploy cloud resources in a consistent, repeatable way. Blueprints support security and compliance governance activities, and an ISO 27001 blueprint sample has been created by Microsoft. However, blueprints are designed for workload deployment. In this scenario, you only need to evaluate the existing deployment against ISO 27001.

---

### References:

[Customize the set of standards in your regulatory compliance dashboard](https://learn.microsoft.com/en-us/azure/defender-for-cloud/update-regulatory-compliance-packages)  
[Quickstart: Enable enhanced security features](https://learn.microsoft.com/en-us/azure/defender-for-cloud/connect-azure-subscription)  
[Tutorial: Improve your regulatory compliance](https://learn.microsoft.com/en-us/azure/defender-for-cloud/regulatory-compliance-dashboard)  
[What is Azure Blueprints?](https://learn.microsoft.com/en-us/azure/governance/blueprints/overview)  


---

## Q042:

Your company has an Azure AD subscription. You have designed an architecture as shown in the exhibit. Recently, the company hired an external contractor who will provide managed SOC services.
You need to ensure that employees from both entities can collaborate via Microsoft Teams. Your solution must meet the following requirements:

Accounts must be managed by administrators in each respective tenancy.
Users from both organizations must have access to a shared Teams channel.
Access must be facilitated using single sign-on.

What should you include in your solution?

Choose the correct answer

- Self-service sign-up
- B2B direct connect
- Azure AD B2C
- B2B collaboration

![image info](./Q42.PNG)


---

### Answer:
- B2B direct connect

You should include Azure Active Directory business-to-business (Azure AD B2B) direct connect in your solution. B2B direct connect is part of the External Identities portfolio in Azure AD. External Identities provides solutions for users outside your organization to interact with your users using their own identities, including those from other identity providers, such as Facebook or Google. B2B connect functions by creating two-way trusts between Azure AD organizations. This facilitates single sign-on collaboration using shared Microsoft Teams channels.
You should not include B2B collaboration in your solution. B2B collaboration requires sending invitations to users in the partner organization. Once the sign-up process is completed, external users sign in to your resources using their own identities.
You should not include Azure AD business-to-customer (B2C) in your solution. Azure AD B2C is similar to B2B but it is intended for use by your customers. Once configured, your customers can sign in to your apps or services using their credentials from other platforms, such as Twitter or Amazon.
You should not include self-service sign-up in your solution. Self-service sign-up can be used in B2B or B2C scenarios where you do not want to send invitations to users. Instead, the user initiates the sign-up process the first time they access your service or app.

---

### References:

[B2B direct connect overview](https://learn.microsoft.com/en-us/entra/external-id/b2b-direct-connect-overview)  
[B2B collaboration overview](https://learn.microsoft.com/en-us/entra/external-id/what-is-b2b)  
[What is Azure Active Directory B2C?](https://learn.microsoft.com/en-us/azure/active-directory-b2c/overview)  
[Self-service sign-up](https://learn.microsoft.com/en-us/entra/external-id/self-service-sign-up-overview)  

---

## Q041:

Your company uses Azure Storage and Azure AD. You manage a team of security analysts who have access to sensitive information for different customers. Currently, access to this data is managed using RBAC.
You need to design a solution that limits access to blobs based on tags.
Which authentication method should you recommend to support role assignment conditions?
Choose the correct answer
Mandatory Access Control (MAC)
Discretionary Access Control (DAC)
Privileged Access Management (PAM)
Attribute-Based Access Control (ABAC)

---

### Answer:

You should recommend attribute-based access control (ABAC). ABAC is a type of authorization mechanism that uses attributes to determine whether or not a user has access to a particular resource. With Azure blobs, attributes could include container names, account names, or blob index tags. ABAC is different from other authorization mechanisms, such as role-based access control (RBAC), because it allows for fine- grained control over who has access to what. For example, with RBAC, you might give all members of the Administrators group read and write access to a blob. With ABAC, you could instead give read and write access to that file only to users that match a specific blob attribute. ABAC is implemented in Azure by defining role assignment conditions.
You should not recommend privileged access management (PAM). PAM is a Microsoft Purview feature designed to facilitate more granular control over privileged administration accounts.
You should not recommend mandatory access control (MAC). MAC is considered the most secure access control method and is primarily used in government systems. The basis of the MAC model is the application of security labels, which are applied to all system resources.
You should not recommend discretionary access control (DAC). In a DAC model, file owners or those with similar privileges can grant access to other groups or users.


---

### References:

[What is Azure attribute-based access control (Azure ABAC)?](https://learn.microsoft.com/en-us/azure/role-based-access-control/conditions-overview)  
[Understand Azure role definitions](https://learn.microsoft.com/en-us/azure/role-based-access-control/role-definitions)  
[What is Azure role-based access control (Azure RBAC)?](https://learn.microsoft.com/en-us/azure/role-based-access-control/overview)  
[Access Control Models: MAC, DAC, RBAC, & PAM Explained](https://www.twingate.com/blog/other/access-control-models)  

---

## Q040:

Your company has Microsoft 365 Business Premium licenses. Recently, the company purchased laptops for all employees. To maintain network security, management plans to require MFA for all sign-ins outside the corporate LAN. The security team configures conditional access and creates a named location. However, employees report they are prompted to complete MFA regardless of their location.
You need to recommend a solution so that employees are only prompted for MFA when they are not connected to the corporate LAN.

What should you recommend?

Choose the correct answer

Ensuring that the option to determine location by GPS coordinates is enabled
Ensuring users have the Microsoft Authenticator mobile app installed
Ensuring that the option to determine location by IP address is configured
Ensuring that the location has been configured as a trusted location

---

### Answer:

You should ensure that the security team has configured the location as a trusted location. Conditional Access is a security feature that helps you control how users access your Azure resources. With Conditional Access, you can define conditions under which users are allowed to access your resources, and what actions they can take once they have accessed them. For example, you could allow users to access your resources only from certain locations or only during certain hours.
Named locations can be used in Conditional Access policies to make access decisions based on Global Positioning System (GPS) coordinates or IP addresses. In this scenario, a named location has been created, but it has not been marked as a trusted location. As a result, the condition is not applied when users are connected to the corporate LAN.
You should not ensure that the security team has configured the option to determine location by IP address. This option can be used when creating a named location based on country.
You should not ensure that the security team has enabled the option to determine location by GPS coordinates. This option can be used when creating a named location based on country.
You should not ensure that users have the Microsoft Authenticator mobile app installed. The Microsoft Authenticator app is only required if you are using GPS coordinates to determine a device location.

---

### References:

[Conditional Access: Network assignment](https://learn.microsoft.com/en-us/entra/identity/conditional-access/concept-assignment-network)  
[What is Conditional Access?](https://learn.microsoft.com/en-us/entra/identity/conditional-access/overview)    
[Configuring Conditional Access Policy to Restrict Access From Specific IP or Location](https://www.penthara.com/configuring-conditional-access-policy-to-restrict-access-from-specific-ip-or-location/)    
[Create Azure conditional access policy with named location](https://thesleepyadmins.com/2020/10/18/create-azure-conditional-access-policy-with-named-location/)    

---

## Q039:

Your company uses a single Azure AD subscription, and each employee has a dedicated Azure virtual desktop owned and managed by their department's IT administrator. Currently, IT administrators can only manage VMs for their department. The development team is creating a custom application that will allow Help Desk technicians to troubleshoot users' VMs, including modifying VM settings.
You need to design a solution to facilitate IT administrators to manage VMs in any department, while minimizing administrative overhead.

Which authorization method should you recommend?

Choose the correct answer

- Scope-based
- Role-based
- Resource-based
- Subscription-based

---

### Answer:
- Resource-based

You should recommend resource-based authorization. Resource-based authorization provides a way to authorize access to Azure resources by using the principle of least privilege. With resource-based authorization, you assign specific permissions to a user for individual resources. This means that you can give a user access only to the resources they need to do their job, and no more. For example, you could give a user permission to read data from an Azure storage account, but not write data to the account. This is particularly useful when resources are dispersed across Azure resource groups or other containers.
You should not recommend role-based authorization. Azure roles are collections of permissions, and every role has a scope. In this scenario, where resources are managed at the department level, granting the custom application role-based authorization for managing VMs is possible, but it does not minimize administrative overhead.
You should not recommend scope-based authorization. Scope-based authorization is equivalent to role- based authorization, as every role has a scope assigned to it.
You should not recommend subscription-based authorization. In this scenario, your company uses a single subscription, which defines a scope. As with role-based or scope-based authorization, permissions at the subscription level would apply to all resources in the subscription.


---

### References:

[Authorization with Azure AD](https://learn.microsoft.com/en-us/azure/well-architected/security/identity-access)  
[Architectural considerations for identity in a multitenant solution](https://learn.microsoft.com/en-us/azure/architecture/guide/multitenant/considerations/identity)  
[Resource access management in Azure](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/get-started/how-azure-resource-manager-works)  
[What is Azure Resource Manager?](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/overview)  

---

## Q038:

You are an IT administrator for a company that has recently migrated to Microsoft 365 and Azure. As part of the migration to Azure you enabled Microsoft Defender for Cloud in addition to utilizing Azure AD, Azure Key Vault and Azure Kubernetes Services (AKS). At present all these services are working well but your manager wants a unified solution to deliver security analytics and threat intelligence. You recommend integrating all the services with Microsoft Sentinel.
You need to onboard Microsoft Sentinel with the cloud services currently in use in the tenant.

Which built-in onboarding method should you use?

Choose the correct answer

- Enable the built-in connectors to the cloud native services.
- Configure Syslog.
- Deploy monitoring agents to all services.
- Create REST-APIS.

---

### Answer:

Explanation
You should enable the built-in connectors to the cloud native services. To onboard Microsoft Sentinel you initially need to connect to your various data sources. Microsoft Sentinel has multiple built-in connectors for Microsoft services that are available out of the box and provide real-time integration. Some of the connectors include Microsoft sources like Microsoft Defender for Cloud, Office 365, Azure Key Vault and Azure Kubernetes Services (AKS).
You should not deploy monitoring agents to all services. Microsoft Sentinel has an agent that can be installed, but only to virtual machines (VMs) and not the services in this scenario. The Microsoft Sentinel agent is actually the Log Analytics agent, which is installed on VMs to integrate them into Microsoft Sentinel.
You should not create REST-APIS. REST API integration is built by the provider and connects with the provider data. It is not a Microsoft Sentinel built-in method but could be utilized with it to integrate Microsoft services like the ones in this scenario.
You should not configure Syslog. You can stream events from Linux VMs as long as they support Syslog into Microsoft Sentinel. This is not a built-in method and it does not support any of the services in this scenario.


---

### References:

[What is Microsoft Sentinel?](https://learn.microsoft.com/en-us/azure/sentinel/overview?tabs=azure-portal)  
[Microsoft Sentinel data connectors](https://learn.microsoft.com/en-us/azure/sentinel/connect-data-sources?tabs=azure-portal)  
[Connect your data source to the Microsoft Sentinel Data Collector API to ingest data](https://learn.microsoft.com/en-us/azure/sentinel/connect-rest-api-template)  

---

## Q037:

You are a Solutions Architect for a company that has a hybrid estate with services hosted on-premises and in an Azure subscription with no existing monitoring. Your organization wants to use Azure Monitor to collect data from multiple services hosted in Azure and on premises.
You need to design a monitoring solution that is able to categorize the different data types according to its source.
Which data source will correspond to each description in your design? To answer, drag the appropriate data source to the correct description. Each data source may be used once, more than once, or not at all.

Drag and drop the answers

- Application
Infrastructure
Azure Platform
Custom Sources


Data description | Data source

Data about performance and functionality
- Application

Data about containers and guest OS
Infrastructure

Data about tenant-level operations
Azure Platform

Data that utilizes Azure Monitor REST APIs to send log data to Azure Monitor
Custom Sources

---

### Answer:

The - Application data type is the source for data about performance and functionality of your application code on any platform. Azure Monitor can collect data from multiple sources like Azure, non-Microsoft cloud, and on premises.
The Infrastructure data type is the source for data about containers such as Azure Kubernetes Service (AKS) and applications running inside containers. Data collected from guest OS systems on which applications run also qualify as Infrastructure data type.
The Azure Platform data type is the source for data from Azure resources, subscriptions and tenants. It is also the source of any data that relates to changes within your Azure resources and how to address incidents and issues.
The Custom sources data type uses the Azure Monitor REST API to send customer metric or log data to Azure Monitor and incorporate monitoring of resources.

---

### References:

[Design centralized logging and auditing](https://learn.microsoft.com/en-us/training/modules/design-solutions-security-operations/3-design-centralized-logging-auditing)  
[Azure Monitor overview](https://learn.microsoft.com/en-us/azure/azure-monitor/overview)  

---

## Q036:

Your client has implemented Microsoft Sentinel as its cloud-based Security Information and Event Management (SIEM). The client wants to maximize the value of their investment and has asked you how they can enhance the incident management lifecycle by cost-effectively detecting and responding to threats before they cause damage or disrupt their business.
You need to identify the Sentinel components that will help the client to reach this goal.
Which Sentinel tool should you recommend for each scenario? To answer, drag the appropriate tool to the correct incident management activity. Each tool may be used once, more than once, or not at all.

Drag and drop the answers

Notebook
Playbook
Workbook
Runbook

Automatically isolate an infected machine.
Playbook

Visualize and monitor threat data.
Workbook

Analyze data with Python machine learning.
Notebook

---

### Answer:

The client should use a playbook to automatically isolate an infected machine. A Sentinel playbook is a reusable set of steps to perform common security-related tasks, such as investigating and responding to incidents. Playbooks can be created using Logic - Apps Designer in Microsoft Sentinel and can be triggered manually or automatically in response to security events. Microsoft Sentinel allows you to create custom playbooks that are tailored to your organization's specific needs. For example, you could create a playbook that automatically responds to alerts about suspicious logins by obtaining more information about the user and their activity.
The client should use a workbook to visualize and monitor threat data. Microsoft Sentinel Workbooks, which is based on Azure Monitor Workbooks, is a reusable tool that you can use to visualize and analyze data from your Azure monitoring metrics. You can create workbooks containing multiple visuals and then save them so you can access them later. Workbooks are stored in JavaScript Object Notation (JSON) format and can be exported and imported from one Azure tenant to another.
The client should use a notebook to analyze data with Python machine learning. A Jupyter notebook is an interactive, web-based environment for code execution commonly used to develop machine learning tasks. Jupyter notebooks in Sentinel enable you to interactively analyze and visualize data in your workspace.

With Jupyter notebooks in Microsoft Sentinel, you can:

- Query and analyze data interactively.
- Visualize data to gain insights and better understand relationships.
- Build and share machine learning models.

The client should not use a runbook in any of these scenarios. A runbook is used in Azure Automation to define process automation. Runbooks can be written in PowerShell or Python or created using graphical tools.

---

### References:

[Automate threat response with playbooks in Microsoft Sentinel](https://learn.microsoft.com/en-us/azure/sentinel/automation/automate-responses-with-playbooks)  
[Use workbooks to visualize and monitor your data](https://learn.microsoft.com/en-us/azure/sentinel/monitor-your-data?tabs=azure-portal)  
[Use Jupyter notebooks to hunt for security threats](https://learn.microsoft.com/en-us/azure/sentinel/notebooks)  
[What is Azure Automation?](https://learn.microsoft.com/en-us/azure/automation/overview)  


---

## Q035:

Your company uses the following Azure subscriptions and services:

- Azure Active Directory
- Azure Firewall
- Microsoft Defender for Cloud

Your security team monitors data from the above services. As part of a regular security audit, you discover that the team spends an inordinate time manually searching for relevant threat vectors and events. Additionally, the team wastes valuable time responding to low-level security events. You suggest to senior management that the company should evaluate the benefits of implementing Microsoft Sentinel. However, management needs you to justify your recommendation.
Which Sentinel-supported technologies or tools should you include in your justification? To answer, select the appropriate options from the drop-down menus.

Choose the correct options
CDN 
SASTS
SND
SOAR
KQL

To automate threat responses: SOAR
To correlate and search threat data: KQL

---

### Answer:

To automate threat responses, you should include Security Orchestration, Automation and Response (SOAR) in your justification. SOAR refers to a coordinated approach to security management that combines various tools and technologies to streamline incident response. With the help of automation and orchestration, SOAR can rapidly absorb new information from diverse sources, identify patterns and correlations, and take the appropriate actions. This will help to reduce the company's reliance on manual processes and it will free up human resources for more strategic tasks.
To correlate and search threat data, you should include Kusto Query Language (KQL) in your justification. KQL is a declarative language used to query data in Microsoft Sentinel. It allows you to express simple or complex queries in a concise and easy-to-read manner. KQL is based on Structured Query Language (SQL) and provides powerful search capabilities across all your data, including unstructured data. You can use it to quickly find the information you need, without having to learn complex syntax or structure, thereby reducing the time the security team spends on searching for relevant threats.
You should not include content delivery networks (CDNs) in your justification. Azure CDN offers developers a global network of servers that can be used to cache and deliver content, such as images, media files, and application files, to users. When you use the Azure CDN, your content is cached on servers that are close to your users, which improves the performance and reliability of your applications.
You should not include Static - Application Security Testing (SAST) in your justification. SAST is a type of security testing that is performed on software code. SAST consists of scanning the source code or compiled version of the application to look for known vulnerabilities. The aim is to find security issues early in the development process, before the code is deployed.
You should not include Software Defined Networking (SDN) in your justification. SDN controller architectures allow you to manage networks in a more abstract way, which can make networking more flexible and simpler. SDN allows network administrators to remotely configure and manage network devices using software, rather than having to physically access each device. Azure Stack supports SDN.

---

### References:

[Security Orchestration, Automation, and Response (SOAR) in Microsoft Sentinel](https://learn.microsoft.com/en-us/azure/sentinel/automation/automation)  
[Kusto Query Language in Microsoft Sentinel](https://learn.microsoft.com/en-us/azure/sentinel/kusto-overview)  
[Azure Content Delivery Network](https://azure.microsoft.com/en-us/products/cdn/)  
[What do SAST, DAST, IAST and RASP Mean to Developers?](https://www.softwaresecured.com/post/what-do-sast-dast-iast-and-rasp-mean-to-developers)  
[Plan a Software Defined Network infrastructure](https://learn.microsoft.com/en-us/azure-stack/hci/concepts/plan-software-defined-networking-infrastructure)  


---

## Q034:

Your company deploys compute, network, and storage resources in Azure. You manage a security team and plan to use Microsoft Sentinel as a core component of your incident management lifecycle.
You need to identify incident classifications so that closed incidents are searchable and can be used to help resolve future incidents.
Which classification should you recommend for each of the scenarios below? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

Benign Positive
True Positive
False Positive

A user signs in after hours to access a sensitive document in preparation for a shareholder meeting.
Benign Positive

A penetration tester triggers a file integrity monitoring alert on a protected file server.
Benign Positive

A contractor sends proprietary product blueprints to a personal email address.
True Positive

---

### Answer:

If a user signs in after hours to access a sensitive document in preparation for a shareholder meeting, you should recommend that the incident be classified as Benign Positive. A Benign Positive event is triggered by suspicious activity. However, the event is expected and harmless. Microsoft Sentinel uses machine learning (ML) to minimize these types of events, but in some cases the final decision must be made by a security analyst.
If a penetration tester triggers a file integrity monitoring alert on a protected file server, you should recommend that the incident be classified as Benign Positive.
If a contractor sends proprietary product blueprints to a personal email address, you should recommend that the incident be classified as True Positive. This means that the event was suspicious and correctly triggered the incident response process.
None of these scenarios should be classified as False Positive. An incident should be classified as False Positive if the alert logic is incorrect or if the data supplied to Sentinel is incorrect.

---

### References:

[Investigate incidents with Microsoft Sentinel](https://learn.microsoft.com/en-us/azure/sentinel/investigate-cases)  
[What is Microsoft Sentinel?](https://learn.microsoft.com/en-us/azure/sentinel/overview?tabs=azure-portal)  
[Incident response overview](https://learn.microsoft.com/en-us/security/operations/incident-response-overview)  


---

## Q033:

Your company uses Azure to host sensitive workloads. Following a security breach where a known virus infected a server VM, the system administration team deploys off-the-shelf anti-malware software. The administration team ensures that signatures are updated daily, but the server suffers a zero-day virus infection.
You need to design a solution that mitigates similar future attacks.
Which recommendation should you include in your design?


- Create an anomaly detection policy.
- Create an application security group.
- Create a firewall application rule.
- Create an Microsoft Sentinel playbook.

---

### Answer:
- Create an anomaly detection policy.

You should recommend creating an anomaly detection policy. Anomaly detection is a feature offered by Microsoft Defender for Cloud. In this scenario, the anti-malware software has been implemented properly and is updated daily but is still vulnerable to zero-day attacks. A zero-day attack is one which is either not known to software or application developers or is publicly known but has not been remediated. Behavior- based detection aims to identify malicious activity based on seemingly unrelated events, as opposed to known indicators of compromise (IOCs).
You should not recommend creating an Microsoft Sentinel Playbook. A playbook is a reusable set of steps. to perform common security-related tasks, such as investigating and responding to incidents. Playbooks can be created using Logic app designer in Sentinel and can be triggered manually or automatically in response to security events. For example, you could create a playbook that automatically responds to alerts about suspicious logins by obtaining more information about the user and their activity.
You should not recommend creating a firewall application rule. Azure Firewall is a Next-Generation Firewall (NGFW) with full Intrusion Prevention System (IPS) capabilities. Azure Firewall uses application rules to define internet resources that can be accessed from a subnet.
You should not recommend creating an application security group (ASG) and assign a public IP. An ASG is a logical grouping of Azure resources that allows you to manage their security policies as a single unit.


---

### References:

[Anomaly detection policies in Defender for Cloud - Apps](https://learn.microsoft.com/en-us/defender-cloud-apps/anomaly-detection-policy)  
[Automate threat response with playbooks in Microsoft Sentinel](https://learn.microsoft.com/en-us/azure/sentinel/automation/automate-responses-with-playbooks)  
[Create Azure firewall rules](https://learn.microsoft.com/en-us/training/modules/introduction-azure-firewall/)  
[Azure - Application Security Group (ASG) Overview](https://medium.com/awesome-azure/azure-application-security-group-asg-1e5e2e5321c3)  

---

## Q032:

Your company uses Microsoft Defender for Cloud to monitor compliance status for its multi-cloud and hybrid cloud environments. Following a recent breach, an auditor reports that management ports on some VMs were not secured properly. Management has acknowledged the finding but seeks to understand how this vulnerability might have been exploited.
You need to perform a task to determine the MITRE ATT&CK tactics and techniques an attacker may have used.

What should you do?

Choose the correct answer

- Review the security initiative for VM management ports.
- Review the associated Defender for Cloud recommendation.
- Review the vulnerability in Azure Resource Graph Explorer.
- Review the Quick Fix recommendations for the finding.

---

### Answer:
- Review the associated Defender for Cloud recommendation.


You should review the associated Defender for Cloud recommendation. Security recommendations are used to map MITRE ATT&CK tactics and techniques. MITRE ATT&CK is a framework for understanding and describing the tactics and techniques used by malicious actors in cyberattacks. It can be used to help organizations identify and defend against threats, as well as to plan their own cybersecurity strategies. Defender for Cloud can evaluate your infrastructure against the policies you have defined and provide recommendations for remediating any vulnerabilities or misconfigurations that are discovered, including the tactics and techniques an attacker may use to exploit a vulnerability.
You should not review the security initiative for VM management ports. Security initiatives are used to group rules for a specific purpose or goal. Grouping rules, or policy definitions, simplifies the tasks of assigning and managing Azure Policy. A security initiative contains at least two policy definitions.
You should not review the Quick Fix recommendations for the finding. Depending on the recommendation, Defender for Cloud may offer a Quick Fix option for resolving the vulnerability identified in a recommendation. This option allows you to identify vulnerable resources and remediate risks almost instantly. The recommendations must be carefully reviewed before any fix is applied.
You should not review the vulnerability in Azure Resource Graph Explorer (ARG), ARG is a service that enables you to query your posture data in Azure at scale. With ARG, you can query Azure for all your resources and even organize them by resource type, location, subscription, or Resource Group.

---

### References:

[What are security policies, initiatives, and recommendations?](https://learn.microsoft.com/en-us/azure/defender-for-cloud/security-policy-concept)  
[What is Microsoft Defender for Cloud?](https://learn.microsoft.com/en-us/azure/defender-for-cloud/defender-for-cloud-introduction)  
[Manage your cloud security posture with Microsoft Defender for Cloud](https://learn.microsoft.com/en-us/training/modules/m365-security-azure-security-center/manage-cloud-posture)  
[Find recommendations that can improve your security posture](https://learn.microsoft.com/en-us/azure/defender-for-cloud/review-security-recommendations)  

---

## Q031:

You create a custom query in Microsoft Sentinel. As part of the query options configuration, you select the T1204 User Execution technique family, which includes the Malicious Link, Malicious File, and Malicious Image techniques.
Which statement correctly describes this activity?

Choose the correct answer

- You are using MITRE ATT&CK to perform threat hunting.
- You are using Jupyter notebooks to perform threat hunting.
- You are using the Advanced Security Information Model (ASIM) to perform threat hunting.
- You are using a JavaScript Object Notation (JSON) workbook to perform threat hunting.

---

### Answer:
- You are using MITRE ATT&CK to perform threat hunting.

You are using MITRE ATT&CK to perform threat hunting. MITRE ATT&CK is a framework for understanding and describing the tactics and techniques used by malicious actors in cyber attacks. It can be used to help organizations identify and defend against threats, as well as to plan their own cybersecurity strategies. You can create custom queries in Microsoft Sentinel that analyze threat data for MITRE ATT&CK techniques.
You are not using Jupyter notebooks to perform threat hunting. A Jupyter notebook is an interactive, web- based environment for code execution commonly used to develop machine learning tasks. Jupyter notebooks in Sentinel enable you to interactively analyze and visualize data in your workspace.
You are not using a JSON workbook to perform threat hunting. A Microsoft Sentinel workbook, which is stored in JavaScript Object Notation (JSON) format, is a reusable tool that you can use to visualize and analyze data from your Azure monitoring metrics. You can create workbooks containing multiple visuals, and then save them so you can access them later.
You are not using the Advanced Security Information Model (ASIM) to perform threat hunting. Sentinel uses ASIM to normalize log data ingested from various sources. This facilitates better event correlation.


---

### References:

[Hunt for threats with Microsoft Sentinel](https://learn.microsoft.com/en-us/azure/sentinel/hunting?tabs=azure-portal)  
[Use Jupyter notebooks to hunt for security threats](https://learn.microsoft.com/en-us/azure/sentinel/notebooks)  
[Use workbooks to visualize and monitor your data](https://learn.microsoft.com/en-us/azure/sentinel/monitor-your-data?tabs=azure-portal)  
[Normalization and the Advanced Security Information Model (ASIM) (Public preview)](https://learn.microsoft.com/en-us/azure/sentinel/normalization)  


---

## Q030:

Your company has implemented the recommended controls for common data exfiltration attacks on network boundaries and on servers that handle sensitive information. Despite these mitigations, proprietary corporate data has been extracted and shared with a competitor.
You need to design a solution that automates the detection of unauthorized activities, for example, if employees inadvertently access systems or information that they should not be able to access.

Which approach should you recommend?

- Configure Defender Endpoint detection and response (EDR) in block mode.
- Enable the User and Entity Behavior Analytics (UEBA) functionality in Microsoft Sentinel.
- Define regular expressions in Microsoft Purview.
- - Apply classification labels to sensitive data.

---

### Answer:
- Enable the User and Entity Behavior Analytics (UEBA) functionality in Microsoft Sentinel.

You should recommend your company to enable User and Entity Behavior Analytics (UEBA) in Microsoft Sentinel. UEBA uses artificial intelligence (AI) and machine learning algorithms to analyze user and entity behavior across different data sets in order to identify patterns of abnormal or unexpected behavior. This allows organizations to identify and respond to potential threats or security incidents more quickly. UEBA is often used to detect malicious activity, such as a data breach. However, it can also be used to detect non- malicious activities, such as employees accessing confidential information that they are not supposed to.
You should not recommend your company to configure Microsoft Defender for Endpoint detection and response (EDR) in block mode. This configuration provides an extra layer of endpoint protection when Microsoft Defender Antivirus is running on a system in passive mode. When EDR is in block mode, Microsoft Defender for Endpoint uses EDR logic and functionality to identify malware that the primary antivirus application may miss.
You should not recommend your company to define regular expressions in Microsoft Purview. Purview is a Microsoft service that helps organizations manage and protect their data. It provides centralized data discovery and cataloging capabilities that can help your company ensure its compliance with regulations such as the General Data Protection Regulation (GDPR). Purview also includes features for data classification and risk assessment, making it a comprehensive solution for data governance. While regular expressions, which are advanced data search filters, may help identify some sensitive information, it will not help identify system access.
You should not recommend your company to apply classification labels to sensitive data. Purview uses labels to identify and secure data. You can think of labels as tags that specify aspects such as data sensitivity and retention requirements. Like regular expressions, classification labels on their own will not meet the requirements stated in this scenario.

---

### References:

[Identify advanced threats with User and Entity Behavior Analytics (UEBA) in Microsoft Sentinel](https://learn.microsoft.com/en-us/azure/sentinel/identify-threats-with-entity-behavior-analytics)  
Endpoint detection and response in block mode
Create custom sensitive information types in the compliance portal
How to use the Microsoft data classification dashboard


---

## Q029:


You are a security architect for an organization that has an on-premises environment. The company is planning to migrate all its resources to Azure. Before the company can migrate workloads and resources to Azure, you have been asked to create a detailed design for the future Azure strategy. You decide to use the Azure Cloud Adoption Framework as well as the Microsoft Well-Architected Framework to help you with your design.
As part of your design you need to identify the key ways in which security will integrate with the larger organization according to the Cloud Adoption Framework Secure methodology.
Which security discipline does establishing a Zero Trust access model for modern and legacy assets using identity and networking controls sit under?

- Access control
- Security operations
- Security governance
- Asset protection

---

### Answer:
- Access control

According to the Azure Cloud Adoption Framework (CAF) Secure methodology, establishing a Zero Trust access model for modern and legacy assets using identity and networking controls sits under the access control security discipline.
Detecting, responding, and recovering from attacks as well as hunting for hidden threats and sharing threat intelligence sits under the security operations security discipline.
Protecting sensitive data and systems as well as continuously discovering, classifying, and securing assets sits under the asset protection discipline.
Continuously identifying, measuring, and managing security posture to reduce risk and maintaining compliance sits under the security governance security discipline.
---

### References:

[Cloud Adoption Framework secure methodology](https://learn.microsoft.com/en-us/training/modules/design-solutions-align-cloud-adoption-framework-well-architected-framework/3-cloud-adoption-framework-secure-methodology)  
[Microsoft Azure Well-Architected Framework](https://learn.microsoft.com/en-us/azure/well-architected/)  
[Design area: Azure governance](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/landing-zone/design-area/governance)  

---

## Q028:

You are a Cloud Architect for an organization that is planning on migrating to an Azure landing zone. Your team is currently designing the landing zone.
You need to define the tools and controls that will be deployed to ensure the organization achieves a security baseline as quickly as possible.

Which three Microsoft Tools should you recommend to meet the goal? Each correct answer presents part of the solution.

- Azure Firewall
- Privileged Identity Management (PIM)
- Route tables
- Exchange Online
- Microsoft Defender for Cloud

---

### Answer:
- Azure Firewall
- Privileged Identity Management (PIM)
- Microsoft Defender for Cloud

Security is an essential Azure landing zone accelerator and there are multiple tools and controls you can configure to assist in the journey of achieving a security baseline, in some cases much quicker than normal.
You can use Microsoft Defender for Cloud, both the standard and free tiers to help achieve security baselines. Microsoft Defender for Cloud combines development security operations (DevSecOps), cloud security posture management (CSPM), and cloud workload protection platform (CWPP) to help to protect your applications and resources against cyberthreats and vulnerabilities.
You can also use Azure Firewall to help to achieve security baselines. Azure Firewall is a cloud-native, stateful firewall as-a-service, that provides protection to your Azure workloads against network-related attacks and vulnerabilities.
You can also use privileged identity management (PIM) to help to achieve security baselines. PIM is a service that is part of Azure Active Directory (Azure AD) and it allows you to manage, control, and monitor access to resources within your Azure landing zone.
You should not recommend Microsoft Exchange Online. Microsoft Exchange Online is a SaaS application that is available as part of Microsoft 365 and is not intended to help to achieve security baselines. It is used to send email messages both internally and externally to allow your users to collaborate with teams, partners, and clients.
You should not recommend route tables. Route tables are a feature of virtual networks (VNets) that allow you to route network traffic both within your Azure landing zone and externally.

---

### References:

[Design area: Security](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/landing-zone/design-area/security)  
[What is an Azure landing zone?](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/landing-zone/)  
[What is Microsoft Defender for Cloud?](https://learn.microsoft.com/en-us/azure/defender-for-cloud/defender-for-cloud-introduction)  
[What is Azure Firewall?](https://learn.microsoft.com/en-us/azure/firewall/overview)  
[What is Azure AD Privileged Identity Management?](https://learn.microsoft.com/en-us/entra/id-governance/privileged-identity-management/pim-configure)  


---

## Q027:


You are a Security Architect for an organization with an on-premises infrastructure. The company plans to migrate services to an Azure landing zone over the next six to 12 months and needs to design the governance and security of the Azure landing zone. You are in charge of this project.
You are currently considering the security operations and need to define the scope to ensure that virtual machines adhere to National Cyber Security Centre (NCSC) Cloud Security Principle 5: Operational Security.

Which security operation scope do these requirements most likely align to?

- Security alerts
- Security controls
- Vulnerability management
- Encryption and keys

---

### Answer:
- Vulnerability management

The security operation scope of vulnerability management covers the context of:

- Emergency patching for critical vulnerabilities
- Patch for VMs that are offline for extended periods of time
- Vulnerability assessment for VMs

These three all adhere to the NCSC Cloud Security Principle 5: Operational Security, which considers vulnerability management, protective monitoring, incident management, and configuration and change management. The Microsoft Cloud Adoption Framework includes multiple security disciplines and guidance principles, including access control, Security assurances and security governance which all align with NCSC Cloud Security Principles.
There are multiple security operations as of the Cloud Adoption Framework when designing Azure landing zones. They cover multiple areas of security which align with the NCSC Cloud Security principles, including Security alerts, Security logs, Security Controls, Shared Responsibility and Encryption and keys.
The security alerts scope covers the following context:

- Which teams require notifications for security alerts?
- Do services need to be put into groups so alerts can be routed to different teams?
- Business requirements for real-time monitoring and alerting.
- Security information and event management integration with Microsoft Defender for Cloud and Microsoft Sentinel.

The encryption and keys scope tries to answer the questions of who requires access to keys in the environment and who will be responsible for managing those keys.
The security controls scope defines the baseline security configuration via Azure in-guest VM policy and considers how your security controls will align with governance guardrails.

---

### References:

[What is Operational Security?](https://www.fortinet.com/resources/cyberglossary/operational-security)
[Design area: Security](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/landing-zone/design-area/security)  
[What is an Azure landing zone?](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/landing-zone/)  
[Principle 5: Operational security](https://www.ncsc.gov.uk/collection/cloud/the-cloud-security-principles/principle-5-operational-security)  
[Security in the Microsoft Cloud Adoption Framework for Azure](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/secure/)  

---

## Q026:

You are an IT administrator working for an organization that has recently deployed an Azure subscription. The Dev team has started to deploy applications and services but would like to adopt DevOps models to increase the pace of innovation.
The SecOps team has asked you to review the existing deployments in Azure by the Dev team to ensure they meet security disciplines according to the Microsoft Cloud Adoption Framework.

Which Microsoft Cloud Adoption Framework security discipline must the Dev team adhere to before they can adopt DevOps models?

- Security Operations
- Access Control
- Innovation Security
- Security Governance

---

### Answer:
- Innovation Security

The Dev team must adhere to the Innovation Security security discipline. With this discipline, security needs to become an integral part of the DevSecOps process. It will require the organization to integrate security expertise and resources directly into the DevOps cycle and it will involve shifting decision making from central teams to enable workload-focused teams.
The Security Governance security discipline is not vital for the Dev team to adhere to before trying to adopt DevOps models. This discipline relates to making delegated decisions that allow organizations to accelerate innovation and introduce new risks.
The Security Operations security discipline is not vital for the Dev team to adhere to before trying to adopt DevOps models. This discipline requires organizations to monitor IT operation to detect, respond, and recover from any type of breach. They need to utilize data to continuously reduce the risk of a breach.
The Access Control security discipline is not vital for the Dev team to adhere to before trying to adopt DevOps models. This discipline requires that organizations apply network and identity control to create boundaries and segmentation to reduce the number of security breaches.

---

### References:

[Security in the Microsoft Cloud Adoption Framework for Azure](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/secure/)  
[Summary - Design solutions that align with the Cloud Adoption Framework (CAF) and Well-Architected Framework (WAF)](https://learn.microsoft.com/en-us/training/modules/design-solutions-align-cloud-adoption-framework-well-architected-framework/10-summary)  
[The Well-Architected Framework security pillar](https://learn.microsoft.com/en-us/training/modules/design-solutions-align-cloud-adoption-framework-well-architected-framework/7-well-architected-framework-security-pillar)  

---

## Q025:

You are a Security Operations Lead for a company that develops and deploys Azure Kubernetes Services (AKS). A recent security audit has recommended that the Dev team start to utilize the DevSecOps lifecycle stages to implement better security controls within their development.
You need to categorize the existing AKS deployment lifecycle tasks into the DevSecOps lifecycle stages.
Which current Dev team AKS deployment lifecycle task matches which DevSecOps lifecycle stage? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

AKS deployment task |  DevSecOps lifecycle stage

- Apply Azure Well-Architected Framework (WAF). : Plan Phase
Secure container images. : Develop Phase
Build new images on base image updates. : Build Phase
Keep deployment credentials secure. : Deploy Phase
Update Kubernetes clusters. : Operate Phase

---

### Answer:

The DevSecOps lifecycle has multiple stages which allow you to implement security controls in each phase of the software development lifecycle (SDLC). This is a key piece of the DevSecOps strategy.
- Applying Azure Well-Architected Framework (WAF) falls within the Plan Phase. The plan phase has the least amount of automation and has important security implications that will impact a lot of the late stages. - Applying the Azure Well Architected Framework (WAF) applies DevSecOps and monitoring to your environment which is why it comes under the plan phase.
Securing container images falls within the Develop Phase. The develop phase entails the 'Shift-left' approach which is a key aspect of the DevSecOps process. This phase comes before any code creation or deployment is even started, and requires you to adopt secure code and best practices using Integrated Development Environment (IDE) tools and plugins. Securing container images task falls within the develop phase as you are required to use trusted, lightweight base images when building containers.
Building new images on base image updates falls within the Build Phase. The build phase allows developers to work with security teams to integrate automated scans of their app source within their Continuous Integration (CI) build pipelines. Building new images on base image updates task belongs to the build phase as Azure Container Registry tasks dynamically discover base image dependencies when building a container image.
Keeping deployment credentials secure falls within the Deploy Phase. During the deploy phase, the developers and app operators work as a single team to establish the correct security controls for the Continuous Delivery (CD) pipelines. One example of this task is that the Development team can utilize OpenID Connect (OIDC) to allow GitHub action workflows to access resources in Azure without the need to store the credentials as a long-lived GitHub secret.
Updating Kubernetes clusters falls within the Operate Phase. The operate phase entails operation monitoring and security monitoring tasks that are proactively performed to monitor, analyze, and alert on any security incidents. Updating Kubernetes clusters fits in this phase because keeping services updated is essential so they do not fall behind or fall out of support.

---

### References:


[DevSecOps on Azure Kubernetes Service (AKS)](https://learn.microsoft.com/en-us/azure/architecture/guide/devsecops/devsecops-on-aks)  
[What is Azure Kubernetes Service?](https://learn.microsoft.com/en-us/azure/aks/what-is-aks)  


---

## Q024:

You are an IT Administrator for a company that uses Azure services. The organization has recently had a security audit that has recommended the company start to utilize DevSecOps process when developing and deploying Azure Kubernetes Services (AKS).
The following table details the users within the Dev team and their existing responsibility:

| Username  | Role description | 
|---|---|
| DevA | Responsible for writing the application code  |
| DevB | Responsible for building containers           |
| DevC | Responsible for creating and selecting Azure Policies |

As part of the DevSecOps process you need to first ensure members of the team have a defined role depending on the tasks they cover.
Which user's job description matches the DevSecOps team responsibilities? To answer, select the appropriate answer from the drop-down menus.

Choose the correct options

DevA : Developer
DevB : - Application operator
DevC : Security team

---

### Answer:

DevA should have the developer role, as they are responsible for writing the application code. They also have the responsibility for committing code to the designated repository.
DevB should have the application operator role. They are responsible for building application on the cloud by utilizing containers and Kubernetes to simplify application development, deployment, and scalability.
DevC should have the security team role. The security team is responsible for developing security standards and enforcing them by creating and selecting Azure Policies that is enforced at the subscription and resource group levels.
None of the team members have responsibilities that would come under a cluster operator role. This role is responsible for configuring and managing the cluster infrastructure and often use infrastructure as code (laC) best practices and frameworks.

---

### References:

[DevSecOps on Azure Kubernetes Service (AKS)](https://learn.microsoft.com/en-us/azure/architecture/guide/devsecops/devsecops-on-aks)  
[DevSecOps controls](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/secure/devsecops-controls)  

---

## Q023:

Your company plans to migrate to Microsoft 365.
You need to translate business governance goals into security requirements.
Which Microsoft assurance area should you recommend for each security requirement? To answer, drag the appropriate assurance area to each security requirement. An assurance area may be used once, more than once, or not at all.

Drag and drop the answers

Information Assurance
Operational Assurance
Control Assurance
Outcomes Assurance

To ensure that users can authenticate with minimal latency during a server failure:
Operational Assurance

To ensure that sensitive emails are protected from eavesdropping:
Information Assurance

To ensure that retention policies are compliant with all regulatory requirements:
Information Assurance

---

### Answer:

You should recommend operational assurance to ensure that users can authenticate with minimal latency during a server failure. Operational assurance focuses on ensuring that services are available and perform as expected. It often involves service or server redundancy and it is designed to ensure data resiliency. Assurance areas in Microsoft 365 are considered part of cloud governance.
You should recommend information assurance to ensure that sensitive emails are protected from eavesdropping. Information assurance protects data confidentiality and integrity. This may be required as a business imperative, to protect proprietary information, for example, or stipulated by regulatory standards and requirements.
You should recommend information assurance to ensure that retention policies are compliant with all regulatory requirements. This aspect of information assurance focuses on data availability. This ensures that data can be restored in the event of a loss or can be used in legal or other proceedings to maintain regulatory compliance.
You should not recommend outcomes assurance for any of the listed requirements. Outcomes assurance is supported by user training so that your employees understand organizational goals and can work towards those goals while protecting system and information security and compliance. Microsoft Purview can be used to manage data retention.
You should not recommend control assurance for any of the listed requirements. Control assurance is used to ensure that security controls are operating as expected.

---

### References:

[Create your collaboration governance plan](https://learn.microsoft.com/en-us/microsoft-365/solutions/collaboration-governance-first?view=o365-worldwide)  
[Data resiliency in Microsoft 365](https://learn.microsoft.com/en-us/compliance/assurance/assurance-data-resiliency-overview)  
[Govern your data with Microsoft Purview](https://learn.microsoft.com/en-us/purview/manage-data-governance)  


---

## Q022:

Your company hosts VM-based file, web, and database servers in the Azure cloud. You are concerned that employees accessing a general file server also have access to other servers that host sensitive information. Rather than deploy new permissions schemes on the servers, you want to mitigate this risk by ensuring the network design aligns with Zero Trust recommendations, as shown in the exhibit.

Your design must meet the following requirements:

- Limit user access to corporate file servers.
- Isolate other server workloads.
- Implement software-defined parameters.
- Reduce administrative overhead.

Which solution should you recommend?

Choose the correct answer

- The company should place each VM in an isolated VNet.
- The company should deploy VMs behind a jump box.
- The company should require a VPN for server access.
- The company should implement micro-segmentation.

![image info](./Q22.PNG)

---

### Answer:
- The company should implement micro-segmentation.

You should recommend implementing micro-segmentation. Micro-segmentation is a technique used for dividing a network into smaller, isolated segments. By doing this, you can further reduce the risk of data breaches and malware infections. With micro-segmentation, each segment is its own mini network with its own security controls. This isolates workloads, makes it much more difficult for attackers to move laterally within a network, and limits the impact of any breach.
You should not recommend placing each VM in an isolated virtual network (VNet). An Azure VNet is a private network in the cloud that you can use to deploy and manage your resources. A VNet provides you with an isolated and secure environment to run your applications and services. However, placing each VM in an isolated VNet is not part of Zero Trust and does not reduce administrative overhead. Common server VMs and their associated workloads can be located in the same VNet.
You should not recommend deploying VMs behind a jump box. A jump box is typically a hardened workstation that provides access to a secure network. In order to manage devices on the secure network, an administrator first connects to the jump box and then performs administrative tasks from that node. Jump boxes are also known as jump servers or bastion hosts.
You should not recommend requiring a Virtual Private Network (VPN) for server access. VPNs can be used to secure network communications, but this will not isolate the VMs from one another.

---

### References:

[Secure networks with Zero Trust](https://learn.microsoft.com/en-us/security/zero-trust/deploy/networks)  
[What is Azure Virtual Network?](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-overview)  
[Jump Box Security](https://www.linux-magazine.com/Online/Features/Jump-Box-Security/(language)/eng-US)  
[Remote work using Azure VPN Gateway Point-to-site](https://learn.microsoft.com/en-us/azure/vpn-gateway/work-remotely-support)  


---

## Q021:

Your company provides custom API development services. The network and system administration team regularly builds and tears down testing and production environments to support these projects. Recently, a configuration error resulted in a breach that quickly spread to multiple environments.
You have been asked to design an Azure landing zone architecture that will reduce this risk in the future. You need to recommend a process or method for storing network and system configurations centrally in standardized files. Your approach should be based on DevSecOps best practices.
Which option should you include in your recommendation?

Choose the correct answer

- Infrastructure as code
- Continuous delivery
- Continuous integration
- Infrastructure automation

---

### Answer:
- Infrastructure as code

You should recommend implementing infrastructure as code (laC). laC is an infrastructure management methodology that stores network and system configurations centrally in standardized files. The primary benefit of using laC is the facilitation of network orchestration creating, testing, and reviewing code prior to deployment. The code is also deployed in a predictable, repeatable, and often automated way. Implementing laC also reduces the occurrence of configuration mistakes.
You should not recommend implementing infrastructure automation. Infrastructure automation aims to reduce errors by using scripts to automate repetitive tasks. Infrastructure automation does not store network and system configurations centrally in standardized files. Azure Automation can be used to facilitate infrastructure automation.
You should not recommend implementing continuous integration (CI). This is part of Continuous Integration/Continuous Delivery (CI/CD), which is designed to ensure that functional code can be deployed at any time during the development process. Cl means that code updates are made frequently. Cl does not store network and system configurations centrally in standardized files.
You should not recommend implementing continuous delivery (CD). This is the second piece of CI/CD. CD means that up-to-date code can be deployed at any time. CD does not store network and system configurations centrally in standardized files.

---

### References:

[DevSecOps for infrastructure as code (laC)](https://learn.microsoft.com/en-us/azure/architecture/solution-ideas/articles/devsecops-infrastructure-as-code) 
[What is infrastructure as code (laC)?](https://learn.microsoft.com/en-us/devops/deliver/what-is-infrastructure-as-code)  
[What is Azure Automation?](https://learn.microsoft.com/en-us/azure/automation/overview)  
[CI/CD baseline architecture with Azure Pipelines](https://learn.microsoft.com/en-us/azure/devops/pipelines/architectures/devops-pipelines-baseline-architecture?view=azure-devops)  

---

## Q020:

Your international company plans to gradually migrate subsidiary company platforms and applications to Azure. To ensure operational efficiency, reduce administrative overhead, and mitigate the risk of misconfigured services or systems, you have been tasked with implementing Azure landing zone architectures.
You must ensure that your design follows globally-accepted benchmarks, such as ISO 27001. Additionally, deployments must be applicable at scale and across multiple subscriptions.
Which option should you use to meet this goal?

Choose the correct answer

- Azure Blueprints
- Access packages
- Azure Policy
- Artifacts

---

### Answer:
- Azure Blueprints

You should use Azure Blueprints. Azure Blueprints is a service that helps you manage and deploy cloud resources at scale in a consistent and repeatable way. It provides a collection of templates and best practices that you can use to build your own cloud deployments and is a perfect companion to Azure landing zones. Azure Blueprints also support security and compliance governance activities, including ISO 27001. You can use this blueprint to deploy artifacts such as role assignments, resource groups, and policy assignments in an automated, orchestrated fashion.
You cannot use Azure Policy alone to meet this goal. Azure Policy is a service in Azure that you can use to create, assign, and manage policy definitions. Policy definitions specify what resources will be validated against the desired conditions. Azure Blueprints can include Azure policies, but this is not required.
You cannot use artifacts alone to meet this goal. Artifacts are components of blueprint definitions. Artifacts might include resource groups, role assignments, policy assignments, and Azure Resource Manager (ARM) templates. Many artifacts can stand on their own, but only when contained in a blueprint definition can they be used to meet the goal stated in this scenario.
You should not use access packages. Access packages are used in Azure Active Directory (Azure AD) identity governance to provide a user with the resource access they need to complete a project.

---

### References:

[What is an Azure landing zone?](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/landing-zone/)  
[What is Azure Blueprints?](https://learn.microsoft.com/en-us/azure/governance/blueprints/overview)  
[What is Azure Policy?](https://learn.microsoft.com/en-us/azure/governance/policy/overview)  
[What is entitlement management?](https://learn.microsoft.com/en-us/entra/id-governance/entitlement-management-overview)  


---

## Q019:

You are Cloud Security Engineer for an organization that has an existing Microsoft 365 and Azure tenant where you host your data estate. In a recent security incident, a member user inadvertently leaked sensitive information. This led the organization to conduct a full security review and policy assessment on all the Microsoft 365 and Azure estate.
The report highlighted that there were no existing data loss prevention (DLP) policies. Sensitive information was not clearly defined within the tenant, and no 'High Severity' DLP alerts were configured.
You need to create a policy that solves the issues listed in the report.

Which policy template should you use?

Choose the correct answer

- Risky user template
- Security policy violations
- Data theft by departing users
- Data Leaks template

---

### Answer:
- Data Leaks template

You should use the Data leaks template. This policy template requires you to configure a minimum of one Microsoft Purview Data Loss Prevention (DLP) policies as well as define what is classified as sensitive information within your estate. You also configure it to receive insider risk alerts for 'High Severity' DLP policy alerts.
You should not use the Data theft by departing users template. This policy template requires you to configure the Microsoft 365 HR connector, which then imports resignation and termination date data for users within your estate.
You should not use the Security policy violation template. This policy template requires you to enable Microsoft Defender for Endpoint for insider risk management integration from within the Microsoft Defender Security Center. This then imports security violation alerts into the service.
You should not use the Risky users template. This policy template requires you to configure a Microsoft 365 HR connector, which then imports performance or demotion data for users within the company.

---

### References:

[Learn about insider risk management](https://learn.microsoft.com/en-us/purview/insider-risk-management?view=o365-worldwide)  
[Plan for insider risk management](https://learn.microsoft.com/en-us/purview/insider-risk-management-plan?view=o365-worldwide)  
[Microsoft Purview Insider Risk Management](https://www.microsoft.com/en-gb/security/business/risk-management/microsoft-purview-insider-risk-management)  

---

## Q018:

You are a Cloud Architect for an organization that hosts laaS, PaaS, and SaaS servicing within Azure and Microsoft Cloud. A recent security audit has made recommendations for the organization to start using the Zero Trust Rapid Modernization Plan (RaMP) as an alternative to deployment guides to enable key layers of protection within the existing cloud estate.

You have the following services within the estate for which you need to adopt Zero Trust:

| Service type | Microsoft service name |
|--------------|------------------------|
| Identity     | Azure AD |
| Endpoints    | Intune     |
| DevOps       | Azure DevOps |
| IoT devices  | Azure IoT |
| - Applications | Intune |

You need to ensure you prioritize the initiatives when following Zero Trust RaMP.
Which three service types should you look to modernize as a priority? 
Each correct answer presents part of the solution.

Choose the correct answers

- Identity
- Endpoints
- - Applications
- DevOps

---

### Answer:
- Identity
- Endpoints
- - Applications

You should modernize the Identity, Endpoint, and - Application services first. The Zero Trust Rapid Modernization Plan (RaMP) is an alternative to deployment guides that documents detailed configuration steps for all of the technology pillars that need to be protected by Zero Trust principles in Azure. There multiple initiatives that are categorized as 'Top Priority' and 'As needed'. The following initiatives are classed as 'Top Priority':
User access and productivity (this covers Identity, Endpoints, and - Applications)
Data, compliance, and governance
Modernize security operations
You should not prioritize DevOps and lot devices as these are deemed to be 'As needed' within the RaMP and are covered by the following initiatives:
OT and Industrial IoT
Datacenter & DevOps Security

---

### References:

[Zero Trust Rapid Modernization Plan](https://learn.microsoft.com/en-us/security/zero-trust/zero-trust-ramp-overview)  
[Introduction to Zero Trust](https://learn.microsoft.com/en-us/training/modules/introduction-zero-trust-best-practice-frameworks/2-introduction-zero-trust)  
[What is Azure Internet of Things (IoT)?](https://learn.microsoft.com/en-us/azure/iot/iot-introduction)  
[Data protection overview](https://learn.microsoft.com/en-us/azure/devops/organizations/security/data-protection?view=azure-devops)  

---

## Q017:

Your company purchases Surface laptops for all of its employees. The company requires that user systems be secured from emerging threats so you have recommended deploying - Application Guard.
You need to enhance the security stance of each device.
Which two statements should you include in your recommendation? Each correct answer presents a complete the solution.
Choose the correct answers

- - Application Guard relies on a locally installed Hyper-V instance to support security.
- - Application Guard forces untrusted resources to be opened in a secure container.
- - Application Guard is supported on end-user systems, including VDI deployments.
- - Application Guard can be used to define domains that host trusted applications.
- - Application Guard is only supported on systems running Windows 11 or later.

---

### Answer:
- - Application Guard forces untrusted resources to be opened in a secure container.
- - Application Guard can be used to define domains that host trusted applications.

- Application Guard can be used to define domains that host trusted applications and forces untrusted resources to be opened in a secure container. - Application Guard allows you to define domains and network ranges that host trusted applications, files, and web sites. Untrusted resources are opened in a Hyper-V container, or sandbox. This ensures that even if the resource contains or accesses malicious content, the local system will remain safe.
- Application Guard is supported on end-user systems as long as those systems do not form part of a virtual desktop infrastructure (VDI) deployment. - Application Guard is not supported for installation on VDI virtual machines (VMs).
- Application Guard is supported on systems running Windows 10 or Windows 11. - Application Guard can be installed on enterprise desktops, laptops, and Windows-based mobile devices.
- Application Guard does not rely on a locally installed Hyper-V instance to support security. The Hyper-V container is maintained separately from the user's operating system.

---

### References:

[Microsoft Defender - Application Guard overview](https://learn.microsoft.com/en-us/windows/security/application-security/application-isolation/microsoft-defender-application-guard/md-app-guard-overview)  
[System requirements for Microsoft Defender - Application Guard](https://learn.microsoft.com/en-us/windows/security/application-security/application-isolation/microsoft-defender-application-guard/reqs-md-app-guard)  
[Configure Microsoft Defender - Application Guard policy settings](https://learn.microsoft.com/en-us/windows/security/application-security/application-isolation/microsoft-defender-application-guard/configure-md-app-guard)  
[Microsoft Defender - Application Guard Extension](https://learn.microsoft.com/en-us/windows/security/application-security/application-isolation/microsoft-defender-application-guard/md-app-guard-browser-extension)  

---

## Q016:

You are an engineer for a small company that hosts it resources in a single Azure subscription. The company tenant has recently been subject to a systemic identity compromise attack where an attacker gained a foothold in Azure AD.

Your manager has asked you to map out the plan to respond to this attack and re-establish control of the Azure AD tenant without any additional third-party support.
Which four actions should you perform in sequence to meet the goal? To answer, move the appropriate actions from the list of possible actions to the answer area and arrange them in the correct order.
Create a list in the correct order

Possible actions
Log a support ticket with Microsoft.
Scan for malicious files.
Isolate the bad actor.

Actions in order
Establish secure communications.
Investigate your environment.
Improve security posture.
Regain / retain control.


---

### Answer:

You should perform the following steps in order to respond to the systemic identity compromise attack and re-establish control of the Azure Active Directory (Azure AD) tenant:
1. Establish secure communications
2. Investigate your environment
3. Improve security posture
4. Regain / retain control
The first step is to establish secure communications. Before taking any recovery action you should make sure that all members of the support team who are taking part in the investigation can securely communicate. Securing communications has to be your first step to allow you to proceed without the attacker's knowledge.
Next, you should investigate your environment. Once secure communications have been arranged for the main team members you should start looking into the attack, such as initial access points and persistence techniques.
Then, you should improve security posture for the tenant. You should enable security features and ensure you follow best practice guidelines and recommendations so you can improve security. You should also continue to monitor the environment as the security landscape changes.
Finally, you should regain / retain control of the environment. It is vital that you regain administrative control of Azure AD and the environment in general. Once you have control you need to ensure you refresh the estate's security posture and block all possible persistence techniques and new initial access exploits.
You should not log a support ticket with Microsoft. You would normally log a support ticket with Microsoft
for technical issues if parts of the estate are not working. However, it is not an essential part of the response plan and the scenario clearly states not to seek any third-party support.
You should not isolate the bad actor. Although as part of the investigation you may try to isolate the attacker, it is not a general step for the response to the attack.
You should not scan for malicious files. In the same way, scanning for malicious files may be a task that is completed as part of the remediation and improving security posture but it is not a general step within the response plan.

---

### References:

[Recovering from systemic identity compromise](https://learn.microsoft.com/en-us/azure/security/fundamentals/recover-from-identity-compromise)  


---

## Q013-Q015:

Your company uses Azure Synapse Analytics for data warehousing and data virtualization. Data analysts use the following Synapse resources:

- Dedicated SQL pools for big data analytics
- Serverless SQL endpoints for batch processing

You need to ensure that the Analytics deployment meets Azure Security Benchmark baseline requirements. Specifically, each Synapse resource should be accessible via a managed private endpoint.

---

## Q015:

Solution: You recommend deploying all SQL nodes in a common virtual network and that a P2S connection should be created between each endpoint and Azure Synapse Analytics.

Does this solution meet the goal?


---

### Answer: No

This solution does not meet the goal. Reaching Synapse resources via a managed private endpoint requires a Managed Virtual Network Workspace. This is a Synapse add-on feature that facilitates the creation of managed endpoints powerful compute nodes that are tailored to machine learning tasks. Point-to-Site (P2S) Virtual Private Network (VPN) gateway connections are designed to connect a single endpoint to an Azure virtual network.

---

### References:

[Azure security baseline for Synapse Analytics Workspace](https://learn.microsoft.com/en-us/security/benchmark/azure/security-baselines-overview)  
[What is Azure Express Route?](https://learn.microsoft.com/en-gb/azure/expressroute/expressroute-introduction)  
[Remote work using Azure VPN Gateway Point-to-site](https://learn.microsoft.com/en-us/azure/vpn-gateway/work-remotely-support)  

---

## Q014:

Solution: You recommend creating separate VNets for dedicated SQL pools and serverless SQL endpoints. VNets should be connected using Azure Express Route.

Does this solution meet the goal?

---

### Answer: No

This solution does not meet the goal. Reaching Synapse resources via a managed private endpoint requires a Managed Virtual Network Workspace. This is a Synapse add-on feature that facilitates the creation of managed endpoints powerful compute nodes that are tailored to machine learning tasks. In Azure, VNets are the basic building blocks for network segmentation and Azure Express Route lets you extend your on- premises and other-cloud networks into the Microsoft cloud over a secure, private connection.

---

### References:

[Azure security baseline for Synapse Analytics Workspace](https://learn.microsoft.com/en-us/security/benchmark/azure/security-baselines-overview)  
[What is Azure Express Route?](https://learn.microsoft.com/en-gb/azure/expressroute/expressroute-introduction)  
[Remote work using Azure VPN Gateway Point-to-site](https://learn.microsoft.com/en-us/azure/vpn-gateway/work-remotely-support)  

---

## Q013:


Solution: 
You recommend creating a Managed Virtual Network Workspace and that all dedicated and serverless pools should be located in the workspace.

Does this solution meet the goal?

---

### Answer: Yes

This solution meets the goal. Azure Synapse Analytics is an integrated Platform as a Service (PaaS) data platform that enables you to collect, clean, govern, analyze, and act on data in real time. It provides a single platform for data warehousing, big data analytics, and advanced analytics. Security for data stored in and processed by Synapse can be enhanced by implementing private endpoints. This approach is supported by the Azure Security Benchmark.
An Azure private endpoint is a network interface that connects your users privately and securely to a service powered by Azure Private Link. By deploying a Virtual Network Workspace for dedicated SQL pools and serverless SQL endpoints, you can ensure secure network segmentation. Data traversing a private link never traverses the public internet.

---

### References:

[Azure security baseline for Synapse Analytics Workspace](https://learn.microsoft.com/en-us/security/benchmark/azure/security-baselines-overview)  
[What is Azure Express Route?](https://learn.microsoft.com/en-gb/azure/expressroute/expressroute-introduction)  
[Remote work using Azure VPN Gateway Point-to-site](https://learn.microsoft.com/en-us/azure/vpn-gateway/work-remotely-support)  

---

## Q009-Q012:

> Overview

CompanyA is an online e-tailer that specializes in high-end fashion and accessories. In the past, CompanyA worked with clothing manufactures to drop ship purchases to customers, allowing it to focus on maintaining a lightweight online presence. However, it has recently acquired several boutique clothing manufacturers and wants to bring these acquisitions into the CompanyA environment as quickly as possible. This will require CompanyA to expand operations from strictly online sales and marketing to manufacturing and delivery. Additionally, the company has experienced dramatic expansion into European and Asian markets and wants to consolidate diverse on- premises and cloud resources in Azure.

> Existing Environment

CompanyA hosts all e-commerce servers in an on-premises data center located in North America. Its customers reside across the world and many of them use the CompanyA mobile app to browse and purchase items. This app sends requests to an API endpoint using HTTP or HTTPS. When a customer completes a purchase, a third-party transaction server connects to a remote credit card processor over TCP 6868. Backend data is stored on a custom Microsoft database and CompanyA has hired a remote DBA contractor to manage the database platform using RDP.
The current e-commerce site was recently hacked and an attacker was able to modify the descriptions for many products. A third-party security consulting firm was hired to perform an investigation and confirmed that the attacker modified the underlying database information.
Systems for the recently acquired clothing manufacturers are also hosted on-premises. These databases store clothing patterns and designs in document databases.

> Requirements

The existing e-commerce platform must be migrated to Azure. Once complete, access to the migrated workload must be protected by strict inbound and outbound traffic rules. It is anticipated that this functionality will be provided by Azure Firewall.
CompanyA is committed to a green, climate-friendly operation and has publicly announced that it will be carbon-neutral within three years. To comply with this goal, it plans to deploy loT sensors in the recently acquired clothing manufacturing plants. The sensors will monitor environmental conditions, including power consumption. Additionally, the sensors will monitor resource consumption, which will aid in procuring raw materials for the manufacturing process. As the sensors will have access to CompanyA's intellectual property, they must be secured from tampering. It is anticipated that these sensors will be managed by Azure IoT Hub Device Provisioning Service (DPS).
Given the recent database attack, CompanyA's management wants to ensure that the migrated system is secure and not susceptible to similar attacks in the future.
Clothing designs and patterns must be migrated to CosmosDB. To maximize security, this database must be segmented from other network traffic. The design for this database must meet the following requirements:

- On-premises analysts must have access to data stored in Cosmos DB.
- All network traffic must be segmented from the internet.
- Resource access must be mappable to a single database instance.


---

## Q012:

You need to design a solution for access to CosmosDB.
The solution should meet the following requirements:

- To extend your on-premises network into Azure, bypassing the internet
- To provide access to a single database instance

Which two technologies or components should you recommend for each stated requirement? Each correct answer presents part of the solution.

- Virtual network TAP
- Service endpoint
- Private Link
- Express Route

---

### Answer:
- Private Link
- Express Route

To bypass the internet and extend your on-premises network into Azure, you should recommend the deployment of Express Route. Azure ExpressRoute lets you extend your on-premises and other-cloud networks into the Microsoft cloud over a secure, private connection. You can create hybrid applications and architectures that include both cloud and on-premises services, and you can use Express Route to bypass the public internet and improve network performance.
To provide access to a single database instance, you should recommend the deployment of Private Link. Azure Private Link is a service that enables customers to securely access Azure platform as a service (PaaS) resources over a private endpoint hosted in their virtual network. Traffic between the customer's network and Azure services traverses over the Microsoft backbone, eliminating exposure from the internet. Customers can also leverage Private Link to break out egress traffic from an on-premises network using Express Route.
You should not recommend using a service endpoint. Service endpoints facilitate secure access to Azure resources from your virtual network. However, service endpoints are not used to provide access for on- premises users.
You should not recommend using a virtual network Terminal Access Point (TAP). An Azure VNet TAP allows you to passively monitor traffic sent between nodes by mirroring network traffic to a monitoring device for further analysis.


---

### References:

[What is Azure Express Route?](https://learn.microsoft.com/en-gb/azure/expressroute/expressroute-introduction)  
[What is Azure Private Link?](https://learn.microsoft.com/en-us/azure/private-link/private-link-overview)  
[Virtual Network service endpoints](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview)  
[Virtual network TAP](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-tap-overview)  

---

## Q011:

You must secure the e-commerce database.
What should you include in your recommendation?

- The web development team should run all submitted user requests through a link checker.
- The web development team should add input validation functions to the shopping cart page.
- The system security team should require TLS on all servers that host web content.
- The DBA should enable data execution prevention on all servers hosting website data.

---

### Answer:
- The web development team should add input validation functions to the shopping cart page.

The web development team should add input validation functions to the shopping cart page. In this scenario, the e-commerce platform has suffered a Structured Query Language (SQL) injection attack that has allowed a malicious user to modify database content. SQL injection occurs when malicious SQL statements are inserted into an application or website field. A SQL injection attack is designed to exploit application vulnerabilities and extract, modify, or delete database information. Input validation prevents such statements from executing against a database. Tools like Azure Web - Application Firewall (WAF) can perform input validation.
The web development team should not run all submitted user requests through a link checker. Link checking is used to mitigate phishing and other similar attacks by verifying that links in emails and documents are authentic and not malicious. Tools like Microsoft Defender verify links using a technique known as Uniform Resource Locator (URL) scanning.
The system security team should not require Transport Layer Security (TLS) on all servers that host web content. Transport encryption methods, such as Transport Layer Security (TLS), are used to ensure that data is encrypted as it travels between endpoints. Although this is best practice and is normally followed, it is not the ideal approach to mitigate the risk in this scenario.
The database administrator (DBA) should not enable data execution prevention on all servers hosting website data. Data execution prevention (DEP) marks certain areas in memory as non-executable, which prevents malicious code from running. DEP protects against buffer overflow attacks; it does not mitigate injection attacks.

---

### References:

[Web - Application Firewall DRS rule groups and rules](https://learn.microsoft.com/en-us/azure/web-application-firewall/afds/waf-front-door-drs?tabs=drs20)  
[Safe Links in Microsoft Defender for Office 365](https://learn.microsoft.com/en-us/defender-office-365/safe-links-about?view=o365-worldwide)  
[What is TLS (Transport Layer Security)?](https://www.cloudflare.com/learning/ssl/transport-layer-security-tls/)  
[Data Execution Prevention](https://learn.microsoft.com/en-us/windows/win32/memory/data-execution-prevention)  

---

## Q010:

You need to design a solution that ensures that the e-commerce application is secure.
Which Azure Firewall rule type should you recommend to meet each requirement? To answer, select the appropriate options from the drop-down menus.

To facilitate customer access to the API endpoint:
DNAT rule and network rule

To facilitate contractor access to the database server:
DNAT rule and network rule

To facilitate transaction server access to the credit card processor:
Network rule

---

### Answer:

To facilitate customer access to the - Application Programming Interface (API) endpoint, you should recommend creating a destination network address translation (DNAT) rule and a network rule. DNAT rules facilitate translation from a public firewall address and port to a private IP and port. This approach is commonly used to provide access to resources configured with private IPs. A network rule is a traditional layer 3/layer 4 rule based on protocols (TCP or UDP), ports, and IP addresses. While the DNAT rule facilitates network translation, the network rule allows the specified access to the API endpoint over ports 80 and 443.
To facilitate contractor access to the database server, you should recommend creating a DNAT rule and a
network rule. As with the API endpoint, inbound access to the database server's IP will require DNAT, and the network rule will be configured to allow TCP access over the Remote Desktop Protocol (RDP) port, 3389.
To facilitate transaction server access to the credit card processor, you should recommend creating a network rule. The network rule will allow outbound access to the credit card processor over TCP port 6868.
You should not recommend creating an application rule. Azure Firewall uses application rules to define internet resources that can be accessed from a subnet. In this scenario, if payment processing was handled over HTTP using the fully qualified domain name (FQDN) process.payments.com, for example, you could facilitate access to this FQDN using an application rule.

---

### References:


[Azure Firewall Policy rule sets](https://learn.microsoft.com/en-us/azure/firewall/policy-rule-sets)  
[Tutorial: Filter inbound Internet traffic with Azure Firewall policy DNAT using the Azure portal](https://learn.microsoft.com/en-us/azure/firewall/tutorial-firewall-dnat-policy)  
[Introduction to Azure Firewall](https://learn.microsoft.com/en-us/training/modules/introduction-azure-firewall/)  

---

## Q009:

You need to recommend a solution for securely deploying lot sensors.
Which three forms of attestation should you include in your recommendation for confirming each sensor's identity? 

- Password hashes
- Trusted Platform Module (TPM)
- Symmetric keys
- X.509 certificates
- Biometrics
- Multi-factor Authentication (MFA)

---

### Answer:
- Trusted Platform Module (TPM)
- Symmetric keys
- X.509 certificates

You should recommend using symmetric keys, Trusted Platform Modules (TPM), or X.509 certificates for the secure attestation of the Internet of Things (IoT) sensors. When you create an individual enrollment in Azure IoT Hub Device Provisioning Service (DPS), you are presented with three attestation mechanisms: X.509, TPM, and Symmetric Key.
A symmetric key in DPS is a base-64 encoded string. You can define your own symmetric keys or let DPS do it for you. A symmetric key is comparable to a password and must be kept private in order to ensure security.
TPM defines a standard and mechanism for storing secrets in purpose-built hardware or firmware. TPM functionality can also be emulated in software, but this approach is much less secure and is not recommended for production deployments. Due to their design and rigorous testing, TPMs are well-suited to environments where stringent security is required.
X.509 is a standard for defining and creating certificates in Public Key Infrastructure (PKI). An X.509 certificate can be self-generated or generated by a Certificate Authority (CA). A CA is a publicly trusted entity that uses its own methods for validating a certificate requestor prior to issuing the certificate. This allows an entity to present a certificate from a trusted third-party as a form of authentication.
You should not recommend using password hashes for the attestation of your lot sensors. Password hashes are irreversible strings created by hashing functions. Passwords are sometimes stored in hashed format to increase security. DPS does not support password hashes, but services like Azure Active Directory (Azure AD) do.
You should not recommend using Multi-factor Authentication (MFA) for the attestation of your lot sensors. MFA is an authentication method in which a user is granted access only after successfully presenting two or more pieces of evidence, or factors, to an authentication mechanism. The most common type of MFA combines something the user knows (such as a password) with something the user has (such as a code generated by an app on their phone). This is often referred to as two-factor authentication (2FA). Other types of MFA can include biometrics (something the user is), tokens, and smart cards. Azure AD supports MFA authentication. lot devices are not capable of providing multiple authentication factors.
You should not recommend using biometrics for the attestation of your lot sensors. Biometric authentication is a type of security that uses physical or behavioral characteristics to identify an individual. These characteristics can include fingerprints, retina scans, voice recognition, and facial recognition. Biometrics authentication relies on human characteristics, which lot devices cannot provide. Biometric authentication is considered more secure than traditional methods such as passwords and PINs because it is difficult to replicate physical or behavioral characteristics. Azure AD supports biometric
authentication.

---

### References:

[IoT Hub Device Provisioning Service (DPS) terminology](https://learn.microsoft.com/en-us/azure/iot-dps/concepts-service)  
[What is password hash synchronization with Microsoft Entra ID?](https://learn.microsoft.com/en-us/entra/identity/hybrid/connect/whatis-phs)  
[How it works: Microsoft Entra multifactor authentication](https://learn.microsoft.com/en-us/entra/identity/authentication/concept-mfa-howitworks)    
[Passwordless authentication options for Microsoft Entra ID](https://learn.microsoft.com/en-us/entra/identity/authentication/concept-authentication-passwordless)  

---

## Q004-008:

> Background:

CompanyA is a health services company with its main offices in Chicago and Nashville. The company provides physical therapy services to clients in their homes, typically following surgical procedures or as part of workers' compensation claims. Currently, it relies on branch offices in multiple locations to support therapists but it is gradually transitioning to a full mobile work environment. To support this effort, it has initiated a company-wide migration of all critical services to the cloud. This migration includes on- premises servers, user VMs, and the supporting management and monitoring appliances.

> Current Environment:

CompanyA has initiated its cloud migration and establishes an Azure Azure AD tenant. This Azure AD tenant is synchronized with Active Directory Domain Services (AD DS), which is maintained on on-premises domain controllers. As the migration progresses, additional Azure subscriptions will be created on an as-needed basis for each department. To facilitate their daily work, most employees have access to Microsoft 365 applications.
To support continued connectivity, basic Virtual Desktop Infrastructure (VDI) testing has been initiated for most categories of employees, such as account managers, support staff, and business, finance, and HR staff. Secure connectivity is supported via a Virtual Private Network (VPN) gateway for a limited set of users and devices. Additionally, a third-party firewall has been deployed to protect virtual server Virtual Local Area Networks (VLANS).
While they are on site with the clients, physical therapists use mobile devices with locally
stored tracking and monitoring data. This data is protected using proprietary storage
encryption, and each therapist is required to log on to their device using locally stored
credentials before accessing the data.

> Planned Changes:

As the cloud migration continues and expands, CompanyA plans to move all on-premises data to the cloud. The specific tasks planned for the next phase of the data migration include the following:
Client data:

- Protected Health Information (PHI) stored on mobile devices used by therapists will be moved to the cloud.

- Access to mobile devices while in the field should be restricted by geolocation.

- Data sharing between apps on the same device must be controlled.

- Compliance with the Health Insurance Portability and Accountability Act (HIPAA) and other regulations must be maintained regardless of data storage or usage locations.

As data and processing is moved to Azure, the VPN gateway must be configured to support secure P2S connections from devices that run a variety of desktop and mobile operating systems, including Windows, macOS, Android, and others. This will require defining which protocols are available depending on the device or devices being used.
Basic Virtual Desktop Infrastructure (VDI) has been completed and CompanyA plans to
expand its Azure Virtual Desktop footprint. During the pilot phase of testing, an employee installed an application that was packaged with a polymorphic virus. The malware moved laterally to other VDI instances and exfiltrated proprietary company data. This issue must be addressed before any additional VMs are deployed.
As part of the migration, server operating systems must be standardized. Servers must meet the following requirements:

- When new systems are provisioned, a secure baseline must be ensured.

- During testing of a base server virtual machine (VM), a quick vulnerability scan discovered that the system responds on non-standard ports. Such vulnerabilities must be addressed prior to widespread use.

- Management is concerned about Secure Shell (SSH) access to the server VMs and wants to disable direct inbound internet access for this protocol. Remote administrative access must be supported without exposing SSH using a public IP.

---

## Q008:

You need to recommend a solution for protecting SSH access to server VMs.
What should you include in your recommendation?

- Network security groups
- Azure Bastion
- Forced tunneling
- Just-in-time access

---

### Answer:
- Azure Bastion

You should recommend the deployment of Azure Bastion. Azure Bastion provides secure, Transport Layer Security protected (TLS-protected) remote access to your Azure virtual machines (VMs) from anywhere in the world. Bastion enables you to establish a secure connection to your VMs without having to deploy and manage a Virtual Private Network (VPN) or expose the VMs with public IP addresses. In this scenario, once Bastion is deployed, administrators can connect to the Bastion host using TLS, where they will have Secure Shell (SSH) connectivity to Azure VMs.
You should not recommend the deployment of network security groups (NSGs). An NSG is a virtual networking element that enables you to control the inbound and outbound traffic to resources in a virtual network using IP addresses, protocols, and ports. NSGs can be used to close off parts of your network to all traffic, or they can be used to allow specific types of traffic, while blocking all other traffic.
You should not recommend the deployment of forced tunneling. Forced tunneling allows you to control
how internet-bound traffic is routed from a VNet. For example, you could direct traffic to an Intrusion Prevention System (IPS) for deep packet inspection.
You should not recommend the deployment of just-in-time (JIT) access. JIT access requires the manual approval of every access attempt to specified ports on a VM. Each request comes with a limited lifetime, after which the ports are no longer reachable.

---

### References

[What is Azure Bastion?](https://learn.microsoft.com/en-us/azure/bastion/bastion-overview)  
[Network security groups](https://learn.microsoft.com/en-us/azure/virtual-network/network-security-groups-overview)  
[Azure Firewall forced tunneling](https://learn.microsoft.com/en-us/azure/firewall/forced-tunneling)  
[Implement Just-in-time VM access](https://learn.microsoft.com/en-us/training/paths/manage-security-operations-new/)  

---

## Q007:

You need to recommend a solution for addressing the server vulnerabilities.
What should you recommend?

- Installing a host-based intrusion detection system (HIDS)
- Deploying a network-based intrusion prevention system (NIPS) behind the server VLAN firewall
- Enabling data execution prevention on each server
- Uninstalling unused applications and services

---

### Answer:
- Uninstalling unused applications and services

You should recommend uninstalling unused applications and services. This is the best option for removing non-standard ports and reducing a server's attack surface. Among other sources, vulnerabilities are introduced by each application and service installed on a computer. Uninstalling these applications and services is known as system hardening.
You should not recommend installing a host-based intrusion detection system (HIDS). This will not eliminate unnecessary ports and services. A HIDS detects and alerts you of malicious activity.
You should not recommend deploying a network-based intrusion prevention system (NIPS) behind the server VLAN firewall. A NIPS typically sits in-line between trusted and untrusted networks and is designed to detect and prevent malicious network activity. In this scenario, the firewall should already be providing NIPS functionality.
You should not recommend enabling data execution prevention (DEP) on each server. This will not remove non-standard ports and unnecessary services. Data execution prevention marks certain areas in memory as non-executable, which prevents malicious code from running.

---

### References

[Review hardening recommendations](https://learn.microsoft.com/en-us/azure/defender-for-cloud/apply-security-baseline)  

[Security Control: Network Security](https://learn.microsoft.com/en-us/security/benchmark/azure/security-control-network-security)    

[What is Data Execution Prevention (DEP)?](https://support.microsoft.com/en-us/topic/what-is-data-execution-prevention-dep-60dabc2b-90db-45fc-9b18-512419135817)  

---

## Q006:

You need to recommend a solution that will mitigate the risks presented by Virtual Desktop Infrastructure (VDI).
For each mitigation requirement below, which solution should you recommend? To answer, select the appropriate options in the answer area.

To allow only reputable apps to run : WDAC
To manage apps that only run on Windows 8.1 : - AppLocker
To block.ps1, .vbs, and .js scripts : - AppLocker or WDAC
To control which apps a user can use : - AppLocker

---

### Answer:

You should use Windows Defender - Application Control (WDAC) to allow only reputable apps to run. WDAC uses policies to protect systems by controlling the applications, drivers, and scripts that are allowed to run on a system. Each policy is composed of rules that allow or deny behaviors, based on conditions you specify. WDAC can be configured to use Microsoft's Intelligent Security Graph (ISG) to identify applications with known bad, known good, or unknown reputations.
You can use - AppLocker to manage apps that run on Windows 8. - AppLocker was introduced in Windows 7. WDAC is only available on Windows 10 or later and Windows Server 2016 or later.
You can use - AppLocker or WDAC to block .ps1, .vbs, and .js scripts. PowerShell, Visual Basic, and JavaScript files are considered executables and can cause considerable harm if allowed to run without restrictions.
You can use - AppLocker to control which apps a user can use. This means that on shared devices, one user can be allowed to use an application, while any other shared users are prevented from using the application. WDAC policies apply to all users on a device.

---

### References

[Authorize reputable apps with the Intelligent Security Graph (ISG)](https://learn.microsoft.com/en-us/windows/security/application-security/application-control/windows-defender-application-control/design/use-wdac-with-intelligent-security-graph)  

[Requirements to use - AppLocker](https://learn.microsoft.com/en-us/windows/security/application-security/application-control/windows-defender-application-control/applocker/requirements-to-use-applocker)  

[Windows Defender - Application Control and - AppLocker Overview](https://learn.microsoft.com/en-us/windows/security/application-security/application-control/windows-defender-application-control/wdac-and-applocker-overview)  

[Windows Defender - Application Control and - AppLocker feature availability](https://learn.microsoft.com/en-us/windows/security/application-security/application-control/windows-defender-application-control/feature-availability)  

---

## Q005:

You need to specify which protocols are available for point-to-site (P2S) connections based on the operating system each client uses.
For each of the following statements, select Yes if the statement is true. 
Otherwise, select No.


Android, iOS, Windows, Linux, and macOS systems can connect using OpenVPN.
Planned Changes: Yes

Only Windows devices can connect using Secure Socket Tunneling Protocol (SSTP). : Yes

Only Windows and macOS devices can connect using Internet Key Exchange version 2 Virtual Private Network (IKEv2 VPN). : No

---

### Answer:

Android, iOS, Windows, Linux, and macOS systems can connect using OpenVPN. Azure supports point-to- site (P2S) connections via Virtual Private Network (VPN) gateways. Azure deploys VPN gateways as fully managed virtual machines (VMs) that can scale up or down based on client load. VPN gateways support P2S and site-to-site (S2S) connectivity. OpenVPN is an open-source project and offers the broadest client support for P2S connectivity.
Only Windows devices can connect using Secure Socket Tunneling Protocol (SSTP). SSTP is a type of VPN protocol that uses Transport Layer Security (TLS) for tunneling. It was introduced in Windows Vista Service Pack 1 and Windows Server 2008 and has been available in all subsequent versions of Windows.
As well as Windows and macOS devices, Linux, Android, and iOS devices can also connect using Internet Key Exchange version 2 (IKEv2) VPN. Azure VPN gateways do not support IKEv2 connections from Windows clients. The goal of IKE is to establish, negotiate, and agree upon the parameters of an authenticated and encrypted key-exchange for use in setting up a secure communications channel, such as that used in a VPN.

---

### References

[What is OpenVPN?](https://openvpn.net/faq/what-is-openvpn/)  
[About Point-to-Site VPN](https://learn.microsoft.com/en-us/azure/vpn-gateway/point-to-site-about)    
[What is Azure VPN Gateway?](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-vpngateways)  

---

## Q004:

You need to recommend a solution for managing client data stored on mobile devices.
Which two of the following should you include in your recommendation? Each correct answer presents part of the solution.

- Conditional Access policies
- - App protection policies (APP)
- User risk polices
- User and Entity Behavior Analytics (UEBA)
- Windows Defender - Application Control (WDAC) policies

---

### Answer:
- Conditional Access policies
- - App protection policies (APP)

You should recommend Conditional Access policies. Conditional Access is a security feature that helps you to control how users access your Azure resources. With conditional access, you can define the conditions under which users are allowed to access your resources and what actions they can take once they have accessed them. For example, you could allow users to access your resources only from certain locations or only during a certain timeframe.
You should also recommend app protection policies (APP). These are designed to protect apps and the data associated with those apps. This allows your organization's data, such as emails or files, to be protected when accessed from inside the app. APP can limit data sharing or prevent sharing altogether. Additionally, app-specific data can be encrypted. This way, if the device is lost or stolen, your organization's data remains safe.
You should not recommend User and Entity Behavior Analytics (UEBA). UEBA is a Microsoft Defender for Cloud - Apps feature that can be used to detect anomalous user behavior that may indicate malicious activity. For example, if a user normally logs on between the hours of 9:00 AM and 9:00 PM, and then suddenly logs on from a new Internet Protocol (IP) address at 3:00 AM, Defender for Cloud - Apps can be configured to generate an alert.
You should not recommend Windows Defender - Application Control (WDAC) policies. WDAC allows you to create a Windows environment in which only authorized applications can run on client computers. This helps to protect your systems from malicious or unapproved software.
You should not recommend user risk policies. User risk policies are designed to identify and alert on, or prevent risky user behavior. For example, a user attempting authentication using an anonymous Virtual Private Network (VPN).

---

### References:

[Using the location condition in a Conditional Access policy](https://learn.microsoft.com/en-us/entra/identity/conditional-access/concept-assignment-network)  

[- App protection policies overview](https://learn.microsoft.com/en-us/mem/intune/apps/app-protection-policy)    

[Anomaly detection policies in Defender for Cloud - Apps](https://learn.microsoft.com/en-us/defender-cloud-apps/anomaly-detection-policy)    

[Understand Windows Defender - Application Control policy design decisions](https://learn.microsoft.com/en-us/windows/security/application-security/application-control/windows-defender-application-control/design/understand-wdac-policy-design-decisions)    

[What are risk detections?](https://learn.microsoft.com/en-us/entra/id-protection/concept-identity-protection-risks)  

---

## Q001-003:

Your organization is part of a consortium in which each member actively performs threat hunting on their internal networks and systems.
You need to design a solution that allows cyber threat intelligence (CTI) feed to be shared between member threat intelligence platforms (TIPs) automatically. You must ensure that the solution employs industry- accepted formats and protocols and that it is supported by Microsoft Sentinel.


## Q003:

Solution: You define an alert action on the TIP source and specify Microsoft Sentinel as the target product. You provide an application ID and client secret to the TIP source.

Does this solution meet the goal?

---

### Answer: No

This solution does not meet the goal. This solution requires a directory ID before data can be pushed from the threat intelligence platform (TIP) source to Sentinel. This process uses the Microsoft Graph indicators - Application Programming Interface (API).

---

## Q002:

Solution: 

You retrieve the - Application Programming Interface (API) Root and Collection ID for the TIP server and configure a data connector in your target workspace.

Does this solution meet the goal?

---

### Answer: Yes

This solution meets the goal. Cyber threat intelligence (CTI) can be aggregated using an on-premises or cloud-hosted threat intelligence platform (TIP). This information can then be fed to Intrusion Detection System (IDS) and Intrusion Prevention System (IPS) systems and applications using rules and filters you define. Microsoft Sentinel can also ingest CTI using this approach.
This solution allows Microsoft Sentinel to pull CTI from a Trusted Automated Exchange of Intelligence Information (TAXII) server. TAXII is an industry standard protocol that can be used to share CTI over Hypertext Transfer Protocol Secure (HTTPS). TAXII clients can push and receive CTI from a centralized TAXII server.

---

## Q001:

Solution: 

You register an app and grant - Application 
Programming Interface (API) permissions to the app in Azure Active Directory (Azure AD). You use the client secret provided as part of the registration process to add the TIP source.

Does this solution meet the goal?
Yes - No

---

### Answer: NO

This solution does not meet the goal. This solution completes some of the steps required to configure an inbound Sentinel Cyber threat intelligence (CTI) feed. However, in addition to providing the client secret, you must also provide an application ID and directory ID. This information can be collected as part of the app registration process in Azure Active Directory (Azure AD).

---

### References:

[Connect your threat intelligence platform to Microsoft Sentinel](https://learn.microsoft.com/en-us/azure/sentinel/connect-threat-intelligence-tip)  

[Connect Microsoft Sentinel to STIX/TAXII threat intelligence feeds](https://learn.microsoft.com/en-us/azure/sentinel/connect-threat-intelligence-taxii)    

[Work with threat indicators in Microsoft Sentinel](https://learn.microsoft.com/en-us/azure/sentinel/work-with-threat-indicators)  

---


