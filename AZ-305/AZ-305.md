# AZ-305 Practice Test 169 Questions

---

## Q00X:

---

### Answer:

---

### References

---

## Q008-010:

A manufacturing company is looking to improve its manufacturing processes. lot sensors throughout the production line collect real-time data. The company wants to perform real-time data collection and analysis from these devices. The solution must support bi-directional communication to send commands back to the lot sensors.

You need to develop a data flow process to meet this requirement.

---

### References

[IoT Concepts and Azure IoT Hub](https://learn.microsoft.com/en-us/azure/iot-hub/iot-concepts-and-iot-hub)  
[Welcome to Azure Stream Analytics](https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-introduction)  
[Choose between Azure messaging services - Event Grid, Event Hubs, and Service Bus](https://learn.microsoft.com/en-us/azure/service-bus-messaging/compare-messaging-services)  
[Connecting IoT Devices to Azure: IoT Hub and Event Hubs](https://learn.microsoft.com/en-us/azure/iot-hub/iot-hub-compare-event-hubs)  
[Stream Azure monitoring data to an event hub or external partner](https://learn.microsoft.com/en-us/azure/azure-monitor/essentials/stream-monitoring-data-event-hubs)
[What is dedicated SQL pool (formerly SQL DW) in Azure Synapse Analytics?](https://learn.microsoft.com/en-us/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-overview-what-is)  

---

## Q010:

Solution: You configure an lot hub to receive the data and send the data to Azure Stream Analytics.

Does this solution meet the goal?

---

### Answer:
Yes

This solution meets the goal and the scenario requirements. The lot hub provides communication between the lot devices and Azure Stream Analytics. Azure Stream Analytics is a real-time event processing engine that can process a high volume of fast streaming data from a variety of sources. This allows for real-time analysis of telemetry streams for lot devices.

---

## Q009:

Solution: You configure an lot hub to receive the data and send the data to Azure Data Factory.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. An lot hub can be used to receive the data and stream it to a destination, but Azure Data Factory is not used for real-time data analysis. Azure Data Factory is a cloud- based extract-transform-load (ETL) and data integration service designed for data movement and large-scale data transformations.

---

## Q008:

Solution: You configure the lot sensors with an event hub and send the data to Azure Stream Analytics for analysis.

Does this solution meet the goal?

---

### Answer: 
No

This solution does not meet the goal. You can use an event hub for streaming data as an input to Azure Stream Analytics. However, an event hub does not provide bi-directional communication with lot devices.

---

## Q004-Q007:

> Overview

CompanyA sells building materials online and in retail outlets around the world. CompanyA's IT infrastructure is hosted in on-premises data centers in multiple locations. The CEO and CTO realize the potential of Microsoft Azure Cloud to increase the company's competitive advantage and eliminate security concerns.

> Existing Environment

- CompanyA operates public websites serving its online shop.
- An online shop web application is connected to an SQL database server in the backend.

- The company's Microsoft SQL database server holds a 100GB product catalog and online order data. Rapid growth of the database size is not planned.

- The Active Directory (AD) authentication provider is in place. The AD domain name is companya.com.
- Marketing documents, media files, and product manuals are stored on file share servers on-premises at the head office's location.

- Marketing documents are accessed via mapped drives on Windows 10 clients.

> Problem Statement

- The SQL database server is not highly available. Every outage means a drop in sales and loss in customer confidence.

- The online shop website's performance on Black Friday is slow. The Microsoft SQL database has been identified as the bottleneck.

- Searching the site when viewing many items on the page is slow.

- There are security concerns regarding the possible loss of financial and personal data due to the potential unauthorized access by support personnel or administrators of the SQL database content.

- Content on file share servers includes not only current files, but also historical data. This historical data is rarely accessed and is needed only in the case of requests relating to legal and compliance matters. Due to legal requirements, the historical data will have to be kept for seven years. This data occupies additional storage and is costly to manage.

- Some remote locations have a slow internet connection and, therefore, access to marketing documents from remote locations is very slow.
- Privileges and rights granted to users and identities are not supervised.

> Planned Changes

- The online shop web servers will be migrated into Azure Cloud.

- The SQL database servers will be migrated into Azure Cloud with the least amount of effort.

- Data security practices will undergo modernization according to industry standard best practices.

- Marketing documents will be migrated from file share servers onto the cloud.

- A solution to reduce costs for historical data on file shares is to be implemented.

> Technical & Business Requirements

- The SQL database must be highly available. Latency must be reduced. 

- CompanyA requires a solution to obtain real-time business insights about customers' purchasing behavior by analyzing data collected from its own online shop's website, social media channels, and partner websites.

> Security & Policy Requirements

- Legal regulations require customer data stored in Microsoft SQL Database to reside in the corresponding region of customer residence.
- All the data has to be secured at rest, in transit and in use.
- Compliance policy requires the retention of online order data for a minimum of seven years.
- Privileges and rights be granted to users and identities must be supervised.

---

## Q007:

In your solution design you need to recommend a solution to meet the technical requirements for Azure SQL Database.
Which solution for Azure database service tier should you recommend?

- Azure SQL Hyperscale
- Azure SQL Business Critical
- An SQL Server on an Azure Virtual Machine
- Azure SQL General Purpose
- Security and policy requirements

---

### Answer:
- Azure SQL Business Critical

You should recommend Azure SQL Business Critical tier. This Azure database service tier is designed to serve for mission-critical applications that require low latency and minimal downtime. This Azure database service tier utilizes Always On availability groups and high performance direct attached SSD storage. This is the best solution to meet the requirement in this scenario.
You should not recommend the Azure SQL General Purpose. This Azure database service tier provides budget-oriented balance between compute and storage. It utilizes multiple failover nodes with spare capacity. In the case of an outage, spare nodes can create a new SQL Server instance and the workload can be failed over. In addition to a higher latency compared to business critical architecture, this service tier introduces additional downtime to create a new SQL Server instance and failover workloads. In this scenario, especially for Black Friday, it is not acceptable.
You should not recommend the Azure SQL Database Hyperscale solution. This Azure database service tier is most suitable for rapid-changing storage needs, which can be rapidly scaled out up to 100TB. As the SQL database in this scenario is only 100GB and rapid growth is not expected, this service tier is not the solution you should recommend.
You should not recommend SQL Server on Azure Virtual Machine. This type of deployment is similar to what you have on premises, except that SQL server is running on an Azure virtual machine. This deployment is a one-server deployment with no guarantee of the required availability.

---

### References

[vCore purchasing model Azure SQL Database](https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tiers-sql-database-vcore?view=azuresql)  
[Design for Azure SQL Database](https://learn.microsoft.com/en-us/training/modules/design-data-storage-solution-for-relational-data/2-design-for-azure-sql-database)  
[What is an Always On availability group?](https://learn.microsoft.com/en-us/sql/database-engine/availability-groups/windows/overview-of-always-on-availability-groups-sql-server?view=sql-server-ver15)  
[Hyperscale service tier](https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tier-hyperscale?view=azuresql)  

---

## Q006:

You need to recommend a solution to include in your design to meet the security requirement for Azure SQL Database.

What should you recommend?

- SQL Elastic pools
- Azure Cosmos DB with multi-region writes
- Horizontal scaling by Sharding
- Elastic database tools
- Security and policy requirements

---

### Answer:
- Horizontal scaling by Sharding

You should recommend to include Horizontal scaling by Sharding in your SQL database design. Horizontal scaling by Sharding provides a solution to partition (sharding) a database into multiple databases, which can be scaled independently. The Sharding solution utilizes a special database named shard map manager, which maintains global mapping information about all shards (databases) in a shard set. The application uses this shard map to save data into the proper shard. In this scenario, with Sharding, you meet the legal regulations to maintain customer data in the region of respective customer residence by placing each shard with data in the region of customer residence.
You should not recommend SQL Elastic pools. SQL Elastic pools provide a mechanism to scale computer power up or down for SQL Database as needed. In this scenario, SQL Elastic pools cannot meet the requirement for customer data residence as providing more or fewer compute resources does not change the residence of the data. For this specific requirement, you have to implement Horizontal scaling by Sharding in your SQL database design.
You should not recommend Elastic database tools. Elastic database tools provide the solution to query data across multiple databases and provide output to Microsoft Excel or third-party tools for visualization. Elastic database tools have no influence on the data residency, and as such it cannot meet this requirement.
You should not recommend Azure Cosmos DB with multi-region writes. Azure Cosmos DB is a NoSQL database, which provides real-time access, multi-region writes and data distribution to any Azure region, and it can scale storage and throughput across any Azure region elastically and independently. Azure Cosmos DB can provide the best solution for mobile, gaming and lot applications. Although there are possibilities to migrate data from SQL Server to Azure Cosmos DB and implement data residency restrictions, it would be very expensive in terms of efforts and costs. In the given scenario, it is required for the data to reside in the region of corresponding customer residence and the SQL database migration needs to be executed with the least amount of effort.

---

### References

[Recommend a solution for database scalability](https://learn.microsoft.com/en-us/training/modules/design-data-storage-solution-for-relational-data/5-recommend-database-scalability)  
[Welcome to Azure Cosmos DB](https://learn.microsoft.com/en-us/azure/cosmos-db/introduction)  
[Understanding distributed NoSQL databases](https://learn.microsoft.com/en-us/azure/cosmos-db/distributed-nosql)  

---

## Q005:

You are tasked with remediating the security concerns and implement data security requirements.

Which three encryption solutions should you include in your design? Each correct answer presents part of the solution.

- Always Encrypted
- Server-level firewall
- Network security groups (NSGs)
- Transparent Data Encryption (TDE)
- SSL-Secure Sockets Layer/TLS - Transport Layer Security


---

### Answer:

- Always Encrypted
- Transparent Data Encryption (TDE)
- SSL-Secure Sockets Layer/TLS - Transport Layer Security

To remediate the security concerns for data-at-rest you should recommend Transparent Data Encryption (TDE). To ensure data privacy, data sovereignty, and data compliance it is indispensable and mandatory to encrypt data at rest. TDE provides such a data encryption capability for data at rest and, as such, the data is protected from the unauthorized access of raw offline database files on a hard disk or a backup copy. The encryption is performed by TDE on a page level (logical partitioning of the data within a data file (.mdf or .ndf) in a database, numbered contiguously from 0 to n), so that data is encrypted as it is written from memory to the disk and decrypted as it is read from the disk to memory.
To remediate the security concerns for data-in-use you should also recommend Always Encrypted. Always Encrypted is a security technique to hide sensitive data stored in specific database columns. The data can be only decrypted while it is loaded into memory of a client computer and processed by a client application. This technique protects data also from administrators or other support personnel that are authorized to access databases for maintenance.
To remediate the security concerns for data-in-transit you should, additionally, recommend SSL/TLS. This encryption provides protection of data from man-in-the-middle (MITM) or side channel attacks during data transportation from the backend SQL database server to the front end application server.
You should not recommend a server-level firewall. Although server-level firewalls protect from unauthorized access by end-users, it does not protect from unauthorized access by support personnel or administrators. Server-level firewalls work on the network layer, which is layer 3 of the International Standardization Organization (OSI) reference model. As an administrator, you must have access to the server in order to be able to pass by firewall for SQL server maintenance.
You should not recommend Network security groups (NSGs). Using an NSG in Azure you can filter network traffic between Azure resources, such as virtual machines within a virtual network (VLAN). The functionality of an NSG is similar to the functionality of a firewall. Similar to firewalls, NSGs can prohibit access by any unauthorized user or resource, but it cannot prohibit access by support personnel or administrators.
References
Design security for data at rest, data in motion, and data in use
Protect data in-transit and at rest
Windows Network Architecture and the OSI Model

---

### References

[Network security groups](https://learn.microsoft.com/en-us/azure/virtual-network/network-security-groups-overview)   

---

## Q004:

You need to recommend a storage design solution on the Azure Cloud platform for the marketing documents. Administrative effort and cost must be minimized.

What should you recommend?

- Azure Files
- Azure Queue Storage
- Azure managed disks
- Azure Blob Storage

---

### Answer:
- Azure Files

You should recommend Azure Files as a storage design solution for the marketing documents. Azure Files is a file share hosted on the Azure Cloud platform. Files hosted in Azure Files can be accessed via an industry- standard Server Message Block (SMB) protocol for file sharing. SMB allows applications to read and write to files in a computer network. Azure Files can be mapped as a shared drive on all main operating systems and thus can replace the company's on-premises file shares. In this scenario, marketing documents are accessed via mapped drives on Windows 10 clients, as such Azure Files is the best replacement solution.
You should not recommend Azure Blob Storage. Azure Blob Storage is an object-oriented storage solution.
It is optimized to store unstructured data, such as large binary files, media files, log files, and backup files. Unlike Azure Files, Azure Blob Storage cannot be mapped as a shared drive, which is the main reason why, in this scenario, it is not the ideal storage solution for the marketing documents.
You should not recommend Azure managed disks. Azure managed disks are block-level storage volumes used by virtual machines to store data. Usually, you create Azure managed disks at the same time as a virtual machine.
You should not recommend Azure Queue Storage. Azure Queue Storage is a service to provide an interface for service-to-service communication. Azure Queue Storage can store a large amount of messages and can be accessed from anywhere using the HTTP or HTTPS protocols.

---

### References

[Design for data storage](https://learn.microsoft.com/en-us/training/modules/design-data-storage-solution-for-non-relational-data/2-design-for-data-storage)  
[Design for Azure Files](https://learn.microsoft.com/en-us/training/modules/design-data-storage-solution-for-non-relational-data/6-design-for-azure-files)  
[Design for Azure Blob Storage](https://learn.microsoft.com/en-us/training/modules/design-data-storage-solution-for-non-relational-data/5-design-for-azure-blob-storage)  
[Design for Azure managed disks](https://learn.microsoft.com/en-us/training/modules/design-data-storage-solution-for-non-relational-data/7-design-for-azure-disk-solutions)  
[What is Azure Queue Storage?](https://learn.microsoft.com/en-us/azure/storage/queues/storage-queues-introduction)  
[Overview of file sharing using the SMB 3 protocol in Windows Server](https://learn.microsoft.com/en-us/windows-server/storage/file-server/file-server-smb-overview)  

---

## Q001-Q003:

Your organization is moving its business operations to Azure. Your company is organized into three departments that will deploy Azure app services and databases. A fourth department is responsible for internal operations and will deploy resources as necessary to support those activities.
Your company wants to be cost-conscious in its move to the cloud, and exercise cost and budget controls at the department level. The company plans to use the Azure Resource Usage and Rate Card APIs to colle billing data for analysis.

Initially, you set up your company's Azure with one subscription.

You need to design a solution for cost reporting by department. 
The solution should follow best practices for organizing resources and should minimize the effort required to maintain the solution.

---

### References

[Organize your Azure resources effectively](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-setup-guide/organize-resources?tabs=AzureManagementGroupsAndHierarchy)  
[Resource naming and tagging decision guide](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/resource-naming-and-tagging-decision-guide)  
[Track costs across business units, environments, or projects](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/track-costs)  
[Use tags to organize your Azure resources and management hierarchy](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/tag-resources)  

---

## Q003:

Solution: You create a separate resource group for each type of resource, and tag the resources with department and billing code.

Does this solution meet the goal?

---

### Answer:
Yes

This solution meets the goal. You can create a separate resource group for each type of resource, and tag the resources with department and billing code. Microsoft's best practices recommend various options for organizing resources into resource groups, such as by resource type, by project, by lifecycle, and so forth. The use of tags lets you organize the data, and retrieve data by department for cost accounting and budgeting purposes.

---

## Q002:

Solution: You create a separate resource group for each department to host that department's resources, and limit access to the resource group through Azure role-based access control (Azure RBAC).

Does this solution meet the goal?

---

### Answer:
No

The solution does not meet the goal. You should not create a separate resource group for each department to host that department's resources, and limit access to the resource group through Azure RBAC. Organizing by department is an acceptable way of organizing resources, but it does nothing toward retrieving and reporting cost accounting and budget information. Azure RBAC is used to control and manage access to resources, but it does not retrieve the information you need.

---

## Q001:

Solution: 
You create a separate subscription for each department, and use resource groups to organize resources by project.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. You should not create a separate subscription for each department, and use resource groups to organize resources by project. Creating separate subscriptions for each department adds administrative overhead. Organizing by project is an acceptable way of organizing resources, but it does nothing toward retrieving and reporting cost accounting and budget information.

---
