<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# You are developing an Azure Kubernetes Service (AKS) microservice application that uses certificates and API keys stored in Azure Key Vault.

Application development includes the following four environments:

- Development
- Test
- Staging
- Production

You need to configure key vaults.
How many key vaults should you use?

1
2
3
4

The recommended approach is to use one Azure Key Vault per environment, which means you should have four separate key vaults—one each for Development, Test, Staging, and Production environments. This provides strong isolation, minimizes the risk of accidental cross-environment access, and reduces the impact if a security incident occurs in one environment.[^1_1][^1_2][^1_3][^1_4]

### Summary Table

| Environment | Recommended Key Vault Count |
| :-- | :-- |
| Development | 1 |
| Test | 1 |
| Staging | 1 |
| Production | 1 |

So, you should use a total of **4** key vaults—one per environment.[^1_2][^1_3][^1_4][^1_1]
<span style="display:none">[^1_10][^1_11][^1_12][^1_13][^1_14][^1_15][^1_16][^1_17][^1_18][^1_19][^1_20][^1_5][^1_6][^1_7][^1_8][^1_9]</span>

<div align="center">⁂</div>

[^1_1]: https://learn.microsoft.com/en-us/azure/key-vault/general/best-practices

[^1_2]: https://notes.kodekloud.com/docs/AZ-204-Developing-Solutions-for-Microsoft-Azure/Implementing-Azure-Key-Vault/Azure-Key-Vault-Best-Practices

[^1_3]: https://www.cloudthat.com/resources/blog/introduction-to-azure-key-vault-detailed-explanation-with-case-studies/

[^1_4]: https://developersvoice.com/blog/secure-coding/managing-secrets-dotnet-applications/

[^1_5]: https://learn.microsoft.com/en-us/azure/key-vault/secrets/secrets-best-practices

[^1_6]: https://www.reddit.com/r/AZURE/comments/139c0gp/use_azure_key_vault_for_every_single_microservice/

[^1_7]: https://learn.microsoft.com/en-us/answers/questions/77182/key-vault-for-multiple-app-service-should-i-create

[^1_8]: https://stackoverflow.com/questions/43901390/azure-key-vault-multiple-environments-do-i-need-a-azure-key-vault-for-each-en

[^1_9]: https://www.youtube.com/watch?v=I-ka1q3xIvc

[^1_10]: https://learn.microsoft.com/en-us/azure/key-vault/general/developers-guide

[^1_11]: https://www.examtopics.com/discussions/microsoft/view/46496-exam-az-304-topic-2-question-2-discussion/

[^1_12]: https://stackoverflow.com/questions/75473253/is-it-approriate-to-create-separate-azure-key-vaults-in-different-azure-environm

[^1_13]: https://intercept.cloud/en-gb/blogs/azure-key-vault

[^1_14]: https://www.tp.com/en-us/insights-list/insightful-articles/global/azure-key-vault-a-deep-dive-into-access-policies-and-rbac/

[^1_15]: https://northflank.com/blog/what-are-dev-qa-preview-test-staging-and-production-environments

[^1_16]: https://docs.azure.cn/en-us/reliability/reliability-key-vault

[^1_17]: https://docs.azure.cn/en-us/security/fundamentals/secrets-best-practices

[^1_18]: https://learn.microsoft.com/en-us/azure/devops/pipelines/release/azure-key-vault?view=azure-devops

[^1_19]: https://www.reddit.com/r/AZURE/comments/xlr0gd/should_i_create_one_keyvault_per_service_for_an/

[^1_20]: https://docs.gitguardian.com/ggscout-docs/integrations/secret-managers/azure-key-vault


---

# You are developing an application that includes feature management.

You need to implement a feature flag.

Which two components should you configure? Each correct answer presents part of the solution.

Select all answers that apply.

1) name
2) keys and values
3) labels
4) list of filters
5) list of snapshots

To implement a feature flag, you need to configure two key components: the flag's name and its associated keys and values. The name uniquely identifies the flag within your configuration, and keys and values define the flag's state and logic, such as whether the feature is enabled or disabled.[^2_4][^2_5]

So, the correct answers are:

1) name
2) keys and values
<span style="display:none">[^2_1][^2_2][^2_3][^2_6][^2_7][^2_8][^2_9]</span>

<div align="center">⁂</div>

[^2_1]: https://www.reddit.com/r/ExperiencedDevs/comments/1cb2mzm/what_is_the_ideal_way_to_add_implementation/

[^2_2]: https://launchdarkly.com/blog/what-are-feature-flags/

[^2_3]: https://martinfowler.com/articles/feature-toggles.html

[^2_4]: https://fullscale.io/blog/feature-flags-implementation-guide/

[^2_5]: https://docs.getunleash.io/topics/feature-flags/feature-flag-best-practices

[^2_6]: https://blog.railway.com/p/implement-feature-flags-from-scratch

[^2_7]: https://docs.gitlab.com/operations/feature_flags/

[^2_8]: https://carbondesignsystem.com/components/overview/feature-flags/

[^2_9]: https://frontegg.com/guides/feature-flags


---

# You are developing an Azure-based application that stores all application settings in the Azure App Configuration service.

You provision a standard tier Azure App Configuration instance and enable the customer-managed key capability on the instance.
You need to allow the Azure App Configuration instance to use an Azure Key Vault key.

Which two actions should you perform? Each correct answer presents part of the solution.
Select all answers that apply.

1) Enable the purge-protection feature on the Azure Key Vault.
2) Assign a managed identity to the Azure App Configuration instance.
3) Configure a private endpoint for the Azure App Configuration instance.
4) Configure managed identity permission to access the Azure Key Vault.
5) Create a DNS CNAME resource record for the Azure App Configuration instance.

The two actions you should perform to allow the Azure App Configuration instance to use an Azure Key Vault key are:

2) Assign a managed identity to the Azure App Configuration instance.
3) Configure managed identity permission to access the Azure Key Vault.

Assigning a managed identity enables the Azure App Configuration instance to authenticate securely with Azure Key Vault, and configuring the managed identity's permissions allows it to access the encryption key stored in Key Vault. Purge protection is also recommended but is not a required configuration step for the direct integration, while private endpoints and DNS records are not required for this capability.[^3_1][^3_2][^3_3]
<span style="display:none">[^3_10][^3_11][^3_12][^3_13][^3_14][^3_15][^3_16][^3_17][^3_18][^3_19][^3_20][^3_4][^3_5][^3_6][^3_7][^3_8][^3_9]</span>

<div align="center">⁂</div>

[^3_1]: https://docs.azure.cn/en-us/azure-app-configuration/concept-customer-managed-keys

[^3_2]: https://learn.microsoft.com/en-us/azure/azure-app-configuration/concept-customer-managed-keys

[^3_3]: https://learn.microsoft.com/en-us/azure/key-vault/general/soft-delete-overview

[^3_4]: https://learn.microsoft.com/en-us/azure/azure-app-configuration/use-key-vault-references-dotnet-core

[^3_5]: https://learn.microsoft.com/en-us/samples/azure/azure-sdk-for-net/app-secrets-configuration/

[^3_6]: https://learn.microsoft.com/en-us/azure/app-service/app-service-key-vault-references

[^3_7]: https://docs.azure.cn/en-us/azure-app-configuration/use-key-vault-references-spring-boot

[^3_8]: https://dev.to/vengi83644/how-to-setup-azure-app-configuration-and-key-vault-in-a-net-core-project-724

[^3_9]: https://stackoverflow.com/questions/71042960/allow-managed-app-consumer-access-to-read-write-key-vault-secret

[^3_10]: https://sysadmin-central.com/2024/12/16/azure-key-vaults-made-safer-how-to-enable-soft-delete-and-purge-protection/

[^3_11]: https://stackoverflow.com/questions/75723724/how-to-use-properly-azure-app-configuration-with-key-vault-reference-in-a-functi

[^3_12]: https://learn.microsoft.com/en-us/azure/frontdoor/managed-identity

[^3_13]: https://docs.prismacloud.io/en/enterprise-edition/policy-reference/azure-policies/azure-general-policies/ensure-that-key-vault-enables-purge-protection

[^3_14]: https://learn.microsoft.com/en-us/azure/azure-app-configuration/reload-key-vault-secrets-dotnet

[^3_15]: https://experienceleague.adobe.com/en/docs/experience-platform/landing/governance-privacy-security/customer-managed-keys/azure/azure-key-vault-config

[^3_16]: https://www.aligneddev.net/blog/2022/azure-appconfiguration-keyvault-managedidentity/

[^3_17]: https://blog.yaseerarafat.com/net-secrets-management-with-azure-app-configuration-key-vault-0597a5bcf6b3

[^3_18]: https://www.youtube.com/watch?v=8gVqYnGl0O0

[^3_19]: https://docs.azure.cn/en-us/storage/common/customer-managed-keys-configure-existing-account

[^3_20]: https://learn.microsoft.com/en-us/azure/azure-app-configuration/howto-integrate-azure-managed-service-identity


---

# You are storing app configuration data by using Azure App Configuration.

You plan to encrypt values by using customer-managed keys from a hardware security module (HSM). The keys must have one replica.

You need to select the components to meet the requirements.

Which two components should you use? Each correct answer presents part of the solution.

Select all answers that apply.

Standard tier Azure App Configuration instance

Premium tier Azure App Configuration instance

Premium Azure Key Vault

Standard Azure Key Vault

To meet the requirements of using customer-managed keys from a hardware security module (HSM) with one replica for encrypting values in Azure App Configuration, you should use:

- **Standard tier Azure App Configuration instance**
- **Premium Azure Key Vault**

The Standard or Premium tier of Azure App Configuration supports customer-managed keys, but only the Premium tier of Azure Key Vault supports HSM-backed keys and provides the advanced cryptographic protection required for hardware-backed keys. Standard Azure Key Vault does not support HSM-backed keys, and the Premium tier is explicitly needed for these scenarios.[^4_1][^4_2][^4_3]
<span style="display:none">[^4_10][^4_11][^4_12][^4_13][^4_14][^4_15][^4_16][^4_17][^4_18][^4_19][^4_20][^4_4][^4_5][^4_6][^4_7][^4_8][^4_9]</span>

<div align="center">⁂</div>

[^4_1]: https://learn.microsoft.com/en-us/azure/azure-app-configuration/concept-customer-managed-keys

[^4_2]: https://docs.azure.cn/en-us/key-vault/managed-hsm/mhsm-control-data

[^4_3]: https://learn.microsoft.com/en-us/azure/key-vault/general/overview

[^4_4]: https://learn.microsoft.com/en-us/azure/security/fundamentals/encryption-customer-managed-keys-support

[^4_5]: https://learn.microsoft.com/en-us/azure/storage/common/customer-managed-keys-overview

[^4_6]: https://docs.azure.cn/en-us/key-vault/managed-hsm/secure-managed-hsm

[^4_7]: https://docs.azure.cn/en-us/databricks/security/keys/cmk-managed-services-azure/cmk-hsm-managed-services-azure

[^4_8]: https://notes.kodekloud.com/docs/AZ-204-Developing-Solutions-for-Microsoft-Azure/Implementing-Azure-App-Configuration/Securing-App-Configuration-Data

[^4_9]: https://intercept.cloud/en-gb/blogs/azure-key-vault

[^4_10]: https://learn.microsoft.com/en-us/azure/search/search-security-manage-encryption-keys

[^4_11]: https://www.datacamp.com/fr/tutorial/azure-key-vault-tutorial

[^4_12]: https://learn.microsoft.com/en-us/azure/azure-app-configuration/faq

[^4_13]: https://hokstadconsulting.com/blog/azure-key-vault-vs-managed-hsm-key-differences

[^4_14]: https://infisical.com/blog/azure-key-vault-pricing

[^4_15]: https://learn.microsoft.com/en-us/azure/mysql/flexible-server/concepts-customer-managed-key

[^4_16]: https://support.fortanix.com/docs/users-guide-fortanix-dsm-azure-managed-hsm-setup-guide

[^4_17]: https://learn.microsoft.com/en-us/azure/security/fundamentals/key-management-choose

[^4_18]: https://experienceleague.adobe.com/en/docs/project-aim-demo/landing/governance-privacy-security/customer-managed-keys/azure/ui-set-up

[^4_19]: https://learn.microsoft.com/en-us/azure/key-vault/keys/about-keys

[^4_20]: https://docs.prismacloud.io/en/enterprise-edition/policy-reference/azure-policies/azure-general-policies/ensure-storage-for-critical-data-are-encrypted-with-customer-managed-key


---

# You are developing an application.

The application stores all application settings in the Azure App Configuration service.

Application development includes the following four environments:

Development
Test
Staging
Production

You need to version the configuration data and use the same configuration values across all environments.

Which key-values pairs attribute should you use?

Select only one answer.

Labels

Feature flags

Feature managers

Filters

The correct attribute to use for versioning configuration data and sharing the same values across all environments is **Labels**. Labels in Azure App Configuration allow you to manage and version configuration settings for different environments (such as Development, Test, Staging, and Production) using the same set of values, providing easy management and retrieval of environment-specific or shared settings.[^5_2][^5_3][^5_4]

So, the correct answer is: **Labels**.
<span style="display:none">[^5_1][^5_5][^5_6][^5_7][^5_8]</span>

<div align="center">⁂</div>

[^5_1]: https://learn.microsoft.com/en-us/azure/azure-app-configuration/howto-best-practices

[^5_2]: https://learn.microsoft.com/en-us/azure/azure-app-configuration/howto-labels-aspnet-core

[^5_3]: https://learn.microsoft.com/en-us/answers/questions/37933/should-i-use-one-azure-app-configuration-resource

[^5_4]: https://configu.com/blog/azure-app-configuration-a-practical-guide/

[^5_5]: https://stackoverflow.com/questions/76031818/app-settings-azure-app-service-multiple-environments

[^5_6]: https://ambuzrnjn33.hashnode.dev/the-ultimate-guide-to-mastering-azure-app-configuration

[^5_7]: https://learn.microsoft.com/en-us/azure/architecture/guide/multitenant/service/app-configuration

[^5_8]: https://learn.microsoft.com/en-us/azure/azure-app-configuration/concept-snapshots


---

# You have an Azure App Service Web App.

You plan to test availability of the Web App by using Application Insights availability tests.
You need to implement a test that will simulate HTTP requests that include custom headers. Your solution must minimize development and configuration efforts.
Which type of availability test should you implement?
Select only one answer.

URL ping test
Standard test
Custom TrackAvailability test

You should implement a **Standard test** for Application Insights availability tests when you need to simulate HTTP requests that include custom headers and want to minimize development and configuration efforts. Standard tests support custom headers and are designed for straightforward configuration directly in the Azure portal, making them appropriate for your scenario.[^6_1][^6_4][^6_7]

The correct answer is: **Standard test**.
<span style="display:none">[^6_10][^6_2][^6_3][^6_5][^6_6][^6_8][^6_9]</span>

<div align="center">⁂</div>

[^6_1]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/availability

[^6_2]: https://learn.microsoft.com/en-us/answers/questions/2264217/how-to-make-a-custom-header-saved-in-standard-avai

[^6_3]: https://stackoverflow.com/questions/42203036/rest-api-post-availability-test-in-azure-app-insights

[^6_4]: https://demiliani.com/2023/09/22/transition-to-using-standard-tests-for-availability-tests-in-azure-application-insights/

[^6_5]: https://docs.azure.cn/en-us/azure-monitor/app/troubleshoot-availability

[^6_6]: https://www.sharepointeurope.com/monitor-availability-website-azure-application-insights-availability-tests/

[^6_7]: https://mydigest.365.training/Link/70ecc43f-2267-ee11-9ae7-6045bd00635c

[^6_8]: https://www.youtube.com/watch?v=QaK7GmbJxfg

[^6_9]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/dotnet

[^6_10]: https://learn.microsoft.com/en-us/azure/azure-monitor/fundamentals/azure-monitor-network-access


---

# You develop and deploy a Java web app to Azure Spring Cloud that includes the latest Application Insights SDK. You create an Application Insights instance and enable auto-instrumentation. The web app generates a large volume of telemetry and Application Insights is throttling the telemetry.

You need to reduce telemetry traffic while preserving a statistically correct analysis of the web app data.
What should you configure?
Select only one answer.

sampling
distributed tracing
metric alerts
log search alerts

To reduce telemetry traffic while preserving a statistically correct analysis of your web app data in Application Insights, you should configure **sampling**. Sampling enables you to limit the volume of telemetry data sent to Application Insights without affecting the accuracy of your metrics and insights.[^7_1][^7_6][^7_9]

The correct answer is: **sampling**.
<span style="display:none">[^7_2][^7_3][^7_4][^7_5][^7_7][^7_8]</span>

<div align="center">⁂</div>

[^7_1]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/java-standalone-config

[^7_2]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/java-spring-boot

[^7_3]: https://learn.microsoft.com/en-us/azure/spring-apps/basic-standard/how-to-application-insights

[^7_4]: https://stackoverflow.com/questions/79001841/how-to-configure-azure-application-insight-for-a-java-spring-boot-in-a-pod-in-az

[^7_5]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/java-standalone-sampling-overrides

[^7_6]: https://docs.azure.cn/en-us/azure-monitor/app/opentelemetry-configuration

[^7_7]: https://stackoverflow.com/questions/78018762/how-to-configure-sampling-for-java-application-dependency-calls-using-the-depend

[^7_8]: https://learn.microsoft.com/it-it/azure/azure-monitor/app/java-standalone-config

[^7_9]: https://azure.microsoft.com/en-us/blog/sampling-in-application-insights/


---

# You develop and deploy a Java web app to Azure Spring Cloud that includes the latest Application Insights SDK. You create an Application Insights instance and enable auto-instrumentation. The web app generates a large volume of telemetry and Application Insights is throttling the telemetry.

You need to reduce telemetry traffic while preserving a statistically correct analysis of the web app data.
What should you configure?
Select only one answer.

sampling
distributed tracing
metric alerts
log search alerts

You should configure **sampling** in Application Insights to reduce telemetry traffic while preserving a statistically correct analysis of your Java web app data. Sampling selectively reduces the volume of telemetry data sent from your app, thereby mitigating throttling issues and controlling costs, while still maintaining sufficient data for accurate insights and diagnostics.[^8_1][^8_2][^8_3]

The other options do not address telemetry volume control or throttling directly:

- Distributed tracing is for tracking requests across services.
- Metric alerts and log search alerts are for monitoring and alerting, not reducing telemetry volume.

Final answer: **sampling**.
<span style="display:none">[^8_4][^8_5][^8_6][^8_7][^8_8][^8_9]</span>

<div align="center">⁂</div>

[^8_1]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/java-standalone-config

[^8_2]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/java-standalone-sampling-overrides

[^8_3]: https://docs.azure.cn/en-us/azure-monitor/app/opentelemetry-sampling

[^8_4]: https://stackoverflow.com/questions/78767232/azure-applicationinsights-sampling-overrides-with-multiple-telemetry-types-with

[^8_5]: https://lng-consultancy.com/configure-sampling-in-application-insight/

[^8_6]: https://stackoverflow.com/questions/78018762/how-to-configure-sampling-for-java-application-dependency-calls-using-the-depend

[^8_7]: https://docs.azure.cn/en-us/azure-monitor/app/opentelemetry-configuration

[^8_8]: https://signoz.io/guides/azure-app-insights/

[^8_9]: https://www.divyaakula.com/cloud-monitoring/2025/08/21/application-insights-primer.html


---

# You develop and deploy an Azure App Service web app by using the latest Application Insights SDK. You are developing a dashboard and near-real-time alerting for the web app.

You need to query operational data to support the dashboard and alerts.
Which data should you use?
Select only one answer.

standard metrics
log-based metrics
distributed traces
Azure Activity log

For creating a dashboard and near-real-time alerting for your Azure App Service web app using the latest Application Insights SDK, you should use **standard metrics**.

Standard metrics in Application Insights are preaggregated performance and usage indicators collected automatically, such as CPU usage, memory consumption, request counts, and response times. Due to their preaggregation and fixed intervals, they provide fast query performance, making them ideal for real-time monitoring and alerting scenarios.[^9_1][^9_4]

Other options like log-based metrics and distributed traces are better suited for detailed diagnostics and deeper analysis but are not as performant for real-time alerts and dashboards. Azure Activity Log is more focused on management and subscription-level events.

Final answer: **standard metrics**.
<span style="display:none">[^9_2][^9_3][^9_5][^9_6][^9_7][^9_8][^9_9]</span>

<div align="center">⁂</div>

[^9_1]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/metrics-overview

[^9_2]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview

[^9_3]: https://docs.azure.cn/en-us/azure-monitor/app/data-model-complete

[^9_4]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/live-stream

[^9_5]: https://www.elastic.co/docs/reference/integrations/azure_application_insights

[^9_6]: https://signoz.io/guides/azure-app-insights/

[^9_7]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/dotnet

[^9_8]: https://learn.microsoft.com/en-us/azure/azure-monitor/metrics/metrics-aggregation-explained

[^9_9]: https://stackoverflow.com/questions/40135991/what-is-the-difference-between-web-app-metrics-and-application-insights-metrics


---

# You have an Azure App Service Web App.

You need to collect page views and performance data from web browser sessions on user devices used to access the Web App. Your solution must minimize development and implementation efforts.
What should you use?
Select only one answer.

Autoinstrumentation with Application Insights
Manual instrumentation with OpenTelemetry
JavaScript OpenTelemetry autoinstrumentation
Manual instrumentation by using an Application Insights SDK

The best option to collect page views and performance data from web browser sessions with minimal development and implementation effort is to use **Autoinstrumentation with Application Insights**.

Autoinstrumentation for Application Insights automatically collects telemetry such as page views, performance metrics, and user sessions from web browsers without requiring code changes. This provides a simple, near-zero effort way to get detailed client-side telemetry for your Azure App Service web app.[^10_1][^10_2][^10_5]

The other options require manual setup or code changes:

- Manual instrumentation with OpenTelemetry or Application Insights SDK involves more development work.
- JavaScript OpenTelemetry autoinstrumentation is not as streamlined or fully integrated for browser telemetry.

Final answer: **Autoinstrumentation with Application Insights**.
<span style="display:none">[^10_10][^10_3][^10_4][^10_6][^10_7][^10_8][^10_9]</span>

<div align="center">⁂</div>

[^10_1]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/codeless-overview

[^10_2]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/codeless-app-service

[^10_3]: https://learn.microsoft.com/en-us/troubleshoot/azure/azure-monitor/app-insights/telemetry/auto-instrumentation-troubleshoot

[^10_4]: https://docs.azure.cn/en-us/azure-monitor/app/codeless-app-service

[^10_5]: https://dzone.com/articles/auto-instrumentation-in-azure-application-insights

[^10_6]: https://stackoverflow.com/questions/79413674/azure-application-insight-autoinstrumentation-not-captured-any-call

[^10_7]: https://azure.github.io/AppService/2021/05/10/codeless-monitoring-for-java-node.html

[^10_8]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview

[^10_9]: https://learn.microsoft.com/en-us/azure/azure-monitor/app/dotnet

[^10_10]: https://azuretechinsider.com/migrate-application-insights-instrumentation-key-to-connection-string/


---

# You plan to create a solution by using Azure Container Apps.

You must configure the solution for autoscaling.
You need to use triggers that allow you to scale to zero instances.
Which three triggers can you use? Each correct answer presents a complete solution.

Select all answers that apply.

Blob count
CPU metrics
MySQL query
Memory utilization
Service Bus queues

The three autoscaling triggers for Azure Container Apps that support scaling to zero instances are:

- Blob count (based on Azure Blob Storage)
- CPU metrics
- Service Bus queues (based on Azure Service Bus message count)

These triggers enable event-driven and metric-based scaling, including scaling down to zero when there is no workload.[^11_1][^11_6][^11_8]

The triggers you should select are:

- Blob count
- CPU metrics
- Service Bus queues
<span style="display:none">[^11_10][^11_2][^11_3][^11_4][^11_5][^11_7][^11_9]</span>

<div align="center">⁂</div>

[^11_1]: https://learn.microsoft.com/en-us/azure/container-apps/scale-app

[^11_2]: https://learn.microsoft.com/en-us/azure/container-apps/tutorial-scaling

[^11_3]: https://dev.to/willvelida/scaling-in-azure-container-apps-2kj5

[^11_4]: https://techcommunity.microsoft.com/blog/appsonazureblog/scaling-options-in-azure-container-apps/3878282

[^11_5]: https://www.byteplus.com/en/topic/575818

[^11_6]: https://azure.github.io/aca-dotnet-workshop/aca/09-aca-autoscale-keda/

[^11_7]: https://techcommunity.microsoft.com/blog/appsonazureblog/configure-time-based-scaling-in-azure-container-apps/4398327

[^11_8]: https://rajanieshkaushikk.com/2024/11/05/scaling-azure-container-apps-for-peak-performance/

[^11_9]: https://www.youtube.com/watch?v=EYtNeHF5Mm8

[^11_10]: https://docs.azure.cn/en-us/container-apps/functions-usage


---

# You plan to create a solution by using Azure Container Apps. The solution will consist of multiple container apps.

You are assessing whether you should create multiple environments.
You need to identify criteria that will require the creation of multiple environments.
Which two criteria should you identify? Each correct answer presents a complete solution.

Select all answers that apply.

Each container app must maintain its own versioning.
Each container app must support different upgrade cadency.
Each container app must be able to scale independently of others.
Each container app must be deployed to a different virtual network.
Each container app must write its logs to a different Log Analytics workspace.

The two criteria that would require creating multiple Azure Container Apps environments are:

1. Each container app must be deployed to a different virtual network.
    - Azure Container Apps environment provides network isolation with its own virtual network. Different virtual networks require different environments to maintain isolation.[^12_1][^12_2]
2. Each container app must write its logs to a different Log Analytics workspace.
    - Logs and monitoring configuration are environment-scoped. Separate logging destinations require separate environments for isolation.[^12_1]

The other criteria such as versioning, upgrade cadence, and independent scaling do not require separate environments as these are supported within the same environment.

Final answers:

- Each container app must be deployed to a different virtual network
- Each container app must write its logs to a different Log Analytics workspace
<span style="display:none">[^12_3][^12_4][^12_5][^12_6][^12_7][^12_8][^12_9]</span>

<div align="center">⁂</div>

[^12_1]: https://learn.microsoft.com/en-us/azure/container-apps/environment

[^12_2]: https://learn.microsoft.com/en-us/azure/architecture/guide/multitenant/service/container-apps

[^12_3]: https://learn.microsoft.com/en-us/azure/well-architected/service-guides/azure-container-apps

[^12_4]: https://www.byteplus.com/en/topic/575823

[^12_5]: https://docs.azure.cn/en-us/spring-apps/migration/migrate-to-azure-container-apps-provision

[^12_6]: https://www.emergentsoftware.net/blog/azure-container-apps-modern-deployment-with-docker/

[^12_7]: https://azure.github.io/aca-dotnet-workshop/aca/00-workshop-intro/1-aca-core-components/

[^12_8]: https://learn.microsoft.com/en-us/azure/container-apps/networking

[^12_9]: https://learn.microsoft.com/en-us/azure/container-apps/environment-variables


---

# You have an Azure Container Apps application named App1. App1 uses an environment named App1Env1, has a revision named App1Rev1, and contains a container named Container1.

You need to create a secret whose value will be available to the code running in App1.
What should you configure?

Select only one answer.

App1
App1Env1
App1Rev1
Container1

In Azure Container Apps, secrets are configured at the **application level**, meaning they are defined for the entire container app (App1) and not scoped to a specific revision or container. These secrets are then accessible to all revisions and containers within that application.

Therefore, to create a secret whose value will be available to the code running in App1, you should configure the secret on **App1**.

Final answer: **App1**.[^13_1][^13_2][^13_6]
<span style="display:none">[^13_10][^13_3][^13_4][^13_5][^13_7][^13_8][^13_9]</span>

<div align="center">⁂</div>

[^13_1]: https://notes.kodekloud.com/docs/AZ-204-Developing-Solutions-for-Microsoft-Azure/Implementing-Azure-Container-Apps/Managing-Revisions-and-Secrets-in-Azure-Container-Apps

[^13_2]: https://learn.microsoft.com/en-us/azure/container-apps/manage-secrets

[^13_3]: https://learn.microsoft.com/it-it/azure/container-apps/manage-secrets

[^13_4]: https://dev.to/willvelida/managing-secrets-in-azure-container-apps-1459

[^13_5]: https://www.playtimesolutions.com.au/configuration-and-secrets-management-in-container-apps/

[^13_6]: https://docs.azure.cn/en-us/container-apps/security

[^13_7]: https://www.youtube.com/watch?v=kml1WL30Cks

[^13_8]: https://stackoverflow.com/questions/77676813/keyvault-stored-secrets-for-azure-container-apps-with-rbac-auth-from-arm-templat

[^13_9]: https://learn.microsoft.com/en-us/azure/container-apps/authentication-entra

[^13_10]: https://hexmaster.nl/posts/secrets-made-easy-for-container-apps/


---

# You have a Dockerfile stored on your local computer.

You need to publish a container image based on the Dockerfile to Azure Container Registry.

Which Azure CLI command should you use?

Select only one answer.

az acr build

az acr export

az acr import

az acr repository

The correct Azure CLI command to publish a container image based on your local Dockerfile to Azure Container Registry is:

**az acr build**

This command uploads your Dockerfile and context to Azure, builds the image in the cloud, and automatically pushes it to your registry.[^14_1][^14_2][^14_4]

Final answer: **az acr build**.
<span style="display:none">[^14_10][^14_3][^14_5][^14_6][^14_7][^14_8][^14_9]</span>

<div align="center">⁂</div>

[^14_1]: https://learn.microsoft.com/en-us/azure/container-registry/container-registry-tutorial-quick-task

[^14_2]: https://learn.microsoft.com/en-us/azure/container-registry/container-registry-quickstart-task-cli

[^14_3]: https://stackoverflow.com/questions/69381095/az-acr-build-command-info-needed

[^14_4]: https://deanobrien.uk/building-docker-images-using-acr-build-command/

[^14_5]: https://notes.kodekloud.com/docs/AZ-204-Developing-Solutions-for-Microsoft-Azure/Managing-Container-Images-in-Azure-Container-Registry/Building-and-Managing-Containers-With-ACR-Tasks

[^14_6]: https://markheath.net/post/build-container-images-with-acr

[^14_7]: https://blog.nashtechglobal.com/how-to-build-and-run-a-container-with-acr-tasks/

[^14_8]: https://docs.azure.cn/en-us/container-registry/container-registry-tutorial-private-base-image-update

[^14_9]: https://www.blueboxes.co.uk/azure-container-registry-more-than-just-an-image-store

[^14_10]: https://www.c-sharpcorner.com/blogs/build-and-pulling-docker-images-to-acr-azure-container-registry


---

# You create a custom image and publish the image to Azure Container Registry.

You need to build images automatically when teammates commit code to a private Git repository in GitHub.

What should you use?

Select only one answer.

ACR Tasks

OCI image

Helm charts

YAML manifest

To build container images automatically when teammates commit code to a private Git repository in GitHub and publish them to Azure Container Registry, you should use:

**ACR Tasks**

Azure Container Registry (ACR) Tasks support automated container image builds triggered on source code changes in GitHub repositories (public or private). These builds are triggered by commits or pull requests, enabling seamless CI/CD integration for container images.[^15_1][^15_6][^15_9]

Other options:

- OCI image: a container image format, not a build automation tool.
- Helm charts: for Kubernetes package management, not building images.
- YAML manifest: describes deployments but not used for building container images directly.

Final answer: **ACR Tasks**.
<span style="display:none">[^15_2][^15_3][^15_4][^15_5][^15_7][^15_8]</span>

<div align="center">⁂</div>

[^15_1]: https://learn.microsoft.com/en-us/azure/container-registry/container-registry-tasks-overview

[^15_2]: https://github.com/jenkinsci/azure-container-registry-tasks-plugin

[^15_3]: https://learn.microsoft.com/en-us/azure/container-instances/container-instances-github-action

[^15_4]: https://azure.github.io/acr/tasks/container-registry-tasks-overview.html

[^15_5]: https://learn.microsoft.com/en-us/azure/container-apps/github-actions

[^15_6]: https://learn.microsoft.com/en-us/azure/container-registry/container-registry-tutorial-build-task

[^15_7]: https://docs.github.com/packages/working-with-a-github-packages-registry/working-with-the-container-registry

[^15_8]: https://dev.to/willvelida/how-to-purge-stale-images-from-azure-container-registry-with-acr-tasks-and-github-actions-291p

[^15_9]: https://cloudengineerskills.com/posts/acr-automatically-triggered-task/


---

# You develop and deploy a new Linux container to Azure Container Instances.

You need to access data from the container by using the Server Message Block (SMB) protocol.
What should you use?
Select only one answer.

YAML file
Container group
Azure File share
Environment variable
Resource Manager template

To access data from an Azure Container Instance using the Server Message Block (SMB) protocol, you should use **Azure File share**.

Azure File shares provide fully managed file shares hosted in Azure Storage accessible via SMB protocol and can be mounted in Azure Container Instances to persist and share data.[^16_1][^16_6][^16_7]

Final answer: **Azure File share**.
<span style="display:none">[^16_10][^16_2][^16_3][^16_4][^16_5][^16_8][^16_9]</span>

<div align="center">⁂</div>

[^16_1]: https://learn.microsoft.com/en-us/azure/container-instances/container-instances-volume-azure-files

[^16_2]: https://learn.microsoft.com/en-us/answers/questions/1620270/how-do-i-mount-an-azure-file-share-in-azure-contai

[^16_3]: https://cloudengineerskills.com/posts/aci-mount-azure-file-share/

[^16_4]: https://learn.microsoft.com/en-us/azure/container-instances/container-instances-overview

[^16_5]: https://github.com/microsoft/azure-container-apps/issues/1446

[^16_6]: https://tutorialsdojo.com/azure-container-instances-aci/

[^16_7]: https://learn.microsoft.com/en-us/azure/storage/files/storage-how-to-use-files-linux

[^16_8]: https://www.youtube.com/watch?v=h2TcpPPVYvQ

[^16_9]: https://stackoverflow.com/questions/78355845/how-to-mount-a-virtual-disk-inside-azure-container-instance

[^16_10]: https://www.reddit.com/r/docker/comments/1k6tbw6/how_to_mount_azure_file_share_as_volume_in_docker/


---

# You plan to implement an Azure Functions app in either C\# script or Python. The app will connect to an Azure SQL database.

You need to specify the database connection string for the app when running it in Azure.

Where should you store the value of the connection string?

Select only one answer.

host.json

function.json

local.settings.json

Application Settings

The value of the database connection string for an Azure Functions app running in Azure should be stored in **Application Settings**.

Application Settings in the Azure portal provide a secure and centralized place to manage connection strings and environment variables for Azure Functions. These settings are injected into the function app’s runtime environment as environment variables and are the recommended place for connection strings used by the app in Azure. The local.settings.json file is used only for local development and should not be used for production.[^17_2][^17_3][^17_5]

Final answer: **Application Settings**.
<span style="display:none">[^17_1][^17_10][^17_4][^17_6][^17_7][^17_8][^17_9]</span>

<div align="center">⁂</div>

[^17_1]: https://learn.microsoft.com/en-us/azure/storage/common/storage-configure-connection-string

[^17_2]: https://stackoverflow.com/questions/37215069/azure-functions-database-connection-string

[^17_3]: https://learn.microsoft.com/en-us/answers/questions/686041/best-place-for-sql-db-connection-string-in-azure-f

[^17_4]: https://learn.microsoft.com/en-us/azure/azure-functions/storage-considerations

[^17_5]: https://learn.microsoft.com/en-us/azure/azure-functions/manage-connections

[^17_6]: https://docs.azure.cn/en-us/azure-functions/functions-add-output-binding-storage-queue-cli

[^17_7]: https://github.com/Azure/Azure-Functions/issues/717

[^17_8]: https://learn.microsoft.com/en-us/azure/azure-functions/functions-add-output-binding-storage-queue-vs-code

[^17_9]: https://docs.azure.cn/en-us/azure-functions/functions-reference

[^17_10]: https://learn.microsoft.com/en-us/azure/azure-functions/functions-app-settings


---

# How to reference an Application Setting from C\# script in Azure Functions

To reference an Application Setting from C\# script in Azure Functions, you use the following code to read the setting as an environment variable:

```csharp
string mySettingValue = System.Environment.GetEnvironmentVariable("MySettingName");
```

This is the recommended and simplest way to access the Application Settings configured in the Azure Functions app or the local.settings.json file during local development. Replace `"MySettingName"` with the key of your application setting.[^18_2][^18_4][^18_7]

Example usage in a function:

```csharp
public static async Task<IActionResult> Run(HttpRequest req, ILogger log) {
    string connectionString = System.Environment.GetEnvironmentVariable("SqlConnectionString");
    // Use the connection string...
    return new OkResult();
}
```

This method fetches the configuration value directly from the environment at runtime, ensuring correct values per deployment environment.
<span style="display:none">[^18_1][^18_3][^18_5][^18_6][^18_8][^18_9]</span>

<div align="center">⁂</div>

[^18_1]: https://learn.microsoft.com/en-us/azure/azure-functions/functions-app-settings

[^18_2]: https://learn.microsoft.com/en-us/azure/azure-functions/functions-how-to-use-azure-function-app-settings

[^18_3]: https://learn.microsoft.com/en-us/azure/azure-functions/functions-reference-csharp

[^18_4]: https://stackoverflow.com/questions/58087577/how-to-access-application-settings-in-azure-function-in-portal-c-sharp-app-funct

[^18_5]: https://docs.azure.cn/en-us/azure-functions/functions-dotnet-class-library

[^18_6]: https://www.itidea.nl/index.php/how-to-reference-a-file-in-azure-function-c-script-function-vs-c-function/

[^18_7]: https://www.serverlessnotes.com/docs/centralize-configuration-for-azure-functions-with-azure-app-configuration

[^18_8]: https://learn.microsoft.com/en-us/azure/app-service/reference-app-settings

[^18_9]: https://blog.thenetworknerd.com/2020/05/24/azure-functions-and-c-code-intricacies-an-azure-pipelines-prequel/


---

# You plan to create an Azure Functions app by using the Python v1 programming model.

You need to configure the app triggers and bindings.
Which method should you use?
Select only one answer.

Update the content of the host.json file.
Update the content of the function.json file.
Decorate methods and parameters with attributes.
Decorate methods and parameters with annotations.

For Azure Functions using the Python v1 programming model, you configure the app triggers and bindings by **updating the content of the function.json file**.

In the v1 Python programming model, bindings and triggers are defined declaratively in a separate function.json file located in the function folder. This file specifies the bindings and triggers that invoke the function, as Python v1 does not support defining bindings directly in the code using decorators or annotations.[^19_3][^19_6]

Final answer: **Update the content of the function.json file**.
<span style="display:none">[^19_1][^19_10][^19_2][^19_4][^19_5][^19_7][^19_8][^19_9]</span>

<div align="center">⁂</div>

[^19_1]: https://learn.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings

[^19_2]: https://learn.microsoft.com/en-us/azure/azure-functions/functions-reference-python

[^19_3]: https://learn.microsoft.com/en-us/azure/azure-functions/functions-bindings-http-webhook-trigger

[^19_4]: https://docs.azure.cn/en-us/azure-functions/functions-bindings-http-webhook

[^19_5]: https://jingwen-z.github.io/building-azure-function-with-python/

[^19_6]: https://learn.microsoft.com/en-us/azure/azure-functions/functions-bindings-timer

[^19_7]: https://stackoverflow.com/questions/77893774/python-azure-functions-identity-based-connection-for-trigger-bindings

[^19_8]: https://learn.microsoft.com/it-it/azure/azure-functions/functions-reference-python

[^19_9]: https://notes.kodekloud.com/docs/AZ-204-Developing-Solutions-for-Microsoft-Azure/Developing-Azure-Functions/Triggers-and-Bindings

[^19_10]: https://dev.to/manukanne/azure-functions-for-python-introduction-of-the-new-v2-programming-model-6h3


---

# You plan to implement an Azure Functions app that will use an identity-based connection to connect to an Azure SQL database.

You need to configure the identifying information that is used to authenticate the connection when the app is running in Azure.

Which identity type should you use?

Select only one answer.

certificate

user account

service principal

managed identity

You should use a **managed identity** for identity-based authentication to Azure SQL Database from your Azure Functions app.

Managed identities provide a secure, password-less way for Azure services, such as Azure Functions, to authenticate to Azure SQL and other Azure resources. The function app can use its system-assigned or user-assigned managed identity, which you grant access to the Azure SQL database by creating a contained database user for that identity and assigning appropriate roles. This eliminates the need to store credentials in the app configuration.[^20_1][^20_4][^20_7][^20_8]

Final answer: **managed identity**.
<span style="display:none">[^20_2][^20_3][^20_5][^20_6][^20_9]</span>

<div align="center">⁂</div>

[^20_1]: https://learn.microsoft.com/en-us/azure/azure-functions/functions-identity-access-azure-sql-with-managed-identity

[^20_2]: https://learn.microsoft.com/it-it/azure/azure-functions/functions-identity-access-azure-sql-with-managed-identity

[^20_3]: https://www.youtube.com/watch?v=oJ09H89k4RA

[^20_4]: https://www.reddit.com/r/AZURE/comments/164ir59/azure_function_managed_identity_for_sql_database/

[^20_5]: https://stackoverflow.com/questions/79100671/connect-to-azure-sql-with-managed-identity-through-azure-function-on-app-service

[^20_6]: https://docs.azure.cn/en-us/stream-analytics/sql-database-output-managed-identity

[^20_7]: https://guidingbytes.com/how-to-connect-azure-function-app-to-sql-database-using-user-assigned-managed-identity-uami/

[^20_8]: https://learn.microsoft.com/en-us/azure/app-service/tutorial-connect-msi-azure-database

[^20_9]: https://learn.microsoft.com/en-us/azure/azure-functions/functions-add-output-binding-azure-sql-vs-code


---

# Your team is developing a C\# application that manages containers in an Azure Storage account by using the Azure.Storage.Blobs .NET client library.

The application must follow security policy that prohibits storing secrets such as connection strings or account keys in code.

You need to authenticate by using Microsoft Entra ID and create a client that can list, create, and delete containers at the account level.

Which two actions should you perform? Each correct answer presents part of the solution. Choose two.

Select all answers that apply.

1) Instantiate a BlobContainerClient.
2) Create a BlobClient from the account URL.
3) Instantiate a BlobServiceClient with the account URL and DefaultAzureCredential.
4) Assign the Entra ID identity of the application an Azure RBAC role that grants access to blob data.
5) Enable anonymous public read access on the container so authentication is not required.

The two correct actions to authenticate using Microsoft Entra ID without storing secrets in code, and to create a client that manages containers at the account level are:

3) Instantiate a BlobServiceClient with the account URL and DefaultAzureCredential.

- This creates a BlobServiceClient that uses Azure AD credentials (via DefaultAzureCredential) for secure authentication.

4) Assign the Entra ID identity of the application an Azure RBAC role that grants access to blob data.

- The app's managed identity or service principal must have an Azure RBAC role like "Storage Blob Data Contributor" on the storage account to list, create, and delete containers.

The other options are incorrect because:

- (1) BlobContainerClient is scoped to a single container, not the account level.
- (2) BlobClient is used for blobs, not container or account management.
- (5) Enabling anonymous access violates security policy.

Final answers: **3 and 4**.

---

# You are trying to recover a deleted container for a Blob storage resource.

When you call the UndeleteBlobContainer method from the BlobServiceClient class, you receive an error.

You need to resolve the error.

What should you do?

Select only one answer.

Enable container soft delete in the storage account.

Enable blob soft delete in the storage account.

Call the UndeleteBlobContainer method from the BlobContainerClient class.

Call the UndeleteBlobContainerAsync method from the BlobServiceClient class.

To resolve the error when calling the UndeleteBlobContainer method from the BlobServiceClient class, you should:

**Enable container soft delete in the storage account.**

Container soft delete must be enabled for the storage account to allow recovery of deleted containers. Without enabling container soft delete, the undelete operation will fail because the deleted container cannot be recovered.[^22_3][^22_5]

- Blob soft delete is for individual blobs, not containers.
- The UndeleteBlobContainer method is correctly called from BlobServiceClient, and async variation is optional but not related to the error.

Final answer: **Enable container soft delete in the storage account**.
<span style="display:none">[^22_1][^22_10][^22_2][^22_4][^22_6][^22_7][^22_8][^22_9]</span>

<div align="center">⁂</div>

[^22_1]: https://learn.microsoft.com/en-us/answers/questions/1149754/how-do-i-undelete-a-storage-container-from-microso

[^22_2]: https://learn.microsoft.com/en-us/rest/api/storageservices/undelete-blob

[^22_3]: https://learn.microsoft.com/en-us/azure/storage/blobs/storage-blob-container-delete

[^22_4]: https://stackoverflow.com/questions/68683323/azure-cli-how-to-undelete-a-storage-blob-with-soft-delete-and-versioning-enabl

[^22_5]: https://docs.azure.cn/en-us/storage/blobs/storage-blob-container-delete-python

[^22_6]: https://www.youtube.com/watch?v=9PS9bVK2C1Q

[^22_7]: https://learn.microsoft.com/en-us/azure/storage/blobs/soft-delete-blob-manage

[^22_8]: https://www.sqlshack.com/how-to-recover-accidental-deletes-in-azure-blob-storage/

[^22_9]: https://www.c-sharpcorner.com/article/how-to-retrieve-accidentally-deleted-azure-storage-blobs/

[^22_10]: https://learn.microsoft.com/en-us/azure/storage/common/storage-explorer-soft-delete


---

# You are writing an application to store data in a storage account.

You must set metadata on a container by using the SetMetadata method of the BlobContainerClient class. The metadata values contain non-ASCII characters.

You need to set the values without any data loss.

What should you do?

Select only one answer.

Remove the non-ASCII characters.

Use Base64 encoding for the metadata values.

Use binary encoding for the metadata values.

Ensure that the non-ASCII characters are using the UTF-16 format.

When setting metadata values that contain non-ASCII characters on a container using the Azure.Storage.Blobs .NET client library, the metadata values must be ASCII only because metadata are sent as HTTP headers which only support ASCII characters.

To avoid data loss, you should **encode the metadata values using Base64 encoding** (or a similar encoding like URL encoding). This allows you to safely represent non-ASCII data in an ASCII-compatible format for HTTP headers, and then decode it back when reading the metadata.[^23_1][^23_4][^23_5]

Answer: **Use Base64 encoding for the metadata values**.
<span style="display:none">[^23_2][^23_3][^23_6][^23_7][^23_8][^23_9]</span>

<div align="center">⁂</div>

[^23_1]: https://github.com/Azure/azure-sdk-for-net/issues/10629

[^23_2]: https://stackoverflow.com/questions/14899461/invalid-character-exception-when-adding-metadata-to-a-cloudblob

[^23_3]: https://learn.microsoft.com/en-us/answers/questions/1822134/how-to-upload-file-in-azure-blob-storage-using-c-h

[^23_4]: https://github.com/Azure/azure-sdk-for-net/issues/10741

[^23_5]: https://github.com/Azure/azure-storage-net/issues/975

[^23_6]: https://dev.to/rkosta/azure-blob-storage-metadata-400-bad-request-1892?comments_sort=top

[^23_7]: https://learn.microsoft.com/en-us/rest/api/storageservices/naming-and-referencing-containers--blobs--and-metadata

[^23_8]: https://learn.microsoft.com/en-us/rest/api/storageservices/set-blob-metadata

[^23_9]: https://learn.microsoft.com/en-us/azure/storage/blobs/storage-blob-properties-metadata


---

# You are configuring an Azure Cosmos DB container by using the .NET SDK.

The solution must minimize latency for read operations while ensuring a consistent view of data, in the context of a user, across multiple regions.

You need to configure the appropriate consistency level when creating the CosmosClient.

Which consistency level should you configure?

Select only one answer.

Strong

Session

Eventual

Consistent prefix

Bounded staleness

The consistency level you should configure in Azure Cosmos DB when you want to minimize latency for reads while ensuring a consistent view of data in the context of a user across multiple regions is **Session** consistency.

Session consistency guarantees that a client session reads its own writes, providing a consistent view for that user while allowing for lower latency compared to strong consistency. It's ideal for user-centric applications where the data should be consistent within a user session but can tolerate slight delays across different users or regions.[^24_1][^24_5][^24_6]

Explanation of other levels:

- **Strong** offers the highest consistency but with higher latency and lower availability.
- **Eventual** provides low latency with no consistency guarantees.
- **Consistent prefix** guarantees ordered reads but not immediate consistency.
- **Bounded staleness** guarantees lag in reads but allows some staleness within configured bounds.

Final answer: **Session**.
<span style="display:none">[^24_2][^24_3][^24_4][^24_7][^24_8][^24_9]</span>

<div align="center">⁂</div>

[^24_1]: https://learn.microsoft.com/en-us/azure/cosmos-db/consistency-levels

[^24_2]: https://www.c-sharpcorner.com/article/consistency-levels-in-azure-cosmos-db-with-an-example/

[^24_3]: https://parveensingh.com/cosmosdb-consistency-levels/

[^24_4]: https://notes.kodekloud.com/docs/AZ-204-Developing-Solutions-for-Microsoft-Azure/Exploring-Azure-Cosmos-DB/Consistency-Levels

[^24_5]: https://dev.to/mariustechie/concepts-of-cosmos-db-data-consistency-levels-272

[^24_6]: https://www.mssqltips.com/sqlservertip/7158/azure-cosmos-db-consistency-levels-strong-bounded-staleness-session-consistent-prefix-eventual/

[^24_7]: https://www.certlibrary.com/blog/exploring-cosmos-db-consistency-levels-what-you-need-to-know/

[^24_8]: https://www.youtube.com/watch?v=t1--kZjrG-o

[^24_9]: https://learn.microsoft.com/en-us/azure/cosmos-db/table/faq


---

# A background worker initializes a new environment for an existing Azure Cosmos DB for NoSQL database named telemetry. The environment may or may not have the required container.

Initialization must be idempotent so that repeated runs do not throw errors.

You need to create a container named logs with partition key path /deviceId by using code.

Which method should you call?

Select only one answer.

database.GetContainer("logs").ReadContainerAsync()

database.CreateContainerAsync(id: "logs", partitionKeyPath: "/deviceId")

database.CreateContainerIfNotExistsAsync(id: "logs", partitionKeyPath: "/deviceId")

CosmosClient.CreateContainerIfNotExistsAsync(id: "logs", partitionKeyPath: "/deviceId")

You should call:

**database.CreateContainerIfNotExistsAsync(id: "logs", partitionKeyPath: "/deviceId")**

This method is idempotent and will create the container only if it does not already exist, avoiding errors on repeated calls. The method belongs to the Database class, so it is called on the database instance, not on CosmosClient directly. This matches your requirements for idempotent container creation.[^25_1][^25_2][^25_3]

Final answer: **database.CreateContainerIfNotExistsAsync(id: "logs", partitionKeyPath: "/deviceId")**.
<span style="display:none">[^25_4][^25_5][^25_6][^25_7][^25_8][^25_9]</span>

<div align="center">⁂</div>

[^25_1]: https://learn.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.database.createcontainerifnotexistsasync?view=azure-dotnet

[^25_2]: https://learn.microsoft.com/en-us/dotnet/api/azure.cosmos.cosmosdatabase.createcontainerifnotexistsasync?view=azure-dotnet-preview

[^25_3]: https://docs.azure.cn/en-us/cosmos-db/nosql/how-to-dotnet-create-container

[^25_4]: https://stackoverflow.com/questions/69802260/createcontainerifnotexistsasync-is-slower-than-getcontainer

[^25_5]: https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-dotnet-create-container

[^25_6]: https://doc.castsoftware.com/export/TECHNOS/Azure+Cosmos+DB+support+for+.NET+source+code

[^25_7]: https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/how-to-create-container

[^25_8]: https://microsoftlearning.github.io/dp-420-cosmos-db-dev/instructions/12-sdk-indexing-policy-custom.html

[^25_9]: https://www.c-sharpcorner.com/article/optimizing-performance-in-azure-cosmos-db-best-practices/


---

# A .NET API stores multi-tenant order data in Azure Cosmos DB for NoSQL. In some new environments, the database and container may not exist.

Startup must initialize these resources in an idempotent way so that repeated runs do not fail.

You need to create the database and a container with partition key /tenantId and provision 400 request units per second (RU/s) on the container by using code.

Which method should you call?

Select only one answer.

CosmosClient.CreateDatabaseIfNotExistsAsync("appDb", throughput: 400)followed bydatabase.CreateContainerIfNotExistsAsync("orders", "/tenantId")

CosmosClient.CreateDatabaseAsync("appDb")followed bydatabase.CreateContainerAsync("orders", "/tenantId", throughput: 400)

CosmosClient.CreateDatabaseIfNotExistsAsync("appDb")followed bydatabase.CreateContainerIfNotExistsAsync("orders", "/tenantId", throughput: 400)

You should call:

**CosmosClient.CreateDatabaseIfNotExistsAsync("appDb") followed by database.CreateContainerIfNotExistsAsync("orders", "/tenantId", throughput: 400)**

This approach is idempotent, meaning it will create the database and container only if they do not exist, preventing errors on repeated initialization. It also correctly sets the provisioned throughput of 400 RU/s on the container within the CreateContainerIfNotExistsAsync method.[^26_1][^26_2][^26_3]

The first option is close but incorrectly tries to set throughput on the database creation for the container throughput. Throughput should be set on the container if per-container throughput is desired.

Final answer: **CosmosClient.CreateDatabaseIfNotExistsAsync("appDb") followed by database.CreateContainerIfNotExistsAsync("orders", "/tenantId", throughput: 400)**.

<div align="center">⁂</div>

[^26_1]: https://learn.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.database.createcontainerifnotexistsasync?view=azure-dotnet

[^26_2]: https://learn.microsoft.com/en-us/dotnet/api/azure.cosmos.cosmosdatabase.createcontainerifnotexistsasync?view=azure-dotnet-preview

[^26_3]: https://docs.azure.cn/en-us/cosmos-db/nosql/how-to-dotnet-create-container


---

# You used an incorrect partition key path when creating an Azure Cosmos DB for NoSQL container named profiles. An appDb database already exists and includes other containers.

You have a Database object named database.
You need to delete the incorrect container and recreate it with the required partition key path without affecting existing containers.
Which code block should you use?
Select only one answer.

A)
database.ReadAsync();
database.GetContainer("profiles").ReadContainerAsync();

B)
database.CreateContainerIfNotExistsAsync(id: "profiles", partitionKeyPath: "/accountId", throughput: 400);
database.GetContainer("profiles").DeleteContainerAsync();

C)
database.GetContainer("profiles").DeleteContainerAsync()
followed by
database.CreateContainerIfNotExistsAsync(id: "profiles", partitionKeyPath: "/accountId")

D)
database.DeleteAsync();
followed by
CosmosClient.CreateDatabaseIfNotExistsAsync("appDb");
database.CreateContainerIfNotExistsAsync(id: "profiles", partitionKeyPath: "/accountId", throughput: 400);

The correct option is:

**C)**

```csharp
database.GetContainer("profiles").DeleteContainerAsync()
followed by
database.CreateContainerIfNotExistsAsync(id: "profiles", partitionKeyPath: "/accountId")
```

Explanation:

- You need to delete only the incorrect container without affecting other containers or the database.
- Option C deletes the "profiles" container and then recreates it with the correct partition key path, preserving other containers.
- Option A does not perform deletion or creation.
- Option B tries to create before deleting, which doesn't replace the container and can cause errors.
- Option D deletes the entire database, affecting all containers, which is not desired.

Final answer: **C**.

