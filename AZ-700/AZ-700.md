[Microsoft Certified: Azure Network Engineer Associate](https://learn.microsoft.com/en-us/credentials/certifications/azure-network-engineer-associate/?practice-assessment-type=certification)   

---

## Q011X:

---

### Answer:

---

### References

---

## Q0118:

Your company hosts its infrastructure in Azure and uses service endpoints to add a layer of protection to Azure storage accounts and Azure SQL managed instances. The Azure infrastructure is connected to your on-premises network via a site-to site VPN.
You have a storage account named sahr678 that is configured with a private-only namespace, which is accessible only to the subnets in the table below:

| Network Name | IP Address Range | Location |
|---|---|---|
| Lon-vNet01 | 10.0.0.0/22 | Azure |
| Man-vNet01 | 10.0.4.0/22 | Azure |
| LonOffice | 172.16.0.0/22 | On-premises |

A virtual network (VNet) in Azure named Lee-vNet01, with an address space of 10.0.8.0/22, hosts a new web application that needs to be able to access sahr678. You need to configure the service endpoint to allow access from this network, while minimizing administrative effort and adhere to the principle of least privilege.
What configuration should you make?

Choose the correct answer

- Add Lee-vNet01 to the list of specific networks on sahr678.
- Route traffic from Lee-vNet01 via LonOffice in order to access sahr678.
- Configure a new service endpoint for the Lee-vNet01 network on sahr678.
- Change the existing service endpoint to public access to allow access for all networks to sahr678.
---

### Answer:

- Add Lee-vNet01 to the list of specific networks on sahr678.

You need to add Lee-vNet01 to the list of specific networks on sahr678. There is an existing service endpoint with a namespace already in place for the sahr678 storage account, which has both Man-vNet01 and Lon- vNet01 added as allowed private networks, so resources connected to those two networks can securely access this storage account. Adding Lee-vNet01 to the allowed networks list represents the least amount of administrative effort from all of the available options.
You should not configure a new service endpoint for the Lee-vNet01 network on sahr678. Although it is possible to configure multiple service endpoints for supported Azure services, which includes Azure storage accounts, this would mean more configuration work and create more administrative effort, and therefore it is not the correct option.
You should not route traffic from Lee-vNet01 via LonOffice in order to access sahr678. This would require a lot of additional work from multiple admins as it would need routing and policy rules putting in place both in Azure and on-premises. This would also offer very poor performance due to latency.
You should not change the existing service endpoint to public access to allow access for all networks to sahr678. Although this would technically work, it would be a huge security risk and not adhere to the principle of least privilege.

---

### References

[Allow access to Azure Service Bus namespace from specific virtual networks](https://learn.microsoft.com/en-us/azure/service-bus-messaging/service-bus-service-endpoints)  

[Virtual Network service endpoints](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview)  

[Create, change, or delete service endpoint policy using the Azure portal](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoint-policies-portal)

[Virtual network service endpoint policies for Azure Storage](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoint-policies-overview)  

---

## Q0117:

You company hosts VMs and storage in Azure. There has been a recent attack to the Azure infrastructure that began within the network. Here are the details:

Virtual Network Name : vnet-A
Virtual Subnet Name  : snet-A
Resource Group Name  : eng-rg

Further analysis has shown that it was caused by a SQL instance with subnet delegation permissions to snet-A named eng Delegation. Your manager has asked you to remove this subnet delegation until the issue is resolved.
You need to remove the subnet delegation using PowerShell.

Which cmdlets should you use? To answer, select the appropriate commands from the drop-down menus.

Choose the correct options

OPTION: 
Get-AzVirtualNetwork | Remove-AzDelegation | Get-AzVirtualNetworkSubnetConfig
Remove-AzVirtualNetwork

```
$virtualnetwork = @{
    Name 'vnet-A'
    ResourceGroupName = 'eng-rg
}

$vnet = OPTION @virtualnetwork

$virtualsubnet = @{
    Name 'snet-A'
    VirtualNetwork = $vnet
}

$subnet = OPTION @virtualsubnet

$delegation = @{
    Name = 'engDelegation'
    Subnet - $subnet
}

$subnet OPTION @delegation

Set-AzVirtualNetwork -VirtualNetwork $vnet

```

```
$virtualnetwork = @{
    Name 'vnet-A'
    ResourceGroupName = 'eng-rg
}

$vnet = Get-AzVirtualNetwork @virtualnetwork

$virtualsubnet = @{
    Name 'snet-A'
    VirtualNetwork = $vnet
}

$subnet = Get-AzVirtualNetworkSubnetConfig @virtualsubnet

$delegation = @{
    Name = 'engDelegation'
    Subnet - $subnet
}

$subnet Remove-AzDelegation @delegation

Set-AzVirtualNetwork -VirtualNetwork $vnet

```


---

### Answer:

You should complete the code as follows:

```
$virtualnetwork = @{
    Name 'vnet-A'
    ResourceGroupName 'eng-rg'
}

$vnet = Get-AzVirtualNetwork @virtualnetwork

$virtualsubnet = @{
    Name 'snet-A'
    VirtualNetwork Svnet
}

$subnet Get-AzVirtualNetworkSubnetConfig @virtualsubnet

$delegation = @{
    Name 'engDelegation'
    Subnet $subnet
}

$subnet Remove-AzDelegation @delegation

Set-AzVirtualNetwork -VirtualNetwork $vnet

```

You first need to use the Get-AzVirtualNetwork cmdlet, as this will retrieve the stored virtual network named virtualnetwork.
Then, you should use the Get-AzVirtual Network SubnetConfig, as this will retrieve the subnet where the delegation association is configured. In this scenario, this is subnet named virtualsubnet.
Finally, you should use the Remove-AzDelegation, which will remove the delegation association on the
subnet named virtualsubnet in the network named virtualnetwork.

You should not use the Remove-AzVirtual Network cmdlet at any point, as this would remove the virtual network.

---

### References

[Add or remove a subnet delegation](https://learn.microsoft.com/en-us/azure/virtual-network/manage-subnet-delegation?tabs=manage-subnet-delegation-powershell)  

[What is subnet delegation?](https://learn.microsoft.com/en-us/azure/virtual-network/subnet-delegation-overview)  

Get-AzVirtual Network
Remove-AzDelegation
Get-AzVirtual Network SubnetConfig
Remove-AzVirtual Network

---

## Q0116:

You work for a retail company that recently adopted Microsoft Azure. The following Azure resources have been deployed in the subscription:

| Resource Type | Resource Name | Azure Region |
|---|---|---|
| Virtual Network | Vnet1 | West Europe |
| Virtual Machine | Vm1 | West Europe |
| Azure SQL | Sql01 | UK South |
| Azure SQL | Sql02 | West Europe |
| Azure SQL | Sql03 | US East |

The networking team would like to enable service endpoints on the Azure SQL servers to ensure optimal network routing over the Azure backbone network.

You need to identify which Azure SQL servers support service endpoints.
Which server should you identify?

Choose the correct answer

- Sql01
- Sql03
- Sql02
- Sql01, Sql02, and Sql03

---

### Answer:

- Sql02

You should identify Sq102 as the server for which you can enable service endpoints. Sq102 and Vnet1 share the same region. Service endpoints can only be enabled on Azure SQL servers that are in the same region as the corresponding virtual network.
Service endpoints cannot be enabled on Sql01. Sq101 is in UK South. This is a different region to Vnet1. For Azure SQL, service endpoints can only be enabled in the same region as the virtual network.
Service endpoints cannot be enabled on Sql03. Sql03 is in US East. This is a different region to Vnet1. For Azure SQL, service endpoints can only be enabled in the same region as the virtual network.

---

### References

[Virtual Network service endpoints](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview)  



---

## Q0115:

You are deploying an Azure Cosmos DB instance in your Azure account. Your company has a security policy to not expose any of their services to the internet for public access, except frontend servers, since these do not have public IPs associated with them.
You need to restrict access to the Azure Cosmos DB instance so that:
It is only accessible from a virtual network (VNet) from your Azure account.
No additional costs are incurred..
It is easy to set up.

What should you do?

Choose the correct answer

- Deploy Azure Cosmos DB in your virtual network (VNet).
- Configure IP firewall in Azure Cosmos DB using IP addresses.
- Use Azure Private Link.
- Use Virtual Network service endpoints.

---

### Answer:

- Use Virtual Network service endpoints.

You should use Virtual Network service endpoints. Service endpoints allow secure and private connectivity using the Azure backbone network to restrict access to Azure services. It is easy to set up and there are no additional charges to use service endpoints.
You should not deploy Azure Cosmos DB in your virtual network (VNet). Azure Cosmos DB is an Azure
Platform as a Service (PaaS) and like all Paas in Azure, you cannot deploy it inside a VNet.
You should not use Azure Private Link. Though Azure private links help you to keep your Azure services secure and private, they are not easy to set up and imply additional costs for Private Endpoint, inbound, and outbound traffic.
You should not configure IP firewall on Azure Cosmos DB using IP addresses. Generally, a firewall is used to allow access from the internet or on-premise networks. Since the frontend servers do no have public IPs, you cannot configure the firewall to allow access only from the VMs.

---

### References

[Virtual Network service endpoints](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview)  

[Azure Virtual Network frequently asked questions (FAQ)](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-faq)  

Azure Private Link pricing

[Configure IP firewall in Azure Cosmos DB](https://learn.microsoft.com/en-us/azure/cosmos-db/how-to-configure-firewall)  

[Configure access to Azure Cosmos DB from virtual networks (VNet)](https://learn.microsoft.com/en-us/azure/cosmos-db/how-to-configure-vnet-service-endpoint?toc=%2Fazure%2Fvirtual-network%2Ftoc.json)  

---

## Q0114:

Your company hosts its services both on-premises and in Azure. Your company hosts its services in the UK South region where client devices are connected to storage accounts via private link service.
You have recently opened a new office in France and created a new subscription for this office within your existing tenant hosted in the Azure France Central region. The Dev team in the France office has deployed an Azure SQL Database and need to connect to it from their devices in the France office.
You configure the following services:
Virtual Network in the Azure France Central region
Azure Private DNS Resolver
A Private DNS zone named privatelink.database.windows.net with type A record
Private Endpoint with a private IP address of 172.16.0.23
Private Endpoint with a FQDN of devsql.francecentral.sql.azure.net
During testing, the Dev team reports they are still unable to connect to the Azure SQL Database from their client devices in the France office.
You need to identify and configure the missing resource.
What service should you configure?

Choose the correct answer

- Network Peering with UK South
- Site-to-Site VPN
- Storage Account
- Management Virtual Machine in Azure

---

### Answer:

- Site-to-Site VPN

You should configure a site-to-site VPN from the on-premises France office and the Azure France Central region. For on-premises workloads to resolve the FQDN of a private endpoint, users need to use an Azure Private Resolver to resolve the Azure service public DNS zone in Azure. Azure Private Resolver is an Azure managed service that can resolve DNS queries without the need for a virtual machine acting as a DNS forwarder. In this scenario, this is already deployed in the Azure France Central region, however, the connectivity between the on-premises office and the Azure region should be established.
You should not configure a storage account. A storage account allows you to store files and tables in different types of storage, including blob, file storage and tables. In this scenario, a connection between an Azure SQL database and an on-premises client is established, which does not require any storage. You can configure storage accounts to be publicly accessible which means no connectivity is required between on- premises and the Azure region.
You should not configure a Management Virtual Machine (VM) in Azure. This configuration would allow the Devs to login to the Management VM and potentially connect to the Azure SQL Database from there, however this would not meet the scenario requirement to connect to the Azure SQL Database from their on- premises hosted client devices.

You should not configure network peering between the UK South and France Central region. This configuration would enable services in the UK South region and the Azure France Central region to communicate with each other, but it would not allow the on-premises Dev team client devices connecting to the Azure SQL Database.

---

### References

What is Azure Private Link?

[Azure Private Endpoint DNS integration](https://learn.microsoft.com/en-us/azure/private-link/private-endpoint-dns-integration)  

[Design and implement private access to Azure Services](https://learn.microsoft.com/en-us/training/modules/design-implement-private-access-to-azure-services/)  

---

## Q0113:

Your company hosts its services and application in Azure and uses services like Key Vaults and Storage Accounts, and Microsoft Entra for Identity & Access Management (IAM).
There is no Azure Private Resolver in your tenant. You want to integrate an Azure SQL Database with a new virtual machine (VM).
You need to configure DNS to ensure that the VMs are able to communicate with the Azure SQL Database securely using a Private Endpoint. Your solution should minimize administrative effort.

What three resources should you configure? Each correct answer presents part of the solution.

Choose the correct answers

- Client virtual network
- Private DNS Zone on a Windows DNS Server
- Virtual Network Peering
- FQDN record name and Private IP information
- Private DNS zone in Azure

---

### Answer:

- Client virtual network
- FQDN record name and Private IP information
- Private DNS zone in Azure

In this scenario, the company uses Microsoft Entra rather than Active Directory Domain Services (AD DS) and there is no custom DNS server. Therefore, you need to use a virtual network, Private DNS Zone in Azure and the FQDN record name and private IP address to configure this correctly. In this specific scenario, the Private DNS zone would be private link database.windows.net (as we have an Azure SQL Database) and it would have an A record as well.
You should not configure a Windows DNS Server. A Windows DNS Server is traditionally found in on- premises environments that have an AD DS server. It allows devices that are joined to the domain to resolve hosts name of services that are also hosted on-premises. Firstly, there is no AD DS domain to integrate with, and it also would imply more administrative effort than integrating this with a Private DNS Zone in Azure.
You should not configure Virtual Network Peering. Virtual Network Peering allows two virtual networks to communicate. Both networks need to be hosted in Azure, but they can be in different regions. The Azure SQL database is a PaaS (Platform as a Service) and although the VM is hosted within a virtual network, it does not need to have peering configured to communicate with the Azure SQL Database.

---

### References

[Azure Private Endpoint DNS integration](https://learn.microsoft.com/en-us/azure/private-link/private-endpoint-dns-integration)  

[Azure Private Endpoint private DNS zone values](https://learn.microsoft.com/en-us/azure/private-link/private-endpoint-dns)  

[Private Link and DNS integration at scale](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/private-link-and-dns-integration-at-scale)  

---

## Q0112:

You have an Azure subscription with a virtual network (VNet) and one subnet configured, which is protected
using a Network Security Group (NSG). An on-premises network is connected to the VNet using Express Route. A web app named web01 has also been deployed to the subscription.
You have configured a private endpoint with web01 and a private DNS zone in the VNet. Access from the on- premises network to web01 is not working.
You need to ensure web01 remains inaccessible from the internet.
What should you do first?

Choose the correct answer

- Deploy Azure Virtual Network NAT in the VNet.
- Create an Azure App Gateway and place web01 in the backend pool.
- Deploy an Azure internal load balancer to the VNet.
- Verify that the network policy is disabled on the subnet using Azure PowerShell.

---

### Answer:

- Verify that the network policy is disabled on the subnet using Azure PowerShell.

You should verify that the network policy is disabled on the subnet using Azure PowerShell. NSGs were not previously supported with private endpoints and, as a result, network policies associated with NSGs can cause issues with private endpoint connectivity. Network policies need to be explicitly disabled. You could also perform this step by using Azure CLI or the Resource Manager template.
You should not deploy Azure Virtual Network NAT in the VNet. A NAT gateway is primarily used to flow traffic to an external resource and allows virtual machines to remain private. Traffic from external resources cannot initiate a connection to virtual machines behind a NAT gateway.
You should not create an Azure App Gateway and place web01 in the backend pool. App gateway is a Layer 7 load balancer and is a publicly accessible service. Layer 7 refers to the application layer of the Network Open Systems Interconnection model (OSI model). External access is not removed by default.
You should not deploy an Azure internal load balancer to the VNet. An Azure internal load balancer functions at Layer 4 and deals with non-HTTP/HTTPS traffic. The web app operates at Layer 7 (the Application Layer of the OSI model) and would not be compatible with the load balancer. As a result, introducing an internal Azure load balancer would not resolve the problem of web01 not working from the on-premises network. Furthermore, a load balancer does not have the ability to restrict public access to web01.

---

### References

[Manage network policies for private endpoints](https://learn.microsoft.com/en-us/azure/private-link/disable-private-endpoint-network-policy?tabs=network-policy-portal)  

[What is Virtual Network NAT?](https://learn.microsoft.com/en-us/azure/nat-gateway/nat-overview)

What is Azure Load Balancer?
What is Azure Application Gateway?

---

## Q0111:

Your organization has an Azure subscription with a virtual network (VNet) named vnet1 and one subnet. You deployed an Azure web app named app01. A Site-to-Site VPN tunnel has also been set up to connect the on-premises network to vnet1.
You need to provide the on-premises network direct access to app01. You must meet the following requirements:
app01 should not be exposed to the internet.
Users need to browse to app01 using the full website name: app01.azurewebsites.net.
Which two steps should you take? Each answer presents part of the solution.

Choose the correct answers

- Enable a private endpoint on app01 and link with vnet1.
- Create and configure a private DNS zone.
- Enable a Private Link service on app01.
- Create an Azure application gateway and place app01 in the backend pool.

---

### Answer:

- Enable a private endpoint on app01 and link with vnet1.
- Create and configure a private DNS zone.

You should enable a private endpoint in vnet1. To isolate the web app, you must first enable and create al private endpoint. This will remove the public IP address from the web app and Azure will assign it a private IP address instead.
You should also create and configure a private DNS zone. The requirements state that users need to browse to app01 using the Fully Qualified Domain Name (FQDN). This can only be done if a private DNS zone is created and associated with the web app. Azure can automatically create this private DNS zone at the time the private endpoint is created, or alternatively it can be created manually afterwards. In addition to this, the appropriate DNS records will also need to be created from the source network or host to the private endpoint.
You should not enable a Private Link service on app01. Azure web apps do not require a Private Link service to be enabled; only a private endpoint is required in vnett. A Private Link service is usually configured if you have a service that you need to make available for a consumer network.
You should not create an Azure application gateway and place app01 in the backend pool. Azure Application Gateway is a layer 7 load balancer and is a publicly accessible service. External access is not removed by default.

---

### References

[Using Private Endpoints for App Service apps](https://learn.microsoft.com/en-us/azure/app-service/overview-private-endpoint)  

[Quickstart: Create a private endpoint by using the Azure portal](https://learn.microsoft.com/en-us/azure/private-link/create-private-endpoint-portal?tabs=dynamic-ip) 

[Azure Private Endpoint private DNS zone values](https://learn.microsoft.com/en-us/azure/private-link/private-endpoint-dns)  


What is Azure Private DNS?
What is Azure Application Gateway?

---

## Q0110:

![image info](./Q110_1.PNG)


You work for Jinsey Electric, which recently acquired a company called Skrul Tech. Both organizations have separate Azure resources and subscriptions. Jinsey Electronics is connected to Azure using Express Route. See the exhibit for the current configuration.

You need to configure secure access to DATAVM1. 
The solution must include the following requirements:

- DATAVM1 should only be accessible from Jinsey Electronics HQ and vnet1.
- DATAVM1 should not be exposed to the internet.
- The solution must be cost effective.

What should you do?

Choose the correct answer

- Create an internal standard load balancer in vnet2 and add DATAVM1 in the backend pool. Then, configure a Private Link service in vnet2 and a corresponding private endpoint in vnet1.

- Create a basic internal load balancer in vnet2 and add DATAVM1 in the backend pool. Then, configure a Private Link service in vnet2 and a corresponding private endpoint in vnet1.

- Deploy Azure Firewall Premium in vnet2. Create a network rule to allow traffic from 10.0.0.17 to 10.7.0.0/24.

- Create a virtual network peering connection between vnet1 and vnet2.


---

### Answer:

- Create an internal standard load balancer in vnet2 and add DATAVM1 in the backend pool. Then, configure a Private Link service in vnet2 and a corresponding private endpoint in vnet1.


You should create an internal standard load balancer in vnet2. Then, configure a Private Link service in vnet2 and a corresponding private endpoint in vnet1. A private link can be used to ensure access from selected virtual networks have direct private access to the selected Azure service. An internal standard load balancer is required for the Private Link service. Also, there are conflicting IP addresses in both subnets, which proves that virtual network peering is out of the question, as overlapping address spaces are not supported. For Jinsey Electronic employees to connect to DATAVM1 securely, a Private Link service must be established in the destination vnet2. To finalize the configuration, a private endpoint needs to be created in vnet1, which can be mapped to the Private Link service.

You should not create a virtual network peering connection between vnet1 and vnet2. Virtual network peering can be used to connect two or virtual networks together in Azure. Networks in different regions can also be connected, which is known as Global Virtual Network Peering. Overlapping address spaces are not supported with peering. The exhibit shows that both virtual machines across both organizations are using the same IP addresses.
You should not deploy Azure Firewall Premium in vnet2, nor create a network rule to allow traffic from 10.0.0.17 to 10.7.0.0/24. Azure Firewall is not a cost-effective solution and does not meet the requirements. Also, there is no mention of user-defined routes (UDRs), which would be required for the traffic flow to work correctly. UDRs are typically used to force network traffic in Azure across required network paths approved by business requirements. For instance, you may want to configure all traffic from a particular Azure virtual network subnet to traverse through an Azure Firewall. A UDR would be required to force all traffic to pass through Azure Firewall from this subnet.
You should not create a basic internal load balancer in vnet2 and add DATAVM1 in the backend pool, and then configure a private link service in vnet2 and a corresponding private endpoint in vnet1. Basic standard load balancers are not supported with the Private Link service.

---

### References

[Virtual network peering](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-peering-overview)  

[Virtual network traffic routing](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-udr-overview)  

[Azure Virtual Network frequently asked questions (FAQ)](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-faq)  

What is Azure Private Link service?

---

## Q0109:


You are an Azure administrator for your organization and have a subscription with two Azure SQL databases. A Site-to-Site VPN tunnel has been configured to connect the on-premises network to Azure. The networking team does not want the Azure SQL databases to be accessible over the internet and have identified a task of enabling an Azure Private Link service on the Azure SQL databases.

The following Azure built-in roles have been applied at subscription level:

| User | Assigned Azure Role |
|---|---|
| User1 | Owner |
| User2 | Network Contributor |
| User3 | Contributor |
| User4 | SQL DB Contributor |

You need to delegate the Azure Private Link on an Azure SQL task to your colleagues by identifying which users have the correct roles to complete the task.

Which users should you identify?

Choose the correct answer

- User1, User2, User3 and User4
- User1 only
- User1, User3, and User4 only
- User1 and User3 only

---

### Answer:

- User1 and User3 only

You should choose User1 and User3. Role-based access control (RBAC) can be used to apply controlled roles to the majority of Azure services. These roles are defined by Microsoft. For Azure Private Link services, you need to have one of the following roles assigned: Owner, Contributor, or Network Contributor. Specific permissions relating to the service you are enabling Private Link on will also need to be defined, e.g. SQL DB Contributor. User1 and User3 are the only users that have the necessary permissions to complete this task in its entirety. According to the requirement, the Private Link service is required on Azure SQL databases. To fully enable Private Link, you also require specific permissions to the service itself (Azure SQL). While User2 has the permissions to enable the Private Link service in general, the Network Contributor role does not have SQL DB Contributor rights and, as a result, User2 would not be able to enable private link on Azure SQL. Similarly, User4 has the required SQL DB Contributor rights, but no Network Contributor role to create the private link.
You should not choose User1 only. User1 has the Owner role assigned, which is a valid user that can enable the Azure Private Link service but, as above, User3 is also a valid user.
You should not choose User1, User2, User3 and User4. User2 can enable Private Link Service, but this user also requires the SQL DB Contributor role to complete the task end-to-end, which they do not have. User4 does not have the correct permissions to create the Private Link service as they only have access to the Azure SQL databases.
You should not choose User1, User3, and User4. As previously described, User4 only has the SQL DB Contributor role, which is not enough to complete the entire task of enabling an Azure Private Link service on the Azure SQL databases.

---

### References

[Azure RBAC permissions for Azure Private Link](https://learn.microsoft.com/en-us/azure/private-link/rbac-permissions)  

Azure built-in roles



---

## Q0108:

![image info](./Q108_1.PNG)

Your company has the Azure environment shown in the network architecture exhibit. The company has two Azure subscriptions for integration purposes between the subscriptions.
An Azure Load Balancer is deployed in front of the Application Server. Your manager wants VMA, VMB, VMC, and VMD to use a separate Vnet address from VnetB to access the application server.
You need to enable the VMs to access the application server as required by the manager.
Which two actions should you perform? Each correct answer presents part of the solution.

Choose the correct answers

- Use subnet delegations.
- Use packet capture.
- Implement ExpressRoute Direct.
- Create a private endpoint.
- Create a private link service.

---

### Answer:

- Create a private endpoint.
- Create a private link service.

You should create a private link service to enable VMA, VMB, VMC, and VMD to access the application server through a separate Vnet address. The creation of the private link service is done within the first Azure subscription between the Azure Load Balancer and Application Server. Creating a private link service will enable you to privately access any service in another Virtual Network (Vnet) from your own Vnet.
You should also create a private endpoint. This action is done within the second Azure subscription where you use the private link service to create a private endpoint. Creating the private endpoint will enable VMA, VMB, VMC, and VMD to access the application server through a separate Vnet address as required by the manager.
You should not implement Express Route Direct. Express Route Direct is used to connect you directly to the global network of Microsoft, but it cannot be used to enable the VMs in VnetB to connect to the application server
You should not use packet capture. This feature, within Azure Network Watcher, enables you to capture packets on virtual machines and capture traffic.
You should not use subnet delegations. A subnet delegation will allow you to label a specified subnet for an Azure Platform as a service (PaaS) that requires to be injected within a virtual network.

---

### References

[Quickstart: Create a Private Link service by using the Azure portal](https://learn.microsoft.com/en-us/azure/private-link/create-private-link-service-portal?tabs=dynamic-ip)  

[About ExpressRoute Direct](https://learn.microsoft.com/en-us/azure/expressroute/expressroute-erdirect-about)    

[Packet capture overview](https://learn.microsoft.com/en-us/azure/network-watcher/packet-capture-overview)  

[What is subnet delegation?](https://learn.microsoft.com/en-us/azure/virtual-network/subnet-delegation-overview)  

What is Azure Private Link Service?

What is Private Endpoint?

---

## Q0107:

You deploy virtual machines (VMs) for a video streaming application in a virtual network (VNet). Developers in your team want the application to access the Azure storage account named VidStrg1 in order to serve the video files from the video streaming application. The security team recommends restricting access to VidStrg1 only to the VNet where the VMs are deployed. The traffic should always remain private.
You have deployed Azure Private Link to provide access to VidStrg1 from the video streaming applications deployed in the VMs.
For each of the following statements, select Yes if the statement is true. Otherwise, select No.

Connection to the storage account is public.
No

Private Link can extend for on-premises network traffic using ExpressRoute or VPN tunnels.
Yes

Private Link can integrate with private Domain Name Server (DNS).
Yes

---

### Answer:

Azure Private Link allows accessing Azure Platform as a Service (PaaS) over a private IP address within the virtual network (VNet). Therefore, the connection to the storage account is not public, but private. Private Link creates a private endpoint within a VNet, which gives it a private IP address attached to a Network Interface (NIC). Using the private IP, you can access VidStrg1 from the application without the traffic ever leaving your VNet.
Private Link can extend for on-premises network traffic using Express Route or VPN tunnels. Since Private Link creates a private IP in the VNet, it is similar to any other resource within the VNet. So any resource part of the VNet can reach the storage account VidStrg1 easily. Similarly, resources deployed on the on-premises network can directly reach the storage account on the secure channel.
Private Link can integrate with Private DNS. The NIC associated with the Private Link contains the information to configure your DNS. It provides you with the private IP address and Fully Qualified Domain Name (FQDN) of the private link resource. Using this information, you can override the DNS resolution for the private endpoint.

---

### References

What is Azure Private Link?

[Azure Private Endpoint DNS configuration](https://learn.microsoft.com/en-us/azure/private-link/private-endpoint-dns)

[Tutorial: Connect to a storage account using an Azure Private Endpoint](https://learn.microsoft.com/en-us/azure/private-link/tutorial-private-endpoint-storage-portal?tabs=dynamic-ip)  

---

## Q0106:

You have associated a custom domain name with Azure Front Door. The Azure Front Door backend pool is associated with the IP address of an Azure virtual machine.
You navigate to the custom domain name, but receive an HTTP 400 status code error.
What should you do to resolve the problem?
Choose the correct answer
Change the health probe method to HEAD.
Create a path in the routing rule pointing to /*.
Create a routing rule and tick the custom domain name under Frontend hosts.
Select the custom domain in Azure Front Door, enable custom domain HTTPS and use a Front Door-managed certificate.

---

### Answer:

You should create a routing rule and tick the custom domain name under Frontend hosts. The 400 status code error is often presented when Azure Front Door cannot associate an appropriate routing rule with the Frontend hosts.
custom domain. A routing rule must be created and the custom domain name needs to be selected under
You should not select the custom domain in Azure Front Door, enable custom domain HTTPS and use a Front Door-managed certificate. This option is selected when you want Azure Front Door to manage the TLS/SSL certificate for HTTPS on the custom domain. This would not solve the 400 status code.
You should not change the health probe method to HEAD. An Azure Front Door health probe is used to determine how healthy the backend pool resources are. A health probe configured with the HEAD method probes the backend pool resource, but it does not expect a return message in the response. This can drastically reduce the network overhead and costs.

You should not create a path in the routing rule pointing to /*. Pattern matches are configured in routing rules, which allows Azure Front Door to process URLs and what to do with them. If the custom domain name was Microsoft.com and /* was added to the routing rule as a path, then a request made to Microsoft.com/cddsa would match the path. This can be useful if you have a distributed web app. For instance, if you have two different web apps, you may want to redirect users to web app 1 for login and authentication, then redirect users to web app 2 for everything else. This is where routing rules would be used with Azure Front Door.

---

### References

[Troubleshoot Azure Front Door](https://learn.microsoft.com/en-us/azure/frontdoor/troubleshoot-issues)  

[Configure HTTPS on a Front Door (classic) custom domain](https://learn.microsoft.com/en-us/azure/frontdoor/front-door-custom-domain-https)  

[Health probes](https://learn.microsoft.com/en-us/azure/frontdoor/health-probes)  

[How requests get matched to a route configuration](https://learn.microsoft.com/en-us/azure/frontdoor/front-door-route-matching?pivots=front-door-standard-premium)  

[Add a custom domain to Azure Front Door](https://learn.microsoft.com/en-us/azure/frontdoor/front-door-custom-domain)  

[Quickstart: Create a Front Door for a highly available global web application](https://learn.microsoft.com/en-us/azure/frontdoor/quickstart-create-front-door)   


---

## Q0105:

You are the Azure administrator for your organization. You have an Azure subscription with two virtual networks (VNets) situated in UK South and East US.
You have deployed one Azure web app in each VNet. You need to route Layer 7 HTTP client requests to the fastest and most available web app backend.
Which solution should you deploy?

Choose the correct answer

- Azure Application Gateway
- Azure public load balancer
- Azure Firewall
- Azure Front Door

---

### Answer:

- Azure Front Door

You should deploy Azure Front Door. Azure Front Door handles requests at layer 7 and is a global service. The two Azure web apps are in different regions and, as a result, a global load-balancing solution is required.
You should not deploy Azure Application Gateway. Azure Application Gateway is a regionally-based Azure service. This does not meet the requirements, as the web apps are not in the same region. Azure Application Gateway can be useful if you have two sets of backend pools: one that stores images and the other that stores videos. A path-based routing rule can then be created to direct end-users to the relevant backend pool depending on the URL; e.g., /images or /videos.
You should not deploy an Azure public load balancer. An Azure load balancer is recommended for non- HTTPS traffic. This solution would not apply, because the backend services are Azure web apps that will be processing HTTP/HTTPS requests. A public load balancer can be useful if you have a web tier in your virtual network, comprising of two or more virtual machines. Users may then need to reach these web servers from the internet on port 80. A public load balancer can be used to achieve this..
You should not deploy Azure Firewall. Azure Firewall is an Azure network security service that can be used to filter both inbound and outbound network traffic. Azure Firewall is not the correct choice in this scenario as it does not have the functionality to load balance network traffic based on the location and availability of resources.

---

### References

What is Azure Front Door?
What is Azure Application Gateway?
What is Azure Load Balancer?
What is Azure Firewall?

---

## Q0104:

Your manager wants you to create a custom rule to block a suspicious request that is passing through your Web Application Firewall on your Azure application gateway.
You need to complete the Azure PowerShell script to create an Azure Front Door.
How should you complete the script? To answer, select the appropriate options from the drop-down menus.

Choose the correct options:

7.  OPTION-1 "5"
12. OPTION-2

OPTION-1: -SampleSize | -'Priority' | -BlobSizeInBytes
OPTION-2: -FrontDoorName $fdname | -UseRemoteGateways | -AllowGatewayTransit

1. $backendObject1 = New-AzFront DoorBackendObject
2. -Address $webappl. DefaultHostName
3. $Health ProbeObject New-AzFrontDoorHealth ProbeSettingObject
4. -Name "SHPA"
5. $LoadBalancingSettingObject = New-AzFront DoorLoadBalancingSettingObject
6. -Name "OLBA"
7. -SampleSize "5"
8. -SuccessfulSamplesRequired "3"
9. -AdditionalLatencyInMilliseconds "0"
10. $BackendPoolObject = New-AzFront DoorBackendPoolObject
11. -Name "PBMA"
12. -FrontDoorName $fdname
13. -ResourceGroupName myResourceGroupFD
14. -Backend $backendObject1
15. -HealthProbeSettingsName "SHPA"
16. -LoadBalancingSettingsName "OLBA"

---

### Answer:

You should complete the Azure PowerShell script as follows:

1. $backendObject1 New-AzFront DoorBackendObject
2. -Address Swebappi.DefaultHostName
3. SHealthProbeObject New-AzFront DoorHealthProbeSettingObject
4. -Name "SHPA"
5. $LoadBalancingSettingObject New-AzFront DoorLoad BalancingSettingObject
6. -Name "OLBA"
7. -SampleSize "5"
8. -SuccessfulSamplesRequired "3"
9. -AdditionalLatencyInMilliseconds "0"
10. $BackendPoolObject New-AzFront DoorBackendPoolObject
11. -Name "PBMA"
12. -Front DoorName $fdname
13. -ResourceGroupName myResourceGroupFD`
14. -Backend $backendObjecti
15. -HealthProbeSettingsName "SHPA"
16. -LoadBalancingSettingsName "OLBA"

You should use -SampleSize in line 7. This expression defines the number of health probes required for evaluating backend health. Backend health is important to be known since it determines if your instance is healthy or not.
You should not use -blobSizeInBytes in line 7. This expression is used in the script of creating a Binary Large Object (blob) storage in Azure and cannot be used in this script. This expression defines the size of the blob.
You should not use 'Priority' in line 7. This expression is used in the script of adding rules to a network security group (NSG). This expression defines the priority of the rule to be added.
You should use -Front DoorName $fdname in line 12. This expression is used to define the name of the Azure Front Door used within the backend pool. A backend pool is a place where your app instance receives and responds to traffic.
You should not use -AllowGateway Transit in line 12. This expression is used to enable the flow of gateway traffic from a spoke to a hub. Using this expression will cause an error in the script.
You should not use -UseRemoteGateways in line 12. This expression is used to enable the connection between an on-premises and a remote network. Using this expression will cause an error in the script.
References
Quickstart: Create a Front Door for a highly available global web application using Azure PowerShell
Calculate the total billing size of a blob container
Hub-spoke network topology in Azure
Origins and origin groups in Azure Front Door
Add an inbound network security group rule

---

### References

[Quickstart: Create a Front Door for a highly available global web application using Azure PowerShell](https://learn.microsoft.com/en-us/azure/frontdoor/quickstart-create-front-door-powershell)  

[Calculate the total billing size of a blob container](https://learn.microsoft.com/en-us/azure/storage/scripts/storage-blobs-container-calculate-billing-size-powershell)  

[Hub-spoke network topology in Azure](https://learn.microsoft.com/en-us/azure/architecture/networking/architecture/hub-spoke?tabs=powershell)  

[Origins and origin groups in Azure Front Door](https://learn.microsoft.com/en-us/azure/frontdoor/origin?pivots=front-door-standard-premium)  

[Add an inbound network security group rule](https://learn.microsoft.com/en-us/azure/service-fabric/scripts/service-fabric-powershell-add-nsg-rule)  

---

## Q0103:

Company A configured Azure Front Door and named the frontend host CompanyA-corp. The default domain name that will be assigned to this company's Azure Front Door will be CompanyA-corp.azurefd.net.
The company employees are not aware of the CompanyA-corp.azurefd.net domain name. The company should use a valid, well-known custom domain so that its users can access the resources behind Azure Front Door.
You need to create a record type for your custom domain to map the custom domain to the Azure Front Door Fully Qualified Domain Name (FQDN).
Which record type should you create?

Choose the correct answer

- AAAA record
- CNAME record
- NS record
- A record

---

### Answer:

- CNAME record

You should create a Canonical Name (CNAME) record to map the custom domain to the Azure Front Door Fully Qualified Domain Name (FQDN). The CNAME record is like an alias record, which you can use to map one domain name to another domain name..
You should not use an A (Address) record to map the custom domain to the Azure Front Door FQDN. An A record is used to map a domain name with an IP address. Note that an A record will always be used to map an IP to a domain name, it will never be used to map two domain names.
You should not use an AAAA (pronounced quad A) record to map the custom domain to the Azure Front Door FQDN. An AAAA record is used to map an IPv6 address to the domain name.
You should not use a Nameserver (NS) record to map the custom domain to the Azure Front Door FQDN. NS records are used to configure the information regarding the authoritative name servers for a particular domain name. Usually, there is more than one NS record configured for redundancy purposes. The NS server is the main location where the actual domain to IP mapping file exists.

---

### References

[DNS Zones and Records overview](https://learn.microsoft.com/en-us/azure/dns/dns-zones-records)  

[Tutorial: Add a custom domain to your Front Door](https://learn.microsoft.com/en-us/azure/frontdoor/front-door-custom-domain)  

[Quickstart: Create a Front Door for a highly available global web application](https://learn.microsoft.com/en-us/azure/frontdoor/quickstart-create-front-door)  

---

## Q0102:

You plan to configure an accounting application that will create a stateful session between the client and the server.
The company will use Azure Front Door to enable a stateful session between the client and the backend servers, so that any incoming request for a specific transaction or TCP stream from the same source IP is always relayed to the same backend server.
Which Azure Front Door feature should you use to implement this requirement?

Choose the correct answer

- Web Application firewall
- Split Transmission Control Protocol (TCP)
- Session Affinity
- Secure Sockets Layer (SSL) offloading

---

### Answer:

- Session Affinity

You should use the Session Affinity feature of Azure Front Door to make sure a specific transaction or Transmission Control Protocol (TCP) stream from the same source IP is always relayed to the same backend server. Azure Front Door uses cookies to create session affinity between the end user and Azure Front Door.
You should not use Split TCP. Split TCP is a technique where the incoming TCP requests that have a large round-trip time (RTT) are split into two connections. The first TCP connection is maintained between the end user and the Frontend, and the second connection is maintained between the Frontend and the Backend. This setup results in minimizing the latency between end users and Azure Front Door.
You should not use Secure Sockets Layer (SSL) offloading. By using SSL offloading, the initial Transport Layer Security (TLS) handshake is established between the end user web client and Azure Front Door, this greatly reduces the load on the backend server resources.
You should not use the Web Application firewall (WAF). WAF is an Application Gateway feature that provides an option to deploy a complete firewall solution that protects against threats from the public Internet and is compliant with Core Rule Set (CRS) 3.1, 3.0, or 2.2.9 from the Open Web Application Security Project (OWASP).

---

### References

[Traffic routing methods to origin](https://learn.microsoft.com/en-us/azure/frontdoor/routing-methods)  

[What is Azure Web Application Firewall on Azure Application Gateway?](https://learn.microsoft.com/en-us/azure/web-application-firewall/ag/ag-overview)  

[Configure HTTPS on a Front Door (classic) custom domain](https://learn.microsoft.com/en-us/azure/frontdoor/front-door-custom-domain-https)  

[Routing architecture overview](https://learn.microsoft.com/en-us/azure/frontdoor/front-door-routing-architecture?pivots=front-door-standard-premium)    

---

## Q0101:

You want to use Azure Front Door to design a global, highly available, and resilient web application. Azure Front Door will be used to manage and distribute the traffic towards the internal and public Azure endpoints.
You need to optimize web performance for global users.
Which two Azure Front Door features can improve performance? Each correct answer presents a complete
solution.

Choose the correct answers

- URL rewrite
- Split Transmission Control Protocol (TCP)
- Caching
- HTTP redirect to HTTPS
- Backend health probes

---

### Answer:

- Split Transmission Control Protocol (TCP)
- Caching

The Split Transmission Control Protocol (TCP) feature of the Azure Front Door optimizes web performance for global users. Split TCP is a technique where the incoming TCP requests that have a large round-trip time (RTT) are split into two connections. The first TCP connection is maintained between the end user and the Frontend, and the second connection is maintained between the frontend and the backend. This setup results in minimizing latency between the end users and Azure Front Door.
The caching feature of Azure Front Door optimizes web performance for global users. By caching the data retrieved from the backend servers, Azure Front Door greatly reduces the response time towards the end users.
The health probes feature of Azure Front Door does not optimize web performance for global users. The backend health probes are useful to keep track of the availability of internal resources, but they do not help with the optimization of incoming HTTP requests.
The HTTP redirect to HTTPS feature of Azure Front Door does not optimize web performance for global users. By configuring this option in Azure Front Door, all the HTTP requests will be redirected to HTTPS. This does not result in minimizing the load on the internal servers, therefore, it would not result in optimizing web traffic performance.
The URL rewrite feature of Azure Front Door does not optimize web performance for global users. The URL rewrite feature of Azure Front Door can be used to modify the incoming URL path and add different parameters to it.

---

### References

[Caching with Azure Front Door](https://learn.microsoft.com/en-us/azure/frontdoor/front-door-caching?pivots=front-door-standard-premium)  

[Configure HTTPS on a Front Door (classic) custom domain](https://learn.microsoft.com/en-us/azure/frontdoor/front-door-routing-architecture?pivots=front-door-standard-premium)  

[Tutorial: Configure HTTPS on a Front Door custom domain](https://learn.microsoft.com/en-us/azure/frontdoor/front-door-custom-domain-https)  

[URL redirect](https://learn.microsoft.com/en-us/azure/frontdoor/front-door-url-redirect?pivots=front-door-standard-premium)  

[URL rewrite](https://learn.microsoft.com/en-us/azure/frontdoor/front-door-url-rewrite?pivots=front-door-standard-premium)  

What is Azure Front Door?

---

## Q0100:

Your company has multiple new web applications that need to be hosted in Azure. Each app will use an Application Gateway service that will be used to balance web traffic, with each one having different scaling requirements as shown in the table below:

| App Name | Scaling Requirements |
|---|---|
| WebApp1 | Needs to scale out within eight minutes |
| WebApp2 | Unexpected traffic spikes require max instance count of 30 |
| WebApp3 | Unexpected traffic spikes require max instance count of 100 |
| WebApp4 | Needs to scale out within 10 minutes |
| WebApp5 | Unexpected traffic spikes require max instance count of 20 |

You need to configure each Web Application with the correct Application Gateway SKU to ensure that the scaling requirements are met.

Which three Web Applications should you configure with the Application Gateway v2 SKU? Each correct answer presents a complete solution.

Choose the correct answers

- WebApp2
- WebApp5
- WebApp1
- WebApp4
- WebApp3

---

### Answer:

- WebApp1
- WebApp4
- WebApp3

You should configure WebApp1, WebApp3, and WebApp4 with the Application Gateway v2 SKU.
WebApp1 needs to be able to scale out within eight minutes and WebApp4 needs to scale out within 10 minutes of the event trigger. For Application Gateway v2 SKU, auto scaling takes six to seven minutes to scale out and provision additional set of instance. This meets the auto scaling requirements of WebApp1 and WebApp4.
WebApp3 needs the max instance count to be set to 100 for unexpected traffic spikes. The Application
Gateway v1 SKU has a maximum of 32 instance counts, whereas the v2 SKU has a maximum instance count of 125, therefore WebApp3 needs to have the v2 SKU in order to meet the auto scaling requirements.
WebApp2 and WebApp5 have an unexpected traffic spike instance count requirement lower than 32 which is the limit for v1 SKU, 
therefore they do not need the v2 SKU to meet their auto scaling requirements.

---

### References

[Scaling Application Gateway v2 and WAF v2](https://learn.microsoft.com/en-us/azure/application-gateway/application-gateway-autoscaling-zone-redundant)  

[Application Gateway infrastructure configuration](https://learn.microsoft.com/en-us/azure/application-gateway/configuration-infrastructure)  

[Quickstart: Direct web traffic with Azure Application Gateway - Azure portal](https://learn.microsoft.com/en-us/azure/application-gateway/quick-create-portal)   

[Application Gateway high traffic support](https://learn.microsoft.com/en-us/azure/application-gateway/high-traffic-support)

---

## Q099:

Your company hosts its infrastructure in Azure. You have a number of web applications that use different load balancing services in Azure as shown in the table below:

| App Name | Load Balancing Service |
|---|---|
| WebApp A | Azure Front Door |
| WebApp B | Azure Front Door |
| WebApp C | Azure Traffic Manager |
| WebApp D | Azure Load Balancer |

The dev team is creating a new web application but wants to integrate it with Azure Application Gateway load-balancing. They have asked you to recommend the features that are supported by this service to ensure they can implement it within their new web application.
You need to identify the relevant features of Azure Application Gateway that will be supported in the new web application.

Which three Azure Application Gateway features should you identify? Each correct answer presents part of the solution.

Choose the correct answers

- Support for the UDP and TCP protocols
- Bot manager protection
- DNS-based load balancing
- Support for the WebSocket protocol
- Support for HTTP and HTTPS traffic
- HTTPS site redirection

---

### Answer:

- Support for the WebSocket protocol
- Support for HTTP and HTTPS traffic
- HTTPS site redirection

You should recommend that the new web application should be able to integrate with the following Azure Application Gateway features:
• Support for the WebSocket protocol
HTTPS site redirection
• Support HTTP and HTTPS traffic
The Azure Application Gateway supports the HTTP. HTTPS, HTTP/2, and WebSocket protocols. Other features include redirection to another site, or from HTTP and HTTPS. You can also get dynamic auto scaling and custom error page features with Azure Application Gateway.
Bot manager protection is a feature of Azure Front Door that is already being used in your environment for WebAppA and WebAppB. Bot manager protection is protection against malicious actors and uses Microsoft's own Threat Intelligence to increase protection.
DNS-based load balancing is a feature of Azure Traffic Manager that is already being used for WebAppC. DNS load balancing allows the application to distribute traffic to your applications to global Azure regions.
Support for the UDP and TCP protocols is a feature of Azure Load Balancer that is already being used for WebAppD. Support for TCP and UDP traffic means that the Azure load balancer can offer ultra-low latency at layer 4 and handle millions of requests per second.

---

### References

[Design Azure Application Gateway](https://learn.microsoft.com/en-us/training/modules/load-balancing-https-traffic-azure/2-design-azure-application-gateway?ns-enrollment-type=learningpath&ns-enrollment-id=learn.wwl.designing-implementing-microsoft-azure-networking-solutions-az-700)  

[Having difficulty choosing the right load balancing solution for your web application on Azure?](https://techcommunity.microsoft.com/t5/fasttrack-for-azure/having-difficulty-choosing-the-right-load-balancing-solution-for/ba-p/3702615)  

Load-balancing options

---

## Q098:

Your company hosts its infrastructure in a hybrid model, both on-premises and Azure. The dev team has recently developed a new web-based application that is being tested. The testing feedback is as follows:
Performance issues at peak traffic times.
Manual scaling causing capacity issues.
The web app is vulnerable to SQL injection attacks.
The web app is unable to handle unencrypted traffic without high cost.
The web application is only handling HTTPS traffic from virtual networks (VNets) within the same region and requires some type of load-balancing service to mitigate the issues found during testing.
You need to recommend an Azure native load-balancing solution that can mitigate the issues from the testing.

Which load-balancing service should you recommend?

Choose the correct answer

- Azure Front Door
- Azure Traffic Manager
- Azure Application Gateway
- Azure Load Balancer

---

### Answer:

- Azure Application Gateway

You should recommend the Azure Application Gateway load balancer to mitigate the issues found in the testing. Azure Application Gateway is a web traffic-specific load-balancer that supports auto scaling based on changing traffic patterns, can be configured with a web application firewall (WAF), which will protect the applications against SQL injections and other common exploits, and enables you to use Secure Socket Layer (SSL/TLS) termination, which allows you to mitigate high costs from unencrypted traffic.

You should not recommend the Azure Front Door load balancer to mitigate the issues found in the testing. Azure Front Door is used for internet-facing applications but it is used for more global delivery rather than regional as in this scenario. It does not offer the additional protection for the web applications against SQL injection and other common exploits but it does allow SSL offloading and fast failover.

---

### References

[Azure Application Gateway features](https://learn.microsoft.com/en-us/azure/application-gateway/features)  

[Load-balancing options](https://learn.microsoft.com/en-us/azure/architecture/guide/technology-choices/load-balancing-overview)  

[What is Azure Front Door (classic)?](https://learn.microsoft.com/en-us/azure/frontdoor/classic-overview)

What is Azure Load Balancer?
What is Azure ?

---

## Q097:

Your company hosts its infrastructure in Azure. You are deploying three new applications that will use Azure Application Gateway to load balance web traffic to each application.
All three applications will use TLS termination at the gateway and require certificates with the following requirements:


| Application Name | TLS termination certificate details and requirements |
|---|---|
| WebAppA | Needs to support five subdomains based on the *.iamanitgeek.com domain. |
| WebAppB | Will be used in the development environment only. |
| WebAppC | The certificate will be issued by a third party. |


You need to use the correct certificate type for each applications TLS termination.
Which three certificate types should you use in your Application Gateway TLS termination configuration for the applications? Each correct answer presents part of the solution.

Choose the correct answers

- Self-signed certificate
- Unified Communications certificate
- Extended Validation certificate
- Wildcard certificate
- Multi-Domain certificate
- Certificate authority (CA) certificate

---

### Answer:

- Self-signed certificate
- Wildcard certificate
- Certificate authority (CA) certificate


You should use the following three certificate types for your Azure Application Gateway TLS termination certificate:

- Certificate authority (CA) certificate
- Wildcard certificate
- Self-signed certificate

WebAppA needs a certificate that can support five subdomains based on the *iamanitgeek.com domain. This would require a wildcard certificate as it can support as many subdomains as you need. It does not support iamanitgeek.com so users need to ensure that they type www when accessing the URL for WebAppA.
WebAppB needs a self-signed certificate as it is only being used for development purposes where it does not matter if the client browsers do not trust the certificate.
WebAppC needs a certificate authority (CA) certificate as this is normally a digital certificate issued by a third-party CA like Comodo.
You do not need a multi-domain certificate for any of the new applications. This type of certificate allows you to use up to 100 different domain names and subdomains with a single certificate. In this scenario, you only have a single domain and multi-domain certificates are not supported for Azure Application Gateway TLS termination.
You do not need a unified communications certificate for any of the new applications. This type of certificate is used to secure Microsoft Exchange and Live communications services. In this scenario, you have three web applications and none are being used for these types of services. Besides, this type of certificate is not supported for Azure Application Gateway TLS termination.
You do not need an extended validation certificate for any of the new applications. This is the most expensive type of certificate you can get and is mainly used for high-profile websites. Although Azure Application Gateway TLS termination supports this type of certificate, it does not meet any of the requirements.

---

### References

[Overview of TLS termination and end to end TLS with Application Gateway](https://learn.microsoft.com/en-us/azure/application-gateway/ssl-overview)  

[Configure end-to-end TLS by using Application Gateway with the portal](https://learn.microsoft.com/en-us/azure/application-gateway/end-to-end-ssl-portal)  

[6 Types of SSL Certificates for Your Website](https://www.liquidweb.com/blog/ssl-certificates/)  

What is Azure Application Gateway? 

---

## Q096:

Your company hosts its Infrastructure in Azure. You have recently implemented an Azure Application Gateway to help manage traffic to multiple websites to allow your clients to purchase goods.
The Service Delivery team has had feedback from over 3000 customers that have reported slow performance on the websites recently. After further investigation you find that this performance degradation correlates with peak usage times on a Friday, Saturday, and Sunday.
You need to implement a solution that resolves this issue. Your solution should minimize cost and administrative effort

What should you do?

Choose the correct answer

- Configure Autoscaling on the Application Gateway.
- Configure manual scaling on the Azure Application Gateway.
- Configure Azure Load Balancer.
- Configure Azure Traffic Manager.

---

### Answer:

- Configure Autoscaling on the Application Gateway.

You should configure Autocaling on the Azure Application Gateway as this will allow the resources to scale up automatically during the peak usage times. When the peak time has passed and the usage has gone down, the resources would automatically scale down as there is less traffic. As Autoscaling automates the increase in resources depending on the amount of traffic, this minimizes the administrative efforts. Furthermore, this is a feature of the existing Azure Application Gateway so the costs are minimized.
You should not configure manual scaling on the Azure Application Gateway. Although this would allow the resources to scale up during the peak usage times, it will is a manual process, where an Administrator needs to configure increased resources and then remove them once the peak traffic time has finished. This would require additional administrative effort but would minimize cost, as it is a feature of the existing Azure Application Gateway.
You should not configure Azure Traffic Manager. Azure Traffic Manager is one of the multiple load balancing services that can be used to help manage and distribute traffic for Azure Resources. In this scenario, we have multiple websites that require load-balancing that supports http(s) traffic and Azure Traffic Manager is a non-https(s) load-balancing service. Implementing an additional load-balancing solution would also
increase cost and administrative effort.
You should not configure Azure Load Balancer. Azure Load Balancer is an Azure service that allows you to load balance layer 4 traffic that supports UDP and TCP protocols. It enables high performance, low latency and zone redundancy; however, it supports non-http(s) traffic so it would not work for the websites in the given scenario. Implementing an additional load-balancing solution would also increase cost and administrative effort.

---

### References

[Application Gateway high traffic support](https://learn.microsoft.com/en-us/azure/application-gateway/high-traffic-support)  

[Configure Azure Application Gateway](https://learn.microsoft.com/en-us/training/modules/load-balancing-https-traffic-azure/3-configure-azure-application-gateway?ns-enrollment-type=learningpath&ns-enrollment-id=learn.wwl.designing-implementing-microsoft-azure-networking-solutions-az-700)  

[What is Azure Load Balancer?](https://learn.microsoft.com/en-us/azure/load-balancer/load-balancer-overview)  

[Load-balancing options](https://learn.microsoft.com/en-us/azure/architecture/guide/technology-choices/load-balancing-overview)  

---

## Q095:

Your organization hosts resources in Azure. In order to load balance and manage web traffic to some new web applications, the company has recently implemented an Azure Application Gateway with the Standard V1 SKU with a single instance count.
The Dev team has asked for Rewrite set to be configured on the Azure Application Gateway. However, when you go to configure this, you receive an error that the current license SKU does not support this configuration.
You need to upgrade the Azure Application Gateway license SKU in order to support the configuration of Rewrite set. You want to minimize costs.

Which Azure Application Gateway SKU should you upgrade to?

Choose the correct answer

- Application Gateway Standard v2 SKU
- Application Gateway WAF v1 SKU
- Application Gateway WAF with DDoS Network Protection v1 SKU
- Application Gateway WAF v2 SKU

---

### Answer:

- Application Gateway Standard v2 SKU

You should upgrade the Azure Application Gateway to the Application Gateway Standard v2 SKU. This is the 2nd tier of SKU that is available within the Azure Application Gateway SKU range, and it supports auto scaling and guarantees high availability. It is also the correct SKU to support the deployment of Rewrite set and Rewrite Policies. The cost formula for this SKU is Fixed Costs Capacity Unit Costs that will give you the Total costs.
You should not upgrade to Application Gateway WAF with DDoS Network Protection v1 SKU. The v1 SKUS do not support Rewrite set or Rewrite policies. Also, there is no requirement for WAF or DDoS Network Protection when configuring Rewrite set, so this would only add additional costs even if v1 SKUs did support Rewrite set.
You should not upgrade to Application Gateway WAF v2 SKU. Although this SKU would support Rewrite set and Rewrite policies, the addition of the WAF feature would increase the cost.
You should not upgrade to Application Gateway WAF v1 SKU. The v1 SKUs do not support Rewrite set. Therefore, this SKU would not be sufficient.

---

### References

[Azure Application Gateway features](https://learn.microsoft.com/en-us/azure/application-gateway/features)  

[Understanding Pricing for Azure Application Gateway and Web Application Firewall](https://learn.microsoft.com/en-us/azure/application-gateway/understanding-pricing)  

[Rewrite URL with Azure Application Gateway - Azure portal](https://learn.microsoft.com/en-us/azure/application-gateway/rewrite-url-portal)  

[Tutorial: Create an application gateway that improves web application access](https://learn.microsoft.com/en-us/azure/application-gateway/tutorial-autoscale-ps)  

[Rewrite HTTP headers and URL with Application Gateway](https://learn.microsoft.com/en-us/azure/application-gateway/rewrite-http-headers-url)  

---

## Q094:

Your company has four hosts named www.companyA.com, www.companyB.com, www.companyC.com, and www.companyD.com.
Your company also has an application gateway named AG1. The four hosts can be accessed through AG1.
The AG1 policies are shown in the following table:


| Policy name | Policy mode | Custom rule priority | Custom rule condition | Custom rule association |
|---|---|---|---|---|
| PAG1 | Prevention | 90 | Deny traffic if IP address contains 192.168.1.0 | HTTPS Listener: LAG3 |
| PAG2 | Detection | 30 | Deny traffic if IP address contains 192.168.1.0 | HTTP Listener: LAG2 |
| PAG3 | Detection | 70 | Allow traffic if IP address contains 192.168.1.0 | HTTP Listener: LAG4 |
| PAG4 | Prevention | 200 | Allow traffic if IP address contains 192.168.1.0 | AG1 |


The listeners of AG1 are shown in the following table:

| Listener name | Listener type | Hostname          | Used protocol | Frontend IP address |
|---------------|---------------|-------------------|---------------|---------------------|
| LAG1          | Basic         | www.companyA.com  | HTTPS         | Public              |
| LAG2          | Multi-site    | www.companyB.com  | HTTP          | Public              |
| LAG3          | Multi-site    | www.companyC.com  | HTTP          | Public              |
| LAG4          | Multi-site    | www.companyD.com  | HTTP          | Public              |

Which host is used in each scenario? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

www.companyA.com
www.companyB.com
www.companyC.com
www.companyD.com

Condition | Hostname
The host that can be accessed from 192.168.1.0 is **www.companyD.com**
The host that has an end-to-end TLS encryption is **www.companyA.com**

---

### Answer:

The www.companyD.com host can be accessed from 192.168.1.0. PAG3 states that traffic can be allowed if the IP address contains 192.168.1.0. LAG4 has www.companyD.com as its hostname. Since PAG3 and LAG4 are associated, then www.companyD.com host can be accessed from 192.168.1.0
The www.companyA.com host cannot be accessed from 192.168.1.0. There is no policy associated with www.companyA.com, thus 192.168.1.0 cannot be accessed from www.companyA.com.
The www.companyB.com host cannot be accessed from 192.168.1.0. LAG2, which has www.companyB.com hostname, is associated with PAG2. PGA2 states that traffic from 192.168.1.0 is denied.
The www.companyC.com host cannot be accessed from 192.168.1.0. LAG3, which has www.companyC.com
hostname, is associated with PAG1. PAG1 states that traffic from 192.168.1.0 is denied.
The www.companyA.com host has an end-to-end Transport Layer Security (TLS) encryption. This host is found within the basic LAG1 listener, which has an Hypertext Transfer Protocol Secure (HTTPS) protocol. HTTPS protocols are used to enable TLS termination or to provide end-to-end TLS encryption.
The www.companyB.com, www.companyC.com, or www.companyD.com hosts do not have an end-to-end TLS encryption. These hosts are associated with listeners that support the HTTP protocol and not the HTTPS protocol.

---

### References

[Application Gateway listener configuration](https://learn.microsoft.com/en-us/azure/application-gateway/configuration-listeners)  

[Application Gateway multiple site hosting](https://learn.microsoft.com/en-us/azure/application-gateway/multiple-site-overview)  

[Tutorial: Create and configure an application gateway to host multiple web sites using the Azure portal](https://learn.microsoft.com/en-us/azure/application-gateway/create-multiple-sites-portal)  

---

## Q093:

![image info](./Q93_1.PNG)

You configured the listener IN_WEB shown in the exhibit under the Application Gateway rule named INCOMING to receive the incoming web requests.
However, the HTTPS requests are failing when users try to access the Application Gateway frontend public IP. The backend pool servers are in a healthy state.
What is the reason for the failure?

Choose the correct answer

- The frontend IP is set to Public..
- The backend targets are not configured.
- The Protocol is set to HTTPS.
- The port number is set to 80.

---

### Answer:

- The port number is set to 80.

The fact that the port number is set to 80 is the main cause of the failing HTTPS requests. 80 is an incorrect port number for the HTTPS. The port number should be set to 443 for the incoming HTTPS requests. With this configuration, the client browser would be sending HTTPS requests to port 443, while the listener would be listening on port 80 for incoming HTTPS requests, which is wrong.
The fact that the protocol is set to HTTPS is not the root cause of the issue. HTTPS is a secure Hypertext Transfer Protocol (HTTP) and uses Transport Layer Security (TLS) protocols to secure the communication between the client and the server.
The fact that the frontend IP is set to Public is not the root cause of the issue. As shown in the exhibit, the frontend IP is set to Public because it is an internet-facing load balancer. You can have three types of Application Gateway Frontend: Public, Private, or Both.
The fact that the Backend targets are not configured is not the root cause of the issue. The question states that the servers are already in a healthy state.

---

### References

[Application gateway components](https://learn.microsoft.com/en-us/azure/application-gateway/application-gateway-components)
[Azure Application Gateway listener configuration](https://learn.microsoft.com/en-us/azure/application-gateway/configuration-listeners)  

---

## Q092:

You are an IT engineer who works for a company that hosts its services in Azure and on-premises. You have deployed a number of applications that are being used by your clients and there have been performance issues since the applications went live. The organization has decided to deploy Azure Traffic Manager, which will help with traffic distribution and improve performance.
The routing method you need to use should meet the following requirements:
There must be a single primary endpoint for all traffic to route to.
There must be multiple backup endpoints in the event of failover.
Traffic should not be routed across different geographical locations.
You need to select the Azure Traffic Manager routing method that meets the requirements.

Which routing method should you use?

Choose the correct answer

- Weighted
- Performance
- Subnet
- Priority

---

### Answer:

- Priority

You should use the priority routing method on Azure Traffic Manager to ensure that you meet the routing requirements that have been set by the company. This type of routing allows you to configure a primary service endpoint for all traffic to route to as well as multiple backup endpoints for failover. It does not route to endpoints in other regions and therefore it meets all the routing requirements set by the company.
You should not use the subnet routing method on Azure Traffic Manager as it does not meet the routing requirements set by the company. This type of routing allows you to map sets of user IP address ranges to a single specific endpoint. It will return the request's source IP address mapped to the endpoint.
You should not use the performance routing method on Azure Traffic Manager as it does not meet the routing requirements set by the company. This type of routing should be used when you have endpoints in different physical locations so that the geographically closest endpoint is used to give low latency.
You should not use the weighted routing method on Azure Traffic Manager. This type of routing allows you to distribute the traffic across multiple endpoints depending on the weight you have set. You need to set the same weight on each endpoint to distribute it evenly.

---

### References

[https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-routing-methods](https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-routing-methods)   

[What is Traffic Manager?](https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-overview)  

[Traffic Manager Frequently Asked Questions (FAQ)](https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-faqs)

---

## Q091:

![image info](./Q91_1.PNG)

You are a solutions architect for an organization that hosts its infrastructure in a hybrid model, both on- premises and in Azure. You have two virtual networks (VNets) that host virtual machines and web applications as shown in the exhibit. Recent performance issues have been reported by users and your manager has asked you to implement Azure Load Balancer to distribute traffic with the following requirements:

- WebAppD must be able to distribute extra traffic load to resources that are hosted on-premises and uses non-HTTP/HTTPS protocols.

- WebAppC must be able to distribute traffic to VMA and VMB and uses the non-HTTP/HTTPS protocols.

- WebAppA and WebAppB both need to distribute traffic to on-premises resources and use non- HTTP/HTTPS protocols.

- WebAppA and WebAppB both need to distribute traffic to VMA and VMB.

You need to identify whether Azure Load Balancer is the appropriate choice to meet the above requirements. For each of the following statements, select Yes if the statement is true. Otherwise, select No.


Azure Load Balancer can support both HTTP and HTTPS traffic.
No

Azure Load Balancer Regional load balancing should be configured to distribute traffic from WebAppC to VMA and VMB.
No

Azure Load Balancer Global load balancing should be configured to distribute supported traffic for WebAppA and WebAppB.
Yes

---

### Answer:

Azure Load Balancer cannot support HTTP and HTTPS traffic. Azure has four different load balancing services: Azure Front Door and Azure Application Gateway (both of which support HTTP/HTTPS traffic), Azure Traffic Manager (which supports non-HTTP/HTTPS traffic), and Azure Load Balancer (which only supports TCP/UDP traffic).

Azure Load Balancer Regional load balancing should not be configured to distribute traffic for WebAppC to VMA and VMB because it requires you to distribute traffic to a different region - East US to UK South -, which is not supported with regional load balancers. This is only supported with global load balancers. WebAppC supports non-HTTP/HTTPS traffic and therefore is supported by Azure Load Balancers.
Azure Load Balancer Global load balancing should be configured to distribute non-HTTPS traffic for WebAppA and WebAppB.

In the exhibit you can see the resources are split between the UK South and East US regions. This means that any load balancing scenario for non-HTTP/HTTPS traffic will require a Global load balancer as the regional load balancer cannot distribute traffic outside a single region. You also have an on-premises location to which you need to distribute traffic, which is also not supported with regional load balancers. There are two ways in which you can configure Azure load balancers for traffic distribution: Global or Regional.

- Global load-balancing is a service that will allow you to distribute traffic to both on-premises, other cloud services, and across the Azure regional back ends. It also offers a reactive feature that monitors service reliability and performance to maximize the availability of the applications.

- Regional load-balancing is a service that will allow you to distribute traffic in virtual networks (VNets) across virtual machines (VMs) within your region. This is a load-balancer between VMs, containers, or clusters that reside within a region in a VNet.

---

### References

[Load-balancing options](https://learn.microsoft.com/en-us/azure/architecture/guide/technology-choices/load-balancing-overview)  

[Cross-region (Global) Load Balancer](https://learn.microsoft.com/en-us/azure/load-balancer/cross-region-overview)  

---

## Q090:

You are a network specialist for an organization that is in the process of migrating web applications from its on-premises infrastructure into Azure. Before the migration your manager realizes that the original project engineer has configured the Azure Traffic Manager profile but not the endpoints.

He has asked you to implement an emergency change and add the missing endpoints to the existing Azure Traffic Manager profile. The endpoints should meet the following requirements:

- Support IPv4 addresses, IPv6 addresses, and Fully Qualified Domain Names (FQDN).
- Support traffic outside Azure.
- Support low latency and better redundancy than the existing on-premises endpoint.

You need to update the existing Azure Traffic Manager profile with two endpoints using PowerShell.
Which cmdlets should you use? To answer, select the appropriate commands from the drop-down menus.

Choose the correct options

OPTIONS-1: New-AzTrafficManagerEndpoint | Add-AzTrafficManagerEndpointConfig | Set-AzTrafficManagerProfile
OPTIONS-2: ExternalEndpoints | NestedEndpoints | AzureEndpoints

```
OPTIONS-1 -Name euA-endpoint `
-ProfileName EuAProfile `
-ResourceGroupName EURG01 `
-EndpointStatus Enabled `
-Type OPTIONS-2 `
-Target app-eu.iamanitgeek.com
```


```
New-AzTrafficManagerEndpoint -Name euA-endpoint `
-ProfileName EuAProfile `
-ResourceGroupName EURG01 `
-EndpointStatus Enabled `
-Type ExternalEndpoints `
-Target app-eu.iamanitgeek.com
```

---

### Answer:

You should complete the PowerShell cmdlets as follows:
New-AzTrafficManagerEndpoint -Name euA-endpoint ProfileName EuAProfile ResourceGroupName EURG01 -Type ExternalEndpoints -Target app-eu.iamanitgeek.com EndpointStatus Enabled
As you need to create a new Azure traffic Manager endpoint, you should use the New- Az Traffic Manager Endpoint cmdlet to start with. You specify the endpoint name, profile name and the Resource Group name before specifying the endpoint type which is an External Endpoint in this scenario.
There are three types of Azure Traffic Manager endpoints you can choose from. The external endpoint meets the requirements in this scenario. The other two possible options are Azure endpoints, which are used for Azure-based services, and nested endpoints, which allow you to use multiple traffic profiles at once.
You should not use the Set-AzTraffic ManagerProfile cmdlet as this updates the Traffic Manager profile once you have set all the parameters and values when creating a new Traffic Manager profile from the start. In this scenario, you are adding a new endpoint to an existing profile.
You should not use the Add-AzTraffic Manager EndpointConfig cmdlet as this adds an endpoint to a local Traffic Manager profile object. In this scenario you need to create a new endpoint.

---

### References

[Using PowerShell to manage Traffic Manager](https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-powershell-arm)  

[Traffic Manager endpoints](https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-endpoint-types)  

[New-AzTrafficManagerEndpoint](https://learn.microsoft.com/en-us/powershell/module/az.trafficmanager/new-aztrafficmanagerendpoint?view=azps-12.1.0&viewFallbackFrom=azps-10.2.0)  

[Add-AzTrafficManagerEndpointConfig](https://learn.microsoft.com/en-us/powershell/module/az.trafficmanager/add-aztrafficmanagerendpointconfig?view=azps-12.1.0&viewFallbackFrom=azps-10.2.0)  

[Set-AzTraffic ManagerProfile](https://learn.microsoft.com/en-us/powershell/module/az.trafficmanager/set-aztrafficmanagerprofile?view=azps-12.1.0&viewFallbackFrom=azps-10.2.0)  

---

## Q089:

Your company hosts its infrastructure within a third-party data center. The lease on your agreement is running out and your company has decided to migrate all workloads to the cloud with you as the head architect.
There will be multiple services routing both inbound and outbound from the proposed Azure environment. In your design, you need to document a native load-balancing service that deals with DNS-based traffic load balancing at the domain level and controls how traffic is distributed to different endpoints.
Which Azure native load-balancing service should you include in your design?

Choose the correct answer

- Azure Load Balancer
- Azure Application Gateway
- Azure Traffic Manager
- Azure Front Door

---

### Answer:

- Azure Traffic Manager

You should include an Azure Traffic Manager load-balancer in your design. This is a DNS--based traffic load-balancer that routes traffic globally to services in all Azure regions. It is highly available with built-in redundancy and will give you high response times. Although it offers failover, due to the nature of DNS- based load-balancing having many challenges it does not fail-over as fast as, for example, Azure Front Door. Azure Traffic Manager enables you to route traffic from your applications globally to all regions from any location.
You should not include an Azure Front Door load-balancer in your design. This service provides global load-balancing and offers Layer 7 services like fast failover and SSL offload. In this scenario, you need DNS- based load balancing, which Azure Front Door does not support; it supports HTTP(s) load balancing.
You should not include Azure Load Balancer in your design. This is another native load-balancing service, which enables low-latency, Layer 4 load-balancing service both inbound and outbound. It supports both the UDP and TCP protocols, is highly available and offers zone redundancy in the service. However, it does not offer DNS load-balancing as is a requirement in this scenario, and therefore it is not the correct option.
You should not use the Azure Application Gateway load-balancing service in your design. This native service is another Layer 7 load-balancing service, which includes features for optimizing webs farm productivity. Its main service is to provide an application delivery controller service for Azure to its consumers. However, it does not offer the DNS load-balancing as is a requirement in the scenario.

---

### References

[Load-balancing options](https://learn.microsoft.com/en-us/azure/architecture/guide/technology-choices/load-balancing-overview)  

[Traffic Manager endpoints](https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-endpoint-types)  

[Quickstart: Create a Traffic Manager profile using the Azure portal](https://learn.microsoft.com/en-us/azure/traffic-manager/quickstart-create-traffic-manager-profile)  

What is Azure Front Door?
What is Azure Application Gateway?
What is Azure Load Balancer?

---

## Q088:

Your company hosts its infrastructure in both Azure and its private data center. You host multiple web applications that are hosted both in Azure and on-premises and an Azure Traffic Manager service that enables you to manage network traffic distributions for all application deployments across the environment.

The dev team has recently configured three new web applications that have the following details and requirements in the Table:

You need to identify the endpoint type to be used for each web app.
Which endpoint types should you identify?

> Table

| Web Application Name | Hosting Location |Requirements|
|----------------------|--|----------------------------------------------------------------|
| WebAppA             | On-premises      | • Active/Active redundancy.<br> • Low application latency.<br>                                            |
| WebAppB             | Azure           | • Needs to direct traffic to the region closest to the user. <br> • Needs to direct a small amount of traffic to another deployment to test updates.<br>                                                |
| WebAppC             | Azure           | • Will not be used all the time. <br> • Should not incur cost when the endpoint is stopped.    |

OPTIONS: Azure endpoint | External endpoint | Nested endpoint | Web App endpoint

---

### Answer:

WebAppA : External endpoint
WebAppB : Nested endpoint
WebAppC : Azure endpoint

The three new web apps should be configured with the following Azure Traffic Manager endpoint types:

- WebAppA will require the external endpoint type.
- WebAppB will require the nested endpoint type.
- WebAppC will require the Azure endpoint type.

Azure Traffic Manager external endpoints are used for services that are hosted outside of Azure, including other cloud hosting or, as in this case, on-premises. External endpoints also provide increased redundancy in an Active/Active failover model and reduced application latency, which are the two main requirements.
Azure Traffic Manager nested endpoints allow you to use multiple traffic routing methods in a single Traffic Manager profile. WebAppB needs to use both performance and weighted traffic routing, which nested endpoints can support.
Azure Traffic Manager Azure endpoints are used for Azure-based services in Traffic Manager. It will detect when the web app has been stopped and started but it does not perform any health checks. Billing for traffic will not occur when the web app is stopped and will only resume when it has started so you do not get charged for the period it was in a stopped state.
Azure Traffic Manager Web App endpoints are not going to be used for any of the new web apps. You can only use this type of endpoint for web apps at the Standard SKU level when integrating them with Azure Traffic Manager. You can only have a single Web App endpoint in each Traffic Manager profile from each Azure region.

---

### References

[Tutorial: Configure priority traffic routing method in Traffic Manager](https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-configure-priority-routing-method)  

[Quickstart: Create a Traffic Manager profile using the Azure portal](https://learn.microsoft.com/en-us/azure/traffic-manager/quickstart-create-traffic-manager-profile)  

[Nested Traffic Manager profiles](https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-nested-profiles)  

[Traffic Manager endpoints](https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-endpoint-types) 

[Add, disable, enable, or delete endpoints](https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-manage-endpoints)  

---

## Q087:


Your company hosts its infrastructure across multiple Azure subscriptions. Your company wants to implement Public Load balancers in its two subscriptions in order to forward traffic on specific ports to virtual machines within your tenancy, as shown in the two exhibits.
The two tables below show the inbound port routing requirements. Table 1 is for Subscription-A (Sub-A) and Table 2 is for Subscription-B (Sub-B):

> Table 1

| Inbound Port | NAT translation | VM Name |
|---|---|---|
| 701 | 443 | VM-A |
| 702 | 443 | VM-B |
| 703 | 443 | VM-C |
| 704 | 443 | VM-C |

> Table 2

| Inbound Port | NAT Translation | VM Name |
|---|---|---|
| 801 | 443 | VM-E |
| 802 | 443 | VM-F |
| 803 | 443 | VM-G |

You need to decide which type of NAT rule to use in both Sub-A and Sub-B.
For each of the following statements, select Yes if the statement is true. Otherwise, select No.

Sub-A is a candidate for a multiple VM inbound NAT rule.
Yes

Sub-B is a candidate for a multiple VM inbound NAT rule.
No

Both Sub-A and Sub-B are candidates for a single VM inbound NAT rule.
No

---

### Answer:

Sub-A is a candidate for a multiple VM inbound NAT rule, as it has a single inbound NAT that is port translating to multiple virtual machines. In the given scenario, it is translating ports according to the first table in the scenario. In multiple VM Inbound NAT rule scenarios, you configure a back-end pool with a port rang to allow the inbound NAT to translate multiple different ports to different virtual machines.
Sub-B is not a candidate for a multiple VM inbound NAT rule. Sub-B is only a candidate for a single VM inbound NAT rule, as it has multiple inbound NATs that are port translating to a single virtual machine each. In the given scenario, it is translating ports according to the second table in the scenario. In single VM inbound NAT rule scenarios, you configure a front-end port and a back-end port for each inbound NAT.
Both Sub-A and Sub-B are not candidates for a single VM inbound NAT rule. Only Sub-B is a candidate for a single VM inbound NAT rule as it has individual inbound NATs translating to individual VMs. Sub-A is not a candidate for single VM inbound NAT rule as it has a single inbound NAT that is port translating to multiple virtual machines, so it needs multiple VM inbound NAT rules.

---

### References

[Manage inbound NAT rules for Azure Load Balancer](https://learn.microsoft.com/en-us/azure/load-balancer/manage-inbound-nat-rules?tabs=inbound-nat-rule-portal)

[Inbound NAT rules](https://learn.microsoft.com/en-us/azure/load-balancer/inbound-nat-rules)  

---

## Q086:

You have configured an Azure Traffic Manager profile and two web app endpoints. The web apps are located in UK South and East US.
You need to ensure that users connect to the endpoints as quickly as possible with the lowest network latency.
Which routing method should you configure?

Choose the correct answer

- Priority
- Performance
- Subnet
- Geographic

---

### Answer:

- Performance

You should configure the Performance routing method. When you configure Azure Traffic Manager, a routing method must be selected. Choosing a performance-based routing method will ensure users get connected to the appropriate endpoint with the lowest network latency.
You should not configure the Geographic routing method. With the geographic option, an Azure administrator can analyze where the original DNS request was made from and then route traffic to the appropriate endpoint. This can assist organizations with strict data sovereignty requirements.
You should not configure the Subnet routing method. This method can be used to analyze IP ranges the traffic is originating from and then redirect traffic to the most appropriate endpoint. For example, all users from a particular branch office can be routed to the endpoint in South UK if required.
You should not configure the Priority routing method. A priority number can be assigned to each endpoint (for example, 1,2,3). The endpoint with an assigned priority number of 1 will receive all the traffic. In the event where the primary endpoint is down, the secondary endpoint can be configured with a priority number of 2. Priority routing can be useful if you may have a critical web app running across three virtual machines. In this scenario you only have one virtual machine that is sized appropriately; the other two virtual machines have lower CPU and RAM due to budgeting cuts. In this case, you would want all traffic to be routed based on priority to the first virtual machine with adequate CPU and RAM. In the event of a failure, it may be acceptable to the business to operate on the other two virtual machines until the issue is resolved.

---

### References

[Traffic Manager routing methods](https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-routing-methods)

---

## Q085:

Your organization has one Azure subscription with a hub and spoke network topology configured. A new application has been deployed to one of the spoke networks, which includes six virtual machines across two availability zones.
You need to configure a load-balancing solution that evenly distributes traffic from the internet across the six virtual machines.
Which two steps should you take? Each correct answer presents part of the solution.

Choose the correct answers

- Create a basic load balancer.
- Set the load balancer type to internal.
- Set the load balancer type to public.
- Create a standard load balancer.

---

### Answer:

- Set the load balancer type to public.
- Create a standard load balancer.


To successfully load balance traffic to the six virtual machines, you should create a standard load balancer and set the load balancer type to public. Azure load balancer comes in two Stock Keeping Units (SKUs): Basic and Standard. The standard load balancer supports zone-redundant traffic. In Azure, selected regions (data centers) have three availability zones. Availability zones are physical separate locations that increase the availability of certain Azure services. In the context of Azure load balancers, a single frontend IP address will still be available even if a zone were to fail. For instance, in UK South, if zone 2 were to fail, then the load balancer would still be available. The question states that the virtual machines have been placed across two availability zones, which addresses this requirement. If ingress traffic originates from the internet, then a public load balancer is required. Basic load balancers do not support availability zones whereas standard ones do. Basic load balancers come with a number of limitations and they are better suited for dev or test environments. For instance, basic load balancers only support Network Interface Card (NIC) based backend pools, whereas standard support both NIC and IP based.
You should not create a basic load balancer. A basic load balancer is recommended for test workloads only. Furthermore, the basic SKU does not support availability zones.
You should not set the load balancer type to internal. Internal load balancers are also referred to as private load balancers. Private load balancers are used when traffic is being routed from private IP addresses only. The requirement states that external traffic is involved and, therefore, this is the incorrect choice.

---

### References

[Azure Load Balancer SKUs](https://learn.microsoft.com/en-us/azure/load-balancer/skus)
What is Azure Load Balancer?
Load Balancer and Availability Zones

---

## Q084:



You work at a company that has an Azure subscription. The company uses Azure Traffic Manager to control network traffic.
The profiles used within Azure Traffic Manager are shown in the table below:

| Name | Routing Method |
|---|---|
| ATMProfileA | Weighted |
| ATMProfileB | Performance |
| ATMProfileC | Geographic |
| ATMProfileD | Subnet |
| ATMProfileE | MultiValue |

Your company has Azure endpoints, external endpoints, and nested endpoints. Your company uses services inside and outside your Azure subscription.

One of the external services uses the ATMProfileE profile.
You need to load balance the traffic for the service that uses the ATMProfileE profile.
For each of the following statements, select Yes if the statement is true. Otherwise, select No.

Use the external endpoints.
Yes

Use the Azure endpoints.
No

Create a private DNS zone.
No

---

### Answer:

You should use external endpoints to load balance the traffic for the service that uses the ATMProfileE profile. These types of endpoints are used to load balance traffic for services and IPv4/IPv6 addresses outside your Azure subscription. Since the mentioned service uses the ATMProfileE profile, which has the MultiValue routing method which is used for only IPv4/IPv6 addresses, this means that you should use external endpoints to load balance the mentioned service.
You should not use the Azure endpoints. Azure Traffic Manager supports the Azure endpoints type which is used to load balance traffic for public IP addresses and web applications located within the Azure subscription, which contradicts the fact that the service is outside the Azure subscription.
You should not create a private DNS zone. Private Domain Name System (DNS) zones are used to manage your company's domains within your Azure Virtual Network but cannot be used to load balance traffic as required in the scenario.

---

### References

[Traffic Manager endpoints](https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-endpoint-types)  

[Quickstart: Create an Azure private DNS zone using the Azure portal](https://learn.microsoft.com/en-us/azure/dns/private-dns-getstarted-portal)


[What is Azure Private DNS?](https://learn.microsoft.com/en-us/azure/dns/private-dns-overview)  

---

## Q083:

Your company has an Azure virtual network (VNet).
You want to create an internal load balancer.
You need to create virtual machines for the backend pool of your internal load balancer.
How should you complete the Azure PowerShell script? To answer, drag the appropriate cmdlet to each blank. A cmdlet may be used once, more than once, or not at all.
Drag and drop the answers

New-AzVM
New-AzVMConfig
Get-Credential

```
}

$vmimage = @{
    PublisherName = 'MSW'
    Offer = 'WS'
    Skus = '2021-Datacenter'
    Version 'latest'
}

$vmConfig = New-AzVMConfig @vmsz `
| Set-AzVMOperatingSystem @vmos -Linux `
| Set-AzVMSourceImage @vmimage `
| Add-AzVMNetworkInterface Id $nicVM.Id

$vm = @ {
    ResourceGroupName = 'MSRG1'
    Location = 'northus'
    VM = $vmConfig
    Zone "$i"
}

New-AzVM @vm -AsJob

}
```

```
}

$vmimage = @{
    PublisherName = 'MSW'
    Offer = 'WS'
    Skus = '2021-Datacenter'
    Version 'latest'
}

$vmConfig = OPTIONS @vmsz `
| Set-AzVMOperatingSystem @vmos -Linux `
| Set-AzVMSourceImage @vmimage `
| Add-AzVMNetworkInterface Id $nicVM.Id

$vm = @ {
    ResourceGroupName = 'MSRG1'
    Location = 'northus'
    VM = $vmConfig
    Zone "$i"
}

OPTIONS @vm -AsJob

}
```

---

### Answer:

You should complete the PowerShell script as follows:

```
}
$vmimage
PublisherName = 'MSW'
Offer = 'WS'
Skus 2021-Datacenter'
Version 'latest'
}
$vmConfig = New-AzVMConfig @vmsz
| Set-AzVMOperatingSystem @vmos -Linux
| Set-AzVMSourceImage @vmimage
| Add-AzVMNetworkInterface Id SnicVM.Id
$vm = @{
ResourceGroupName = 'MSRG1'
Location = 'northus'
VM $vmConfig
Zone = "$i"
}
New-AzVM @vm -AsJob
}
```

You should use the $vmConfig = New-AzVMConfig @vmsz cmdlet. This configures a Virtual Machine (VM) object for Azure. This is a required expression for the script's logic since the load balancer is created for virtual machines so that it can balance the traffic load between them, so with no configured VMs, there would be no benefit of the load balancer. When creating a load balancer for a virtual machine, a resource group for the load balancer should be created along with the configuration of virtual machines and the installation of Internet Information Services (IIS). The Set-AzVMOperating System cmdlet defines the operating system the VM will use. The Set-AzVMSourcelmage cmdlet defines the source image to be used. The Add-AzVMNetworkInterface cmdlet is used to add a network interface to the VM.
You should use the New-AzVM @vm-AsJob cmdlet. This expression enables you to create the VMs you want in Azure so that you can load balance them. This is a required expression to use after finishing the VMs configuration as shown in the PowerShell script.
You should not use the Get-Credential cmdlet in this PowerShell script. This expression is used to get the username and password of an object. This expression enables you to define the administrator and password of the VMs. This is used as the first expression of the Azure PowerShell script used to create VMs.
---

### References

[New-AzVM](https://learn.microsoft.com/en-us/powershell/module/az.compute/new-azvm?view=azps-12.1.0&viewFallbackFrom=azps-6.6.0)  

New-AzVMConfig

[Get-Credential](https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.security/get-credential?view=powershell-7.2)  

---

## Q082:

You configured an Azure Load Balancer named CompanyA-LB. The load balancer is configured with two Public Frontend IPs.
There are three virtual machines (VMs) running in the backend pool named CompanyA-pool.

| Virtual Machine | Backend pool |
|---|---|
| VM-1 | CompanyA-pool |
| VM-2 | CompanyA-pool |
| VM-3 | CompanyA-pool |

VM-3 is also a configuration backup server. You need to configure SSH access only to the virtual machine VM-3 in order to retrieve the configuration backup, but you want to make sure no incoming SSH requests are forwarded to the virtual machines VM-1 or VM-2.
Which of the following solutions should you use?

Choose the correct answer

- Configure a load balancing rule with port and backend port set to 22, and backend pool to CompanyA-pool.
- Configure an outbound NAT rule with outbound port set to 22.
- Configure an inbound NAT rule with service type set to SSH, port number set to 22, and target virtual machine VM-3.
- Configure an inbound NAT rule with service type set to HTTPS, port number set to 22, and target virtual machine VM-3.


---

### Answer:

- Configure an inbound NAT rule with service type set to SSH, port number set to 22, and target virtual machine VM-3.

You should configure an inbound Network Address Translation (NAT) rule with service type set to Secure Shell (SSH), port number set to 22, and target virtual machine VM-3. With this configuration, any incoming SSH request will always get forwarded to the backend virtual machine VM-3.
You should not configure an inbound NAT rule with service type set to Hypertext Transport Protocol Secure (HTTPS), port number set to 22, and target virtual machine VM-3. The scenario is asking for an SSH access solution, which uses port number 22. It is not asking for HTTPS access. Moreover, HTTPS does not use port 22; it always uses port 443.
You should not configure a load balancing rule with port and backend port set to 22, and backend pool to CompanyA-pool. This rule will allow incoming SSH requests to all of the VMs.
You should not configure an outbound NAT rule with outbound port set to 22. The outbound rule is applied for a backend pool and is used for outgoing requests.

---

### References

[Load Balancer frequently asked questions](https://learn.microsoft.com/en-us/azure/load-balancer/load-balancer-faqs)  

[Azure Load Balancer portal settings](https://learn.microsoft.com/en-us/azure/load-balancer/manage)  

[Azure Load Balancer components](https://learn.microsoft.com/en-us/azure/load-balancer/components)  

---

## Q081:

![image info](./Q81_1.PNG)

You configured the Basic SKU Load Balancer topology shown in the exhibit for a Kubernetes-based solution.
You plan to configure health probes towards the internal virtual machines, so that the load balancer can detect a failed backend server in a timely manner and stop sending the incoming traffic towards the failed server.
Which protocol should you configure for the health probes?

Choose the correct answer

- TCP or HTTP
- TCP or HTTPS
- HTTP and UDP
- TCP and UDP

---

### Answer:

- TCP or HTTP

You should use the Transmission Control Protocol (TCP) or the Hypertext Transfer Protocol (HTTP) to configure the health probes towards the internal virtual machines. The Basic SKU Load Balancer only supports these two protocols. The TCP health probing uses the 3-way TCP handshake (SYN, SYN-ACK, ACK messages) to learn if the virtual machine instance is up and running. In case of no response or a TCP reset message from the instance for the configured time-out count, the health probe is considered as failed. The HTTP probing mechanism uses HTTP GET requests. During the health probe, if an HTTP response code other than 200 (for example, 403, 404, or 500) is received, this will mark down the health probe. In case of no response to the HTTP GET requests or in case of a TCP reset message from the virtual machine, the health probe will be considered as failed.
You should not identify HTTP and Use Datagram Protocol (UDP). You cannot use both of these protocols together for a health probe. Also, UDP is not a supported protocol for health probes. The only supported protocols for health probes are TCP, HTTP and Hypertext Transfer Protocol Secure (HTTPS). The HTTPS probes are only with Standard SKU.
You should not identify TCP and UDP. You cannot use both of these protocols together for a health probe. Also, UDP is not a supported protocol for health probes. The only supported protocols for health probing are TCP, HTTP and HTTPS. The HTTPS probes are only with Standard SKU.
You should not identify TCP or HTTPS. In order to use TCP or HTTPS for health probes, you need to have a Standard SKU Load Balancer. The Basic SKU Load Balancer only supports TCP and HTTP.
---

### References

[Azure Load Balancer health probes](https://learn.microsoft.com/en-us/azure/load-balancer/load-balancer-custom-probe-overview)  

---

## Q080:

![image info](./Q80_1.PNG)

You have the Traffic Manager profile configured on Azure as shown in the exhibit.
In case of server failure, Traffic Manager will intelligently distribute the incoming traffic.
To answer, complete the statements by selecting the correct option from the drop-down menus.

Choose the correct options

OPTIONS:
East US 2 | sOUTHeAST aSIA | Test Application Sever

1. In the child nested profile, the Production server fails in the East US region. The Traffic Manager will route all East US traffic to **East US 2**

2. You set MinChildEndpoints for the nested child profile to 1. In case the Production Server fails, the Traffic Manager will route all East US traffic to **Test Application Server**

---

### Answer:

All traffic will be routed to East US 2 if the Production server fails in the East US nested child profile. The reason for this is that the child profile is configured with the option MinChildEndpoints = 2. This means that the profile will ensure that a minimum of two servers are available. If there are fewer than two available servers in the child profile, the traffic will route to the alternate feasible regions. In this case, East US 2 region deployment will be more performant than Southeast Asia.
If MinChildEndpoints for the nested child profile is set to 1 and the Production server fails, Traffic Manager will route all East US traffic to the Test Application Server. In this scenario, the condition is set to one server under the MinChildEndpoints option. If only one server is available, the Traffic Manager routing logic will
continue sending the request to the child profile. Even if the weighted routing is set, The Test Application
Server will receive 100% of the traffic.
If both the East US and East US 2 regions are not available, all traffic would be routed to the servers available in the Southeast Asia region. This situation can result in some latency in processing the incoming client request from remote locations; for example, for users in East US and East US 2. All this routing is configurable in Azure Front Door. Therefore, the organization needs to define it as per the traffic requirements.

---

### References

[Nested Traffic Manager profiles](https://learn.microsoft.com/en-us/azure/traffic-manager/traffic-manager-nested-profiles)  

---

## Q079:

You plan to configure an e-commerce application on Azure. It is a distributed application that will be hosted on multiple backend Azure virtual machines (VMS).
One of the design requirements is to route the traffic to internal servers based on the incoming URL path.
You need to configure an intelligent load-balancing solution.
Which solution should you use to meet this requirement?

Choose the correct answer

- Azure Load Balancer
- Azure Traffic Manager
- Azure Application Gateway
- Azure NAT Gateway

---

### Answer:
- Azure Application Gateway

You should use Azure Application Gateway to meet the requirement. Azure Application Gateway is a layer 7 load balancer that operates at the application layer of the Open Systems Interconnection (OSI) model. Azure Application Gateway can use the incoming request Uniform Resource Locator (URL) or Hypertext Transfer Protocol (HTTP) headers to make intelligent routing decisions and can segregate the traffic across the internal virtual resources.
You should not use Azure Load Balancer. Azure Load Balancer operates at layer 4 of the OSI model, which is the transport layer. It cannot distribute and load balance the incoming requests on the basis of the URL or HTTP headers of the requests.
You should not use Azure NAT Gateway. Azure NAT Gateway provides Network Address Translation (NAT) solution to Azure virtual resources by translating the internal private IP addresses into public IP addresses.
You should not use Azure Traffic Manager. Azure Traffic Manager is a Domain Name System (DNS) based load-balancing solution that helps with traffic routing to Azure virtual machines and even external networks. It is a global service and provides a health check mechanism to ensure the high availability of the service.
---

### References


What is Azure Application Gateway?
Azure NAT Gateway resource
What is Azure Load Balancer?
What is Traffic Manager?

---

## Q078:


![image info](./Q78_1.PNG)

You plan to host your company's mission-critical web application on Azure. To efficiently handle the incoming traffic, you decide to configure Azure Load Balancer to distribute the traffic towards the internal Azure virtual machines (VMs).
The Azure Load Balancer is assigned a public IP address, whereas the internal VMs do not have any public IP address allocations.
All the VMs are configured inside the same Virtual Machine Scale Set (VMSS), as shown in the exhibit. You are exploring multiple possible traffic distribution scenarios:

1. Enabling the session affinity for the incoming web traffic so that the incoming connection from a particular source IP always goes to the same VM for the subsequent requests.

2. Configuring the Hash-based load distribution.

3. Performing a one-to-one mapping between the incoming source IPs and the backend load balancing servers.
To answer, complete each statement by selecting the correct option based on the information presented in the graphic from the drop-down menus.

Choose the correct options

OPTIONS: 
Client IP | None | Client IP & Protocol
default | SourceIP | SourceIPProtocol
Inbound NAT Rules | Outbound  NAT Rules

1. You should set the session persistence to **Client IP** under the load- balancing rules in order to enable session affinity for the incoming source IP.

2. To configure the Hash based load distribution mode under the Azure Load Balancer, you should configure the following:

```
$lb = Get-AzLoadBalancer -Name MyLoadBalancer -ResourceGroupName MyResourceGroupLB
$lb.LoadBalancingRules[0].LoadDistribution = `OPTIONS`
Set-AzLoadBalancer -LoadBalancer $lb
```

```
$lb = Get-AzLoadBalancer -Name MyLoadBalancer -ResourceGroupName MyResourceGroupLB
$lb.LoadBalancingRules[0].LoadDistribution = `default`
Set-AzLoadBalancer -LoadBalancer $lb
```

3. To route traffic to a specific backend virtual machine in an Azure Load Balancer, you should use **Inbound NAT rules**

---

### Answer:

You should set the session persistence to Client IP in the load-balancing rules in order to enable session affinity for the incoming source IP. By setting this option, the load balancer will keep track of the sessions and will ensure that it always routes the successive requests from the source IP address to the same internal VM.

You should use the default mode to configure the Hash-based load distribution mode under the Azure load balancer:

```
$lb.LoadBalancingRules [0].LoadDistribution = 'default'
```

In the hash-based load distribution mode, the incoming requests can go to any internal VM.

You should use the inbound NAT rules to route traffic to a specific backend VM from the Azure load balancer. Requests received on any port where an inbound NAT rule is defined will send the traffic to the specific VM. For example, for Remote Desktop Protocol (RDP) connection, you can create an inbound NAT rule that maps port 33389 to the VM port 3389.

---

### References


[Configure the distribution mode for Azure Load Balancer](https://learn.microsoft.com/en-us/azure/load-balancer/load-balancer-distribution-mode?tabs=azure-portal)  

[Azure Load Balancer distribution modes](https://learn.microsoft.com/en-us/azure/load-balancer/distribution-mode-concepts)  

[Tutorial: Create a single virtual machine inbound NAT rule using the Azure portal](https://learn.microsoft.com/en-us/azure/load-balancer/tutorial-load-balancer-port-forwarding-portal)  

[Manage rules for Azure Load Balancer using the Azure portal](https://learn.microsoft.com/en-us/azure/load-balancer/manage-rules-how-to)  

---

## Q077:

Your organization has on-premises locations that are spread across the globe, including the UK, France, Italy, and North America. You have designed an Azure tenant that follows the Cloud Adoption Framework with a Hub & Spoke network topology with a hub in each Azure region connected to the respective offices.
You need to design the Virtual WAN in Azure so each subscription in the offices is connected to each other.
What Virtual WAN resource should you include in the design?

Choose the correct answer

- Hub route table
- Hub-to-hub connection
- Hub
- Virtual WAN

---

### Answer:

- Hub-to-hub connection

You should include the hub-to-hub connection resource in your Azure Virtual WAN design to facilitate connectivity between the offices. Hub-to-hub connections allow you to connect hubs to each other in a virtual WAN. This resource fulfills the requirement of each branch office being connected to each other.
You should not include the Hub resource in your Azure Virtual WAN design to facilitate connectivity between the offices. Although the Hub resources is required within a Virtual WAN deployment, it is a Microsoft Managed virtual network. It contains different service endpoints that enable connectivity, however
the specific resource that facilitates the connections between the branch offices is the hub-to-hub
connection.
You should not include the Virtual WAN resource in your Azure Virtual WAN design to facilitate connectivity between the offices. Although the Virtual WAN is required within the design and implementation, this specific resource represents a virtual overlay of the Azure network in your tenant and is a collection of multiple services which includes the links to all the virtual hubs.
You should not include the Hub route table resource in your Azure Virtual WAN design to facilitate connectivity between the offices. Although you can add the hub route table into your design and implementation, it is required to apply different routes in your virtual hub. The route table cannot be used to facilitate connectivity between the branch office hubs.

---

### References

[Virtual WAN partners, regions, and virtual hub locations](https://learn.microsoft.com/en-us/azure/virtual-wan/virtual-wan-locations-partners)  

About NVAs in a Virtual WAN hub

---

## Q076:

Your organization has offices all around the world including the UK, France, and Italy, The company has decided to host all its resources in Azure and have connected the physical offices with the following Azure Regions via Express Route connectivity:

| Office Location | Azure Region |
|---|---|
| UK | UK South |
| France | France Central |
| Italy | Italy North |

The company currently has Barracuda Firewalls in each physical office and wants to deploy the same in Azure in a Virtual WAN. You recommend deploying Network Virtual Appliances (NVAs) to facilitate the Barracuda Firewalls in Azure.
You have obtained the relevant licenses and are tasked with deploying the NVAs in each Azure region shown in the table. You create the Virtual WAN, and subscribe to the service in the CloudGen WAN Service in the Azure Marketplace. When you try to create the NVAs, you are unable to deploy them to the Virtual WAN you created earlier, and realized you have missed a deployment step.
You need to troubleshoot the issue.

What should you do?

Choose the correct answer

- Create a Virtual WAN Hub.
- Configure network peering between the Azure regions.
- Connect the Virtual network to the Hub..
- Deploy Virtual Machines.


---

### Answer:

- Create a Virtual WAN Hub.

You should create a Virtual WAN hub before you can create the NVAs as you deploy the NVAs into the virtual WAN hub, not the virtual WAN itself. A virtual hub is a Microsoft managed virtual networking service that can contain different service endpoints that will allow connectivity. This is the center of virtual networks In any given region and you can have multiple hubs in a region.
You should not deploy Virtual Machines within the Virtual WAN or Hub networks before you create the NVAS. NVA's are created as virtual machines with the vendor operating system (OS) installed on them. In this scenario, this will be Barracuda Firewall OS, however the VMs are deployed as part of the NVA configuration, not beforehand.
You should not configure network peering between the Azure regions. Although configuring the network peering will facilitate non transitive relationships between the virtual networks in each Azure region, Azure Virtual WAN enables the different spokes in each region to communicate without having peering configured. Therefore, this is not required when deploying NVAs within a Virtual WAN.
You should not connect the Virtual network to the Hub. This step comes after you create the NVAs, and you actually need to create the virtual hub first.

---

### References

[How to create a Network Virtual Appliance in an Azure Virtual WAN hub](https://learn.microsoft.com/en-us/azure/virtual-wan/how-to-nva-hub)  

[About NVAs in a Virtual WAN hub](https://learn.microsoft.com/en-us/azure/virtual-wan/about-nva-hub)

[Scenario: Route traffic through an NVA](https://learn.microsoft.com/en-us/azure/virtual-wan/scenario-route-through-nva)  

---

## Q075:

You are a support technician for a company that has a hybrid infrastructure with resources hosted on- premises and in Azure. A member of the network team recently started to configure a VPN gateway to a Virtual WAN connection. Your manager has asked you to complete the deployment by creating the connection and testing the service.
When you try to create the connection you notice the two previous steps have not been completed. You need to complete the previous two missing configuration steps before you can create and test the connection.
Which two actions should you perform? Each correct answer presents part of the solution.

Choose the correct answers

- Create the local network gateway.
- Download the VPN configuration files.
- Create Virtual WAN VPN sites.
- Connect sites to the virtual hub.
- Configure a virtual network gateway (VPN gateway).

---

### Answer:

- Create the local network gateway.
- Download the VPN configuration files.

When configuring a connection between a VPN gateway to virtual WAN like in this scenario you need to complete the following steps:

1. Configure a virtual network gateway (VPN gateway).
2. Create virtual WAN sites.
3. Connect sites to the virtual hub.
4. Download the VPN configuration files.
5. Create the local network gateways.
6. Create connections.
7. Test connections.
As per the above order, downloading the VPN configuration files and creating the local network gateways are the two missing steps that come before you can create a connection, and those are the steps that were missed by the network team.
The VPN configuration file contains information about the sites that have been created in step two and that have been connected to the virtual hub in step three.

You need to create the local network gateway using the settings from the VPN files vou downloaded in step four.
This includes the IP address, border gateway protocol (BGP), address space, subscription, resource group and location settings.

---

### Answer:

---

### References

[Connect a VPN Gateway (virtual network gateway) to Virtual WAN](https://learn.microsoft.com/en-us/azure/virtual-wan/connect-virtual-network-gateway-vwan) 

[Tutorial: Create a site-to-site connection using Azure Virtual WAN](https://learn.microsoft.com/en-us/azure/virtual-wan/virtual-wan-site-to-site-portal)  

[What is Azure Virtual WAN?](https://learn.microsoft.com/en-us/azure/virtual-wan/virtual-wan-about)

---

## Q074:

![image info](./Q74_1.PNG)
![image info](./Q74_2.PNG)

Your organization has a hybrid infrastructure with services hosted both on-premises and in Azure as shown in Exhibit A. You have recently re-designed the virtual network (VNet) to be a hub-spoke network topology with an Azure Virtual WAN as shown in Exhibit B. The address spaces in the new design are shown in the following table:

| Virtual Network Name | Address Range |
|---|---|
| HubvNET | 10.2.0.0/16 |
| SpokeAvNET | 10.3.0.0/16 |
| SpokeBvNET | 10.4.0.0/16 |

You configure the VNets and subnets as per the second exhibit but leave all the resources in place. When you try to configure the network virtual appliance (NVA) in your new hub network, you receive a validation error that not all pre-requisites have been met. You need to complete these missing pre-requisites to complete the deployments of the NVA. Your solution must minimize administrative effort.

What change should you make?

Choose the correct answer

- Remove the VNG-A resource.
- Remove any IP address conflict between HubvNET and the spoke virtual networks (VNets).
- Remove all compute resources from the original network topology.
- Peer SpokeAVNET with SpokeBVNET.


---

### Answer:

- Remove the VNG-A resource.

You should remove the VNG-A resource from the environment. You cannot have a virtual network gateway (VPN or ExpressRoute) in any of your virtual networks (VNets) when configuring a network virtual appliance (NVA) in an Azure Virtual WAN. You are required to connect the virtual networks, in our case SpokeAVNET and SpokeBvNET, with a virtual WAN hub gateway instead.
You do not need to remove all compute resources from the original network topology. Although this would include removing the virtual network gateway, it would also require you to remove the virtual machines, which would create more administrative effort.
You do not need to peer SpokeAvNET with SpokeBvNET. In a true hub-spoke topology, all spoke networks must be connected to the hub network only and all traffic routes through that. If resources hosted in two spokes need to communicate with each other, the NVA will route the necessary traffic.
You do not need to remove any IP address conflict between HubvNET and the spoke VNets. As per the table within the scenario, there are three network address ranges, which are all /16, that do not overlap or conflict so this will not be causing an issue. You need to be careful when selecting your network address spaces to ensure there are no conflitcsas it can stop services from working or being deployed.

---

### References

[How to create a Network Virtual Appliance in an Azure Virtual WAN hub](https://learn.microsoft.com/en-us/azure/virtual-wan/how-to-nva-hub)  

[About NVAs in a Virtual WAN hub](https://learn.microsoft.com/en-us/azure/virtual-wan/about-nva-hub)  

[Scenario: Route traffic through an NVA](https://learn.microsoft.com/en-us/azure/virtual-wan/scenario-route-through-nva)

[Hub-spoke network topology with Azure Virtual WAN](https://learn.microsoft.com/en-us/azure/architecture/networking/architecture/hub-spoke-vwan-architecture)  

---

## Q073:

Your organization has just deployed a new instance of Azure virtual WAN basic in US East.
You need to create a Site-to-Site (S2S) VPN connection utilizing the existing Azure virtual WAN. The solution needs to support S2S VPN tunnels only.
Which four actions should you perform in sequence? To answer, move the appropriate actions from the list of possible actions to the answer area and arrange them in the correct order.

Create a list in the correct order

Possible actions
Upgrade virtual WAN from Basic to Standard.
Deploy Azure Firewall in the hub.

Actions in order
1. Create a virtual hub.
2. Create a VPN Site.
3. Connect the VPN site to the virtual hub.
5. Add a virtual network (VNet) connection to the virtual hub.

---

### Answer:

You should perform the following steps in order:
1. Create a virtual hub.
2. Create a VPN site.
3. Connect the VPN site to the virtual hub.
4. Add a virtual network connection to the virtual hub.

The scenario already has virtual WAN deployed; therefore, the first step is to create a virtual hub. Azure Virtual WAN is typically used in large organizations that consist of mar many branch offices across different regions. In the past, the different offices would need to connect to network resources using a combination of different technologies, including VPN tunnels and traditional Software Defined Area Network (SD WAN). Azure virtual WAN combines all of these different methods and utilizes the Microsoft backbone network to connect multiple geographical locations and offices together. A virtual hub is required in an Azure virtual WAN configuration, as it is the termination point for various connections coming into Azure.
Next, you should create a VPN site. A site is essentially a representation of your physical datacenter(s). This is required when configuring a virtual WAN.
Then, you should connect a VPN site to the virtual hub. Once the VPN site has been created and established, the next order of events in the workflow is to associate the site to the previously created virtual hub.
Finally, you should add the virtual network connection to the virtual hub. This step can only be completed once the above steps have been completed. Otherwise, there will be no connections available to connect to.
You should not deploy an Azure firewall. A firewall can be used with virtual WAN, but the scenario does not state the need for any traffic filtering or routing.
You should not upgrade virtual WAN from Basic to Standard. Azure virtual WAN is available in two stock keeping units (SKUs): Basic and Standard. Standard virtual WAN supports more functionality and scenarios, including the incorporation of Azure Firewall, Network Virtual Appliances, inter-virtual network connectivity and Express Route. Basic virtual WAN supports Site-to-Site (S2S) VPN tunnels only. The requirement states that the solution must only support S2S tunnels; as a result, the Standard SKU is not required.

---

### References

[Upgrade a virtual WAN from Basic to Standard](https://learn.microsoft.com/en-us/azure/virtual-wan/upgrade-virtual-wan)  

[Tutorial: Create a site-to-site connection using Azure Virtual WAN](https://learn.microsoft.com/en-us/azure/virtual-wan/virtual-wan-site-to-site-portal)


[Configure Azure Firewall in a Virtual WAN hub](https://learn.microsoft.com/en-us/azure/virtual-wan/howto-firewall)

---

## Q072:

Company1 is a global organization with multiple branch offices. Azure resources are currently spread across UK South and East US regions. Management has decided to decommission the Software-Defined WAN (SD- WAN) and wishes to plan the deployment of Azure virtual WAN instead.
Your tasks include planning the virtual WAN deployment. You need to ensure that spoke virtual networks (VNets) in the same region can communicate with each other and network latency is kept to a minimum.
Which two steps should you take? Each correct answer presents part of the solution.

Choose the correct answers

- Deploy a basic virtual WAN Stock-keeping Unit (SKU).
- Deploy a standard virtual WAN Stock-keeping Unit (SKU).
- Create a virtual WAN hub in both UK South and East US.
- Create a single virtual WAN hub in UK South only.

---

### Answer:

- Deploy a standard virtual WAN Stock-keeping Unit (SKU).
- Create a virtual WAN hub in both UK South and East US.

You should deploy a standard virtual WAN SKU and create a virtual WAN hub in both UK South and East US. If you require transit connectivity between VNets, you need to use a standard virtual WAN. This feature is not possible with a basic virtual WAN. Hubs are critical in a Virtual WAN deployment. They offer a termination point for VPN connections for example Site-to-Site and Point-to-Site. They also offer routing for inter-VNet communication. A Hub-to-hub topology would be viable here. When you create more than one WAN hub in a single virtual WAN instance, then both hubs can communicate with each other automatically. In this scenario and with the options presented, you require a hub in each region to fulfil the requirement.
Azure virtual WAN is typically used in large organizations that consist of many branch offices across different regions. In the past, the different offices would need to connect to network resources using a combination of different technologies, including VPN tunnels and traditional Software Defined Area Network (SD WAN). Azure virtual WAN combines all of these different methods and utilizes the Microsoft backbone network to connect multiple geographical locations and offices together. Azure virtual WAN is available in two SKUs: Basic and Standard. Standard virtual WAN supports more functionality and scenarios, including the incorporation of Azure Firewall, Network Virtual Appliances, inter-virtual network connectivity and Express Route.
You should not deploy a basic virtual WAN SKU. A basic WAN SKU does not support inter-VNet connectivity. A common use case for a basic WAN is when only site-to-site VPN connectivity is required.
You should not create a single virtual WAN hub in UK South only. The typical use case for an isolated virtual
WAN hub is for single-region deployments only. When two or more regions need to be connected together
in an Azure virtual WAN, then a hub is required in each region. This facilitates VPN connectivity from
branch offices into Azure.

---

### References

[What is Azure Virtual WAN?](https://learn.microsoft.com/en-us/azure/virtual-wan/virtual-wan-about)  

[Upgrade a virtual WAN from Basic to Standard](https://learn.microsoft.com/en-us/azure/virtual-wan/upgrade-virtual-wan)

[Global transit network architecture and Virtual WAN](https://learn.microsoft.com/en-us/azure/virtual-wan/virtual-wan-global-transit-network-architecture)  

---

## Q071:

![image info](./Q71_1.PNG)

Your company wants to design its Azure Virtual networks (VNets) as shown in the network architecture exhibit.
You need to enable your end-user and your offices to connect to the virtual machines while taking into consideration the hub used within the network shown in the exhibit.
For each of the following statements, select Yes if the statement is true. Otherwise, select No.


Deploy a Remote Authentication Dial-In User Service (RADIUS) server.
No

Deploy a route table.
Yes

Use Azure Private Link.
No

---

### Answer:

You should not deploy a RADIUS server. Remote Authentication Dial-In User Service (RADIUS) is a network protocol that protects a network by allowing centralized dial-in user authentication and authorization. This solution will not enable you to establish an any-to-any connection.
You should deploy a route table to enable your end-user and your offices to connect to the virtual machines as required. As shown in the exhibit, the type of hub used within the network is a virtual Wide Area Network (WAN) hub. Within a virtual WAN, you can deploy a route table that enables connections propagating to it to reach their destination and can be customized to enable any-to-any connection to be achieved.
You should not use Azure Private Link. Azure Private Link provides private access from an Azure virtual network (VNet) to Platform as a Service (PaaS) services and Microsoft Partner services in Azure. Azure Private Link cannot be used to establish an any-to-any connection.

---

### References

[Virtual WAN network topology](https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/virtual-wan-network-topology)  

[About virtual hub routing](https://learn.microsoft.com/en-us/azure/virtual-wan/about-virtual-hub-routing)  

Express Route connectivity models

[RADIUS authentication with Azure Active Directory](https://learn.microsoft.com/en-us/entra/architecture/auth-radius)  

What is Azure Private Link service?



---

## Q070:


![image info](./Q70_1.PNG)

Your company has the Azure environment shown in the network architecture exhibit.
Your manager complains about the routing mechanism that has been used for years within the company.
You need to implement a solution that eliminates the process of directing connections into transit virtual networks (VNets).
What solution should you implement?
Choose the correct answer

- Azure Virtual Network Gateway
- Network Virtual Appliances (NVAS)
- Azure Firewall
- Azure Virtual WAN

---

### Answer:

- Azure Virtual WAN

You should implement Azure Virtual Wide Area Network (WAN) to eliminate the process of directing connections into transit virtual networks (VNets). Azure Virtual WAN is a service from Azure that enables you to replace the transit VNet with a Virtual WAN hub structure that increases the scale of Site-to-Site Virtual Private Network (VPN) tunnels and simplifies the routing architecture of the network. When this service is enabled, routing will be done through the Virtual WAN hub where any peered Vnet is going to update the global route table. To implement this service, you must login into the Azure portal, where you will create a virtual WAN on the Create WAN page.

You should not implement Azure Virtual Network Gateway. This solution is used to connect on-premises sites to Azure Virtual Networks, but does not provide the ability to eliminate the process of directing connections into transit VNets as Azure Virtual WAN does.
You should not implement Azure Firewall. Azure Firewall is a security service responsible for protecting running workloads in Azure from cyber threats.

You should not implement Network Virtual Appliances (NVAS). NVAs represent the devices that are deployed into the Virtual WAN hub, like Express Route or Cisco Cloud OnRamp for Multi-Cloud. These devices provide networking functions for your network. NVAs cannot be used in eliminating the process of directing connections into transit VNets, as Azure Virtual WAN does, but can be used to increase the security level of your network and prevent attacks carried out by hackers, as well as filtering traffic that is sent and received by the virtual machines of your network.

---

### References

[Tutorial: Create a site-to-site connection using Azure Virtual WAN](https://learn.microsoft.com/en-us/azure/virtual-wan/virtual-wan-site-to-site-portal)  

[Azure Virtual Network Gateway Improvements](https://azure.microsoft.com/fr-fr/blog/azure-virtual-network-gateway-improvements/)  

[Deploy highly available NVAS](https://learn.microsoft.com/en-us/azure/architecture/networking/guide/nva-ha?tabs=cli)  

What is Azure Virtual WAN?
What is Azure Firewall?

---

## Q069:

![image info](./Q69_1.PNG)

You recently migrated your organization's critical applications to Azure. The virtual machines running the applications are distributed across three virtual networks: VNet1, VNet2, and VNet3. The company has two sites: the head office and the branch office. See the exhibit for the current set-up.
The company wants to modernize its existing infrastructure, for which they plan to migrate to the Azure Virtual WAN to link up all their global networks. It decides to create a global WAN entity, named VWAN- CompanyA, in the Azure portal.
The virtual WAN needs to support virtual networks (VNets), Express Route, site-to-site (S25) and point-to-site (P2S) VPN connectivity.
The head office will be connected to the virtual WAN via a S2S VPN connection, and the branch office will be connected to the virtual WAN via an Azure Express Route connection.
For each of the following statements, select Yes if the statement is true. Otherwise, select No.


You need to create the virtual WAN named VWAN-CompanyA with type Basic to support the required remote connection types.
nO

You should create a virtual hub inside the VWAN-CompanyA virtual WAN entity to create the S2S VPN connection.
yES

A virtual WAN hub gateway should be used to connect VNet1, VNet2. and VNet3 with the head office resources via the S2S VPN connection.
yES

---

### Answer:

You do not need to create the virtual Wide Area Network (WAN) named VWAN-CompanyA with type Basic to support the required remote connection types. In order to support the site-to-site (525) virtual private network (VPN) and the Express Route connection type, you need to create the virtual WAN with type Standard. The Basic type virtual WAN supports site-to-site VPN only. The Standard type supports the following connection types:

- Express Route
- User VPN (P2S)
- VPN (site-to-site)
- Inter-hub and VNet-to-VNet transiting through the virtual hub
- Azure Firewall
-  Network Virtual Appliance (NVA) in a virtual WAN

You should create a virtual hub inside the VWAN-CompanyA virtual WAN entity to create the S2S VPN connection. The virtual hub is the representation of the region that you want to connect the different remote and virtual networks (VNets) to. A virtual WAN can contain different hub entities representing different regions. By design, the resource in different hubs can communicate with each other and you do not need to configure any special connectivity for that.
A virtual WAN hub gateway should be used to connect VNet1, VNet2, and VNet3 with the head office resources via S2S VPN connection. You can create different VPN sites inside the virtual hub and then simply connect from there. In order to enable connectivity between the VNets and the remote VPN users, you will also need to associate the required VNets to the virtual WAN hub entity.

---

### References

[Tutorial: Create a Site-to-Site connection using Azure Virtual WAN](https://learn.microsoft.com/en-us/azure/virtual-wan/virtual-wan-site-to-site-portal)  

What is Azure Virtual WAN?

---

## Q068:

Your company plans to migrate workloads to Azure from on-premises. There is currently no connectivity in place between your on-premises services and your Azure tenant.
You have been asked to design an Express Route connection solution with a business case. In addition to the requirement to connect to services in Azure and Microsoft 365, you must ensure that:

- The connection is Active/Active.
- The connection is 100-Gbps.
- The connection is private.

You need to select the most appropriate Express Route connectivity model for your design.
Which connectivity model should you use?
Choose the correct answer

Co-located at Cloud Exchange
Point-to-point ethernet
Direct from ExpressRoute site
Any-to-any networks

---

### Answer:

You should use the Direct from Express Route site Express Route connectivity model to meet your organization's requirements. The Express Route Direct connection model can facilitate large data ingestion and can provide dual 100-Gbps connectivity, an active/active connection, and a private connection directly from your on-premises network into Azure and Microsoft 365 services.

You should not use the Co-located at Cloud Exchange connectivity model. If you have services hosted in a co-located location with a cloud exchange, then you can make a request for a virtual cross-connection to the Microsoft cloud through the co-location provider's ethernet exchange. This can be a Layer 2 cross- connection or a Layer 3 managed cross-connection between your hosted services in the co-location and Microsoft Cloud. This is not a direct connection, and the connection speed will be dependent on the co- location provider's hardware.
You should not use the Point-to-point ethernet connectivity model. This allows you to connect your on- premises offices to Azure through a point-to-point ethernet link. This can also be a Layer 2 connection or a managed connection between your site and Azure. However, this is not a private link.
You should not use the Any-to-any networks connectivity model. The Any-to-Any (IPVPN) allows you to integrate your wide area network (WAN) with Azure and is typically a multiprotocol label switching VPN. It enables an any-to-any connection between your branch offices and data centers. The given scenario does not include a WAN, which makes this model inappropriate.

---

### References

[Express Route connectivity models](https://learn.microsoft.com/en-us/azure/expressroute/expressroute-connectivity-models) 

[About Express Route Direct](https://learn.microsoft.com/en-us/azure/expressroute/expressroute-erdirect-about)

[Express Route prerequisites & checklist](https://learn.microsoft.com/en-us/azure/expressroute/expressroute-prerequisites)

[Extend an on-premises network using Express Route](https://learn.microsoft.com/en-us/azure/architecture/reference-architectures/hybrid-networking/expressroute)  

What is Azure Express Route?


---

## Q067:


Your organization has services that are hosted both on-premises and in Azure. The company has been using an Azure site-to-site VPN to facilitate connectivity between Azure-hosted resources and on-premises resources. However, a recent increase in network traffic has revealed that an Azure Express Route is now required.
You have been tasked with configuring Azure Private Peering for the recently provisioned Express Route with the following details:

![image info](./Q67_1.PNG)

You need to configure Azure Peering for the circuit using PowerShell considering the details in the table. The Express Route Circuit name has been set to $ckt in our script.

Which cmdlets should you use? To answer, select the appropriate commands from the drop-down menus.

Choose the correct options

```
OPTIONS -Name "Express RouteCircA" -ResourceGroupName "ExpressRouteRG"

OPTIONS Name "AzurePrivatePeering" -ExpressRouteCircuit $ckt -PeeringType  AzurePrivatePeering -PeerASN 100-

PrimaryPeerAddress Prefix "172.16.0.0/30" -Secondary PeerAddress Prefix "172.168.0.4/30" -VlanId 300

OPTIONS -ExpressRouteCircuit $ckt

```

```
Get-AzExpressRouteCircuit -Name "Express RouteCircA" -ResourceGroupName "ExpressRouteRG"

Add-AzExpressRouteCircuitPeeringConfig Name "AzurePrivatePeering" -ExpressRouteCircuit $ckt 
-PeeringType  AzurePrivatePeering -PeerASN 100-

PrimaryPeerAddress Prefix "172.16.0.0/30" -Secondary PeerAddress Prefix "172.168.0.4/30" -VlanId 300

Set-AzExpressRouteCircuit -ExpressRouteCircuit $ckt

```

---

### Answer:

You should complete the script as follows:

```
Get-AzExpress RouteCircuit -Name "ExpressRouteCircA" -ResourceGroupName "ExpressRouteRG"
Add-AzExpress RouteCircuitPeeringConfig -Name "Azure PrivatePeering" ExpressRouteCircuit Sckt -PeeringType Azure Private Peering -PeerASN 100 Primary PeerAddressPrefix "172.16.0.0/30" -Secondary PeerAddressPrefix "172.168.0.4/30" -Vlanid 300
Set-AzExpress RouteCircuit ExpressRouteCircuit $ckt
```

You should first use the Get-AzExpress RouteCircuit cmdlet to check the Express Route and ensure it is provisioned and enabled.
You should then use the Add-AzExpress Route Circuit Peering Config, which will add a peering configuration to the existing Express Route named Express RouteCircA. In the given script, this Express Route name value has been set as $ckt.
Finally, you should use the Set-AzExpress Route Circuit that will save the modified changes to the Express Route configuration.
You should not use the Add-AzExpress Route CircuitConnectionConfig, as this cmdlet is used to add a circuit connection configuration to an existing private peering of an Express Route. In the given scenario, we need to add the private peering, so this cmdlet would not be valid.

---

### References

[Tutorial: Create and modify peering for an Express Route circuit using PowerShell](https://learn.microsoft.com/en-us/azure/expressroute/expressroute-howto-routing-arm)  

[Tutorial: Create and modify peering for an Express Route circuit using CL](https://learn.microsoft.com/en-us/azure/expressroute/howto-routing-cli)

[Express Route circuits and peering](https://learn.microsoft.com/en-us/azure/expressroute/expressroute-circuit-peerings)  

[Get-AzExpressRouteCircuit](https://learn.microsoft.com/en-us/powershell/module/az.network/get-azexpressroutecircuit?view=azps-12.1.0&viewFallbackFrom=azps-10.2.0)

Add-AzExpress Route Circuit Peering Config
Set-AzExpress Route Circuit
Add-AzExpress Route CircuitConnectionConfig

---

## Q066:

Company1 has a large on-premises data center with multiple servers and hardware. Management at the company has taken the strategic decision to migrate all workloads to Microsoft Azure.
You have been hired as an Azure consultant to help plan the migration tasks.
You need to ensure that the on-premises data center connects to Microsoft Azure over a private connection. The company do not want to utilize the public internet for this connection.
Which solution should you use to meet the requirements?
Choose the correct answer
ExpressRoute
Site-to-Site VPN
Private Link Service
Azure Firewall

---

### Answer:

You should use Express Route. Express Route connections are used to connect on-premises networks to Microsoft Azure over a direct private connection. This can be achieved by either using an Express Route service provider or by connecting directly with Express Route Direct.
You should not use a Site-to-Site (S2S) VPN tunnel. This option allows organizations to configure connectivity from on-premises or another virtual network to Azure over an internet connection, which contradicts the scenario requirement of not using the public internet for this connection.
You should not use Private Link Service. Private link service is a technology provided by Azure, designed to allow consumers or networks to connect to other Azure services over a private connection. For example, the Azure Private Link service can be enabled on Azure SQL databases to ensure that connectivity from virtual networks travels over the Microsoft backbone using a private IP address instead of going over the internet.
You should not use Azure Firewall. Azure Firewall is a Firewall as a Service (FWaaS) provided by Microsoft. It allows customers to protect virtual networks against malicious threats by inspecting inbound and outbound network packets. Azure Firewall provides filtering on Layer 3-7 of the Open Systems Interconnection (OSI) model.

---

### References

[Express Route connectivity models](https://learn.microsoft.com/en-ca/azure/expressroute/expressroute-connectivity-models)  

[About Express Route Direct](https://learn.microsoft.com/en-ca/azure/expressroute/expressroute-erdirect-about)  


What is Azure Express Route?
What is Azure VPN Gateway?
What is Azure Private Link service?
What is Azure Firewall?

---

## Q065:

Your company has four on-premises sites. Three of them represent the branches of the company and the
fourth represents the main office. The company also has an Azure Virtual Network.
The four sites are connected to each other by a WAN network. The four sites connect to the virtual network through the public internet.
You need to establish a direct connection between the on-premises sites and the virtual network without the need to pass through the public internet.
What solution should you use?

Choose the correct answer

- ExpressRoute circuits
- ExpressRoute circuits
- Application Gateway
- Application Proxy
- Standard Load Balancer

---

### Answer:

- ExpressRoute circuits

You should use Express Route circuits to establish a direct connection between the on-premises sites and the virtual network without the need to pass through the public internet. An Express Route circuit is a private connection from your network to a Microsoft peering location that is a supported termination point within the Microsoft Cloud Network. By using Express Route circuits, you can bypass the public internet and achieve a secure and private connection between your sites and your virtual network. You should navigate to the Azure portal, and access the Create Express Route page to create your circuit. There are several types of Express Route circuits like Express Route Direct and Express Route Fast path that can be used to enter the global network of Microsoft from your on-premises site.
You should not use Standard Load Balancer. A Standard Load Balancer enables you to load balance protocol flows on all ports when using an Internal Load Balancer through High Availability ports. However, a Standard Load Balancer cannot be used to establish a direct connection between the on-premises sites and the virtual network without the need to pass by the public internet.
You should not use an Application Proxy. This solution can be used to publish on-premises applications to networks outside the company.

You should not use an Application Gateway. This load-balancing solution is used to load balance across servers at an application level. Application Gateway operates at layer 7 of the OSI model.

---

### References

What is Azure Express Route?

What is Azure Load Balancer?

[Remote access to on-premises applications through Azure AD Application Proxy](https://learn.microsoft.com/en-us/entra/identity/app-proxy/)  

What is Azure Application Gateway?

---

## Q064:

For security reasons, your organization decides to configure a Standard Express Route to connect directly to the Microsoft private network.
You plan to increase the network bandwidth of the Express Route gateway as the user traffic significantly increased.
You need to upgrade from the Standard SKU to the HighPerformance SKU.
Which Azure PowerShell cmdlets should you use to perform this change?

Choose the correct answer

- Set-AzVirtualNetwork
- Get-AzApplicationGatewaySku
- Resize-AzVirtual Network Gateway
- Reset-AzVirtualNetwork GatewayConnection

---

### Answer:


- Resize-AzVirtual Network Gateway

You should use the Resize-AzVirtual Network Gateway Azure PowerShell cmdlet to change the Express Route virtual network gateway Stock Keeping Unit (SKU):

```
Resize-AzVirtualNetworkGateway
-VirtualNetworkGateway <PSVirtualNetworkGateway>
-GatewaySku <String>
[-DefaultProfile <IAzureContextContainer>]
[<CommonParameters>]
```

You should not use the Set-AzVirtual Network PowerShell cmdlet to change the Express Route virtual network gateway SKU. This cmdlet is used to update a virtual network on the Azure portal.

```
Set-AzVirtualNetwork
-VirtualNetwork <PSVirtualNetwork>
[-AsJob]
[-DefaultProfile <IAzureContextContainer>]
[<CommonParameters>]
```

You should not use the Reset-AzVirtual Network Gateway Connection PowerShell cmdlet to change the Express Route virtual network gateway SKU. This cmdlet is used to reset a virtual network gateway.

```
Reset-AzVirtualNetworkGatewayConnection
-Name <String>
-ResourceGroupName <String>
[-AsJob]
[-DefaultProfile <IAzureContextContainer>]
[<CommonParameters>]
```

You should not use the Get-AzApplicationGateway Sku PowerShell cmdlet to change the Express Route virtual network gateway SKU. This cmdlet is used to get the details of the Application Gateway SKU.
Get-AzVirtualNetworkGateway
[-Name <String>]
-ResourceGroupName <String>
[-DefaultProfile <IAzureContextContainer>]
[<CommonParameters>]

---

### References

[Resize-AzVirtual Network Gateway](https://learn.microsoft.com/en-us/powershell/module/az.network/resize-azvirtualnetworkgateway?view=azps-12.1.0&viewFallbackFrom=azps-6.6.0)  

[Get-AzApplicationGatewaySku](https://learn.microsoft.com/en-us/powershell/module/az.network/get-azapplicationgatewaysku?view=azps-12.1.0&viewFallbackFrom=azps-6.6.0)

[Reset-AzVirtualNetworkGatewayConnection](https://learn.microsoft.com/en-us/powershell/module/az.network/reset-azvirtualnetworkgatewayconnection?view=azps-12.1.0&viewFallbackFrom=azps-6.6.0)

Set-AzVirtualNetwork

[About Express Route virtual network gateways](https://learn.microsoft.com/en-us/azure/expressroute/expressroute-about-virtual-network-gateways)  

---

## Q063:

You experience a long link failure detection time between the Customer Premises Equipment (CPE)/Router and the Microsoft Enterprise edge (MSEE) devices on Azure Express Route private peering interfaces. These long link failures are causing quality issues for real-time applications and significantly degrade the user experience in the branch offices.
You need to speed up this link failure detection time so that redundant links can be used on the express route circuits to maintain the traffic quality.
Which technology should you use?
Choose the correct answer\

- BGP timers
- Bidirectional Forwarding Detection (BFD)
- Virtual Private Network (VPN)
- Open Shortest Path First (OSPF)

---

### Answer:

- Bidirectional Forwarding Detection (BFD)

You should use Bidirectional Forwarding Detection (BFD). BFD is a link failure detection mechanism that provides a faster failover from the primary link to the secondary link in case of link failure. The Border Gateway Protocol (BGP) keep-alive and hold-time play a role in determining the link failure detection time between MSEE and customer edge routers. In most cases, the link failure detection can take up to three minutes. To reduce this link failure detection time to a few seconds, it is recommended that you enable BFD. On the MSEE, the BFD is configured by default; you only need to configure it on the local edge routers and then associate it with the BGP session.
You should not use Border Gateway Protocol (BGP) timers. BGP is the protocol that runs the internet. This protocol helps to create links with next-hop autonomous systems (AS) and keep a map of the whole internet topology. The BGP neighbors will update each other about any routing changes they might detect. BGP keep-alive is used to keep track of its neighbors. By configuring a lower BGP keep-alive timer, the link detection failure time can be improved, but this will cause significant overhead on the routers because BGP is a resource-intensive protocol.

You should not use Open Shortest Path First (OSPF). OSPF is an Interior Gateway Protocol (IGP) based on the shortest path first algorithm. The OSPF uses concepts of an area, which comprises routing nodes, and maintains a list of all the optimal and suboptimal routes in its database. OSPF cannot be used to form peers with public internet routers.
You should not use Virtual Private Network (VPN). In most cases, VPN is the extension of the private internal network to remote locations or users. The traffic that flows via a virtual network is encrypted, thus it provides maximum security against traffic sniffing or replay attacks. VPN is a tunneling protocol and it cannot be used to detect the link failure events at L2 or L3.

---

### References

[Explore Azure Express Route](https://learn.microsoft.com/en-us/training/modules/design-implement-azure-expressroute/2-explore)  

[What is BGP? | BGP routing explained](https://www.cloudflare.com/learning/security/glossary/what-is-bgp/)

[Open Shortest Path First (OSPF) protocol States](https://www.geeksforgeeks.org/open-shortest-path-first-ospf-protocol-states/)  

---

## Q062:

Your company hosts its corporate services in Azure and uses Azure point-to-site VPN to allow users to connect into cloud-hosted VMs. The current solution uses certificate authentication and has been working fine since it was implemented over 12 months ago.
Multiple users have contacted the support desk to report problems when trying to connect to the point-to- site VPN. Upon further investigation, you find that all users are getting the following error: The message received was unexpected or badly formatted.
You need troubleshoot the issue and find the root case of what is causing this error.
What is the root cause of this error?
Choose the correct answer
The public key has expired.
The User Defined Routes (UDR) with default route is set incorrectly.
The root certificate public key has not been uploaded to the Azure VPN Gateway.
An incorrect Gateway type has been configured.

---

### Answer:

There are multiple reasons that may cause this error to be generated, including:

- The User Defined Routes (UDR) with default route on the Gateway subnet is set incorrectly.

- The root certificate public key has not been uploaded into the Azure VPN Gateway.

- The public key is corrupted or has expired.

The UDR and public key being uploaded to Azure VPN Gateway are tasks that are only necessary once when the initial configuration has been completed. In this scenario, the VPN was deployed over 12 months ago, indicating that the correct answer is that the public key has expired and needs to be renewed.

You will receive the "Target URI is not specified" error when the incorrect gateway type has been configured. This is, therefore, not the root cause of the issue.

---

### References

[Troubleshoot a Microsoft Entra authentication VPN client](https://learn.microsoft.com/bs-latn-ba/azure/vpn-gateway/troubleshoot-ad-vpn-client)  

[Troubleshooting: Azure point-to-site connection problems](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-troubleshoot-vpn-point-to-site-connection-problems)  

---

## Q061:

Your company hosts laas services in Azure. You have recently configured Point-to-Site VPN to integrate with Azure AD to allow the Dev team to use their corporate cloud native accounts to authenticate using the Azure Client VPN.
One of the Dev team has contacted the Support Desk and reported that they need to connect to Azure VMs, but they do not know how to connect into the VPN.
The Support Desk staff ask you to document the process of configuring the the Point-to-Site connection. You need to document only the necessary steps that need to be followed in order to configure the Azure VPN client to use Azure AD authentication.
Which four steps should you perform in sequence? To answer, move the appropriate steps from the list of possible steps to the answer area and arrange in the correct order.
Create a list in the correct order

Possible Steps
Export profile settings.
Import Certificate to the VPN Client.

Steps in Order

1. Download and install the Azure VPN Client.
2. Generate the VPN Client Profile Configuration Package.
3. Import the client profile settings to the VPN Client.
4. Create a connection.

---

### Answer:

You should initially download and install the Azure VPN client onto the Windows device that you will be connecting from. You can download the install files from the following URL: https://aka.ms/azvpnclientdownload or directly from the Microsoft Store.
Then, you should generate the VPN client profile configuration files. You can do this either via the Azure Portal or do so via PowerShell. To complete this task via PowerShell, you can run the following cmdlet:
$profile-New-AzVpnClientConfiguration -ResourceGroupName "<enter resource group name here>" -Name "<enter VPN Gateway name here>" -AuthenticationMethod "EapTls"
Sprofile.VPNProfileSASUrl
You should set the VPN profile name value to $profile before running this cmdlet and ensure you know the resource group name and the VPN Gateway name, as you will need to enter them both within the cmdlet. Running this cmdlet will generate a URL, which you need to browse to in order to download the zip file with the relevant configuration package files.
Then, you should import the client profile settings to the VPN Client. Here, you use the azurevpnconfig.xml file, which is part of the zip file you download in step two. This file is imported into the configuration using the Azure VPN Client software and it will populate a lot of the configuration. You need to specify the connection name, but everything else is automatically imported from the xml file.
Finally, you create the connection within the Azure VPN Client. In this part of the workflow, you should fill out the connection information, select Connect to connect to the VPN and select the correct credentials. This will then successfully connect the user to the VPN and grant them access to the relevant resources.
You should not export profile settings as this is an optional step when you want to distribute a client profile. In the given scenario, only the necessary steps should be documented.
You should not import a certificate into the VPN Client, as we are not using Certificate authentication. Instead, we are using Azure AD authentication, which does not need a certificate.

---

### References

[Configure the Azure VPN Client - Azure AD authentication - Windows](https://learn.microsoft.com/en-us/azure/vpn-gateway/point-to-site-entra-vpn-client-windows)

[Configure an Azure AD tenant and P2S configuration for VPN Gateway P2S connections](https://learn.microsoft.com/en-us/azure/vpn-gateway/openvpn-azure-ad-tenant)  

[Configure P2S for access based on users and groups Azure AD authentication](https://learn.microsoft.com/en-us/azure/vpn-gateway/openvpn-azure-ad-tenant-multi-app)

[Generate P2S Azure VPN Client profile configuration files Azure AD authentication](https://learn.microsoft.com/en-us/azure/vpn-gateway/about-vpn-profile-download)

---

## Q060:

An insurance company currently has Point-to-Site (P2S) VPN configured to allow a small number of their employees to connect to Azure resources.
You are tasked with improving the company's authentication methods.
You need to ensure that users can authenticate to the P2S VPN using their on-premises credentials.
What should you do?
Choose the correct answer

- Configure an active-active VPN gateway.
- Configure Network Address Translation (NAT) on the Azure VPN gateway.
- Configure a RADIUS server on-premises and integrate with the Active Directory (AD) server.
- Install and configure Azure Active Directory (Azure AD) Connect.

---

### Answer:

- Configure a RADIUS server on-premises and integrate with the Active Directory (AD) server.

You should configure a RADIUS server on-premises and integrate with the Active Directory (AD) server. The RADIUS server, configured either on-premises or in an Azure VNet, will allow users to utilize their organization's credentials to authenticate against P2S VPN connections. The VPN gateway acts as a messenger between the RADIUS server and the VPN device.
You should not configure an active-active VPN gateway. This is used to create highly available VPN connections between your networks and Azure. It is achieved by deploying a minimum of two VPN gateways and public IP addresses.
You should not install and configure Azure Active Directory (Azure AD) Connect. Depending on the deployment model, Azure AD Connect synchronizes on-premises Active Directory (AD) accounts to Azure AD. This alone will not allow users to utilize their on-premises credentials to authenticate against P2S VPN connections.
You should not configure Network Address Translation (NAT) on the Azure VPN gateway. NAT can be used to keep virtual machines private. Virtual machines can utilize a static public IP address associated with the NAT virtual network for outbound connectivity. A common use case for this feature is to address issues where conflicting IP address spaces are used.

---

### References

[Configure P2S VPN Gateway server settings - RADIUS authentication](https://learn.microsoft.com/en-us/azure/vpn-gateway/point-to-site-how-to-radius-ps)

[Configure active-active VPN gateways using the portal](https://learn.microsoft.com/en-us/azure/vpn-gateway/active-active-portal)  

[https://learn.microsoft.com/en-us/azure/vpn-gateway/nat-overview#:~:text=About%20NAT%20on%20Azure%20VPN%20Gateway](https://learn.microsoft.com/en-us/azure/vpn-gateway/nat-overview)

what is Azure AD Connect?

---

## Q059:

Your company has an Azure virtual network (VNet). Your manager wants the company to be able to use custom domain names within the VNet.
You need to create a private DNS zone using online Azure PowerShell.
Which three actions should you perform in sequence? To answer, move the appropriate actions from the list of possible actions to the answer area and arrange them in the correct order.

Create a list in the correct order

Possible steps
Deploy an Azure Quickstart template.
Validate the deployment of the Azure Quickstart template.

Steps in order

1. Access Azure Cloud Shell.
2. Create a private DNS zone.
3. Create a test virtual machine.

---

### Answer:

You should first access Azure Cloud Shell to create a private DNS zone using online Azure PowerShell. Azure Cloud Shell enables you to configure Azure services over your browser.
Then, you should create a private DNS zone. You should use the New-AzPrivateDnsZone cmdlet to create the private zone within PowerShell. You have to specify the DNS zone name and at what resource group it is found, in addition to specifying which virtual network (VNet) this private DNS zone would be linked to.
Finally, you should create a test virtual machine. At this point, you test your created private DNS zone through test virtual machines. You should use the New-AzVm cmdlet to specify all the details related to the
test virtual machine.
You should not deploy an Azure Quickstart template. You create an Azure Quickstart template when you create a public DNS zone using Azure Resource Manager where you deploy the template that you reviewed on the Azure DNS domain hosting example page.
You should not validate the deployment of the Azure Quickstart template. This action is required after creating a public DNS zone using Azure Resource Manager, where you use the nslookup cmdlet for validation.

---

### References

[Quickstart: Create an Azure private DNS zone using Azure PowerShell](https://learn.microsoft.com/en-us/azure/dns/private-dns-getstarted-powershell)

[Quickstart: Create an Azure DNS zone and record using an ARM template](https://learn.microsoft.com/en-us/azure/dns/dns-get-started-template)  

---

## Q058:

Your company has an Azure Virtual Network. Your manager wants you to establish a point-to-site VPN connection that initiates at the company's workstation and terminates at an Azure Vnet gateway so that users at the company can access resources within the virtual network.
You need to use an authentication method that does not use OpenVPN.

What method should you use?

Choose the correct answer

- Azure Key Vault
- Azure Databricks
- Self-signed certificate authority
- RADIUS

You should perform the following steps in order:
1. Access Azure Cloud Shell.
2. Create a private DNS zone.
3. Create a test virtual machine.
You should first access Azure Cloud Shell to create a private DNS zone using online Azure PowerShell. Azure Cloud Shell enables you to configure Azure services over your browser.
Then, you should create a private DNS zone. You should use the New-AzPrivateDnsZone cmdlet to create the private zone within PowerShell. You have to specify the DNS zone name and at what resource group it is found, in addition to specifying which virtual network (VNet) this private DNS zone would be linked to.
Finally, you should create a test virtual machine. At this point, you test your created private DNS zone test virtual machine.
through test virtual machines. You should use the New-AzVm cmdlet to specify all the details related to the
You should not deploy an Azure Quickstart template. You create an Azure Quickstart template when you create a public DNS zone using Azure Resource Manager where you deploy the template that you reviewed on the Azure DNS domain hosting example page.
You should not validate the deployment of the Azure Quickstart template. This action is required after creating a public DNS zone using Azure Resource Manager, where you use the nslookup cmdlet for validation.

---

### Answer:

- Self-signed certificate authority

You should use a self-signed certificate authority to meet the requirements. A self-signed certificate authority is one of the three authentication methods that point-to-site Virtual Private Network (VPN) uses. This is the only method that does not use OpenVPN but instead, it requires you to generate client certificates from a root certificate, then upload the root certificate to Vnet gateway that authenticate the client certificates. This would achieve a secure connection between the users within the company and the virtual network that contains the resources. OpenVPN is a open source VPN solution available on Azure market that enables you to connect your workstation securely to your virtual network over the public internet.
You should not use the RADIUS authentication method. Remote Authentication Dial-In User Service (RADIUS) is a network protocol that protects a network by allowing centralized dial-in user authentication and authorization. You can use the RADIUS server with OpenVPN to provide authentication via an external directory server to your VPN users.
You should not use Azure Databricks. This service is a data analytics platform that contains applications related to Structured Query Language (SQL), data science, and machine learning. Azure Databricks cannot be used to achieve a secure connection.

You should not use Azure Key Vault. This service is used to encrypt keys and passwords that use keys stored within hardware security modules, but cannot be used to achieve a secure connection.

---

### References

[Create a self-signed public certificate to authenticate your application](https://learn.microsoft.com/en-us/entra/identity-platform/howto-create-self-signed-certificate)  

[RADIUS authentication with Azure Active Directory](https://learn.microsoft.com/en-us/entra/architecture/auth-radius) 

Key Vault
What is Azure Databricks?

---

## Q057:

You plan to configure a Point-to-Site VPN for remote users.
Your network design team needs to identify the protocols that can be used to establish the connection to Azure Virtual Network Gateway.
Which three protocols can be used? Each correct answer presents a complete solution.
Choose the correct answers
Secure Socket Tunneling Protocol (SSTP)
SHA256
OpenVPN Protocol
MD5
AES256
IKEv2 VPN

---

### Answer:

You should identify the following protocols to use:

- OpenVPN Protocol
- Secure Socket Tunneling Protocol (SSTP)
-IKEv2 VPN

The client machine needs to establish a secure virtual private network (VPN) connection to the Virtual Network Gateway. The OpenVPN protocol is supported on the Virtual Network Gateway for creating a P2S VPN connection. SSTP is used to create a secure channel from the client's machine to Azure Virtual
Network Gateway and uses Point-to-Point Protocol (PPP) to send the traffic via a Transport Layer Security (TLS) session. Internet Key Exchange version 2 (IKEv2) VPN provides both security and encryption services. In summary, you can use any of these security protocols to establish the VPN connection from the client to Azure Virtual Network Gateway.
You should not identify Message digest 5 (MD5) and SHA256, as these are hashing standards. Hashing standards are not used to create an IPSec tunnel, they are used to validate the integrity of the data. Hashing functions are used to create a one-way hash of the data and to verify the integrity of the data. If the data is not tampered with, the hash function will generate the same hash result.
You should not identify Advanced Encryption Standard (AES). The AES 256 bit is an encryption standard developed by the National Institute of Standards (NIST). AES uses the same key to encrypt and decrypt the data. It is therefore known as a symmetric encryption algorithm.

---

### References

[Connect devices to networks with Point-to-site VPN connections](https://learn.microsoft.com/en-us/training/modules/design-implement-hybrid-networking/5-connect-devices-to-networks-point-to-site-vpn-connections)  

[Advanced Encryption Standard](https://www.tutorialspoint.com/cryptography/advanced_encryption_standard.htm)

[MD5 vs SHA-1 vs SHA-2 - Which is the Most Secure Encryption Hash and How to Check Them](https://www.freecodecamp.org/news/md5-vs-sha-1-vs-sha-2-which-is-the-most-secure-encryption-hash-and-how-to-check-them/)  

---

## Q056:

You host the company's development servers on the Azure cloud. You plan to configure a Point-to-Site (P2S) VPN connection for remote users who are already configured on-premises in the company's Active Directory (AD) server.
You want to use your existing AD server for the VPN authentication.
What solution should you use?

Choose the correct answer

- IPSec
- Azure Front Door
- RADIUS Server
- OpenVPN

---

### Answer:

- RADIUS Server

You should use a RADIUS Server. You will need to integrate your Remote Access Dial In User Service (RADIUS) server with the Active Directory (AD). The RADIUS server can be installed on-premises or inside an Azure virtual network. The Azure VPN gateway will relay the messages from the VPN client via the RADIUS server to the AD controller and vice versa.
You should not use OpenVPN. OpenVPN is a free open-source VPN system that can be used to deploy a fully working virtual private network setup. The OpenVPN cannot be used to relay the authentication messaging between the client and the AD servers.
You should not use IP Security (IPSec). IPSec is the protocol used by the VPN clients or nodes to create security associations with remote VPN servers. As it is a protocol itself, it cannot be used to solve the problem in this scenario.
You should not use Azure Front Door. Azure Front Door uses Microsoft edge locations and provides load balancing and site acceleration functions. SSL offload, path-based routing, quick failover, caching, and other Layer 7 capabilities are available to boost web application performance.

---

### References

[Connect devices to networks with Point-to-site VPN connections](https://learn.microsoft.com/en-us/training/modules/design-implement-hybrid-networking/5-connect-devices-to-networks-point-to-site-vpn-connections)  
What is fRONT dOOR?

---

## Q055:

> Exhibit:

```
New-AzResource Group -Name RG-A-Location EastUS

$virtual Network = New-AzVirtual Network -ResourceGroupName RG-A
-Location EastUS -Name VNET-A-Address Prefix 172.16.0.0/16

$subnetConfig = Add-AzVirtualNetworkSubnetConfig -Name SN-A
-AddressPrefix 172.16.0.0/24 -Virtual Network $virtual Network

$virtual Network | Set-AzVirtualNetwork
$vnet = Get-AzVirtualNetwork -ResourceGroupName RG-A -Name VNET-A

Add-AzVirtualNetworkSubnetConfig -Name 'GatewaySubnet'
-AddressPrefix 172.16.255.0/27 -VirtualNetwork $vnet

$vnet | Set-AzVirtualNetwork

$gwpip New-AzPublicIpAddress -Name "VNETAGWIP" -ResourceGroupName "RG-A" -Location "EastUS" -AllocationMethod Static
```

Your company has an existing Azure subscription in which it hosts resources, applications and services in the UK South region. The company has recently opened an office in Virginia, USA which will have limited space of on-premises hardware. The directors decide to host services in Azure in the East US region.
Initially, Admin-A started to create the base-line resources within the East-US region as shown in the exhibit, however he did not complete the process. The office is due to launch in a few weeks and there is still not connectivity between the Virginia Office and Azure. You are tasked with reviewing the existing PowerShell script and complete the configuration to which will connect the local office network with Azure.
You need to use PowerShell to complete the configuration to connect the Virginia Office with Azure.
Which cmdlets should you use? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

OPTIONWS: 
Get-AzVirtualNetworkSubnetConfig 
New-AzVirtualNetworkGateway
Get-AzVirtualNetworkGateway
New-AzVirtualNetworkGatewayIpConfig

```
1 $vnet Get-AzVirtual Network -Name VNETA -ResourceGroupName RG-A

2 $subnet = OPTION-2 -Name 'GatewaySubnet' -VirtualNetwork $vnet

3 $gwipconfig = OPTION-3 Network GatewayIpConfig
-Name gwipconfigA -SubnetId $subnet.Id

4-PublicIpAddressId $gwpip.Id

5 OPTION-5 -Name VNetAGW-ResourceGroupName RG-A-Location "East

6 US" -IpConfigurations $gwipconfig -GatewayType "Vpn" -VpnType "RouteBased" -GatewaySku

7 VpnGw2-VpnGatewayGeneration "Generation2"
```

```
1 $vnet Get-AzVirtual Network -Name VNETA -ResourceGroupName RG-A
2 $subnet = Get-AzVirtualNetworkSubnetConfig
-Name 'GatewaySubnet' -VirtualNetwork $vnet
3 $gwipconfig = New-AzVirtual Network GatewayIpConfig
-Name gwipconfigA -SubnetId $subnet.Id
4-PublicIpAddressId $gwpip.Id
5 New-AzVirtualNetworkGateway
-Name VNetAGW-ResourceGroupName RG-A-Location "East
6 US" -IpConfigurations $gwipconfig -GatewayType "Vpn" -VpnType "RouteBased" -GatewaySku
7 VpnGw2-VpnGatewayGeneration "Generation2"
```

---

### Answer:

You should complete the code as follows:

```
$vnet Get-AzVirtualNetwork -Name VNETA -ResourceGroupName RG-A
$subnet = Get-AzVirtualNetworkSubnetConfig -Name 'GatewaySubnet'
VirtualNetwork $vnet
Sgwipconfig = New-AzVirtualNetworkGatewayIpConfig -Name gwipconfigA -SubnetId $subnet.Id
-PublicIpAddressId $gwpip.Id
New-AzVirtualNetworkGateway -Name VNetAGW -ResourceGroupName RG-A
Location "East US"
-IpConfigurations Sgwipconfig -GatewayType "Vpn" -VpnType "RouteBased" -GatewaySku VpnGw2 -VpnGatewayGeneration "Generation2"
```
You should use the Get-AzVirtual Network SubnetConfig cmdlet which will retrieve information regarding the subnet 'Gateway Subnet' in the VNETA.
You should then use the New-AzVirtual Network GatewaylpConfig cmdlet which will create the IP configuration for the virtual network gateway named gwipconfigA with the subnet and public IP address that were created by Admin-A as shown in the exhibit.
You should use the New-AzVirtual Network Gateway cmdlet to create the Virtual Network Gateway named VNetAGW which includes the Gateway IP Configuration created earlier in this script.
You should not use the Get-AzVirtual Network Gateway cmdlet in this script. This cmdlet is used to retrieve the information on an existing Virtual Network Gateway, but here we need to create a new one.

---

### References


[Create a route-based VPN gateway using PowerShell](https://learn.microsoft.com/en-us/azure/vpn-gateway/create-gateway-powershell)  

[Tutorial: Create and manage a VPN gateway by using the Azure portal](https://learn.microsoft.com/en-us/azure/vpn-gateway/tutorial-create-gateway-portal)  

[Tutorial: Create a site-to-site VPN connection in the Azure portal](https://learn.microsoft.com/en-us/azure/vpn-gateway/tutorial-site-to-site-portal)   

[Configure a virtual network gateway for Express Route using the Azure portal](https://learn.microsoft.com/en-us/azure/expressroute/expressroute-howto-add-gateway-portal-resource-manager)  

[New-AzVirtual Network GatewaylpConfig](https://learn.microsoft.com/en-us/powershell/module/az.network/new-azvirtualnetworkgatewayipconfig?view=azps-12.1.0&viewFallbackFrom=azps-11.4.0)  

New-AzVirtual Network Gateway

---

## Q054:

Your company hosts applications and services in Azure that are consumed by users spread across four different locations. The network details for each location are shown in the table below:

| Office Name | On-Premises Subnet Address Space |
|-------------|---------------------------------|
| Office A    | 172.16.48.0/22                   |
| Office B    | 172.16.8.0/22                    |
| Office C    | 172.16.16.0/22                   |
| Office D    | 172.16.28.0/22                   |

You have been asked to configure a VPN Gateway from each local office to its respective Azure Region as shown in the table below:


| Office Name | Azure Region | vNet Address Space | Existing Virtual Subnet |
|-------------|-------------|-------------------|------------------------|
| Office A    | UK South    | 172.16.52.0/22   | 172.16.52.0/24         |
| Office B    | France Central | 172.16.12.0/22   | 172.16.12.0/24         |
| Office C    | East US     | 172.16.20.0/22   | 172.16.20.0/24         |
| Office D    | Italy North | 172.16.32.0/22   | 172.16.32.0/24         |

You need to ensure you configure the local network gateway for each Office VPN that does not overlap with its on-premises address space.
What address space should you use for each Office's local network gateway? To answer, drag the appropriate Office name to each subnet you need to configure. An Office name may be used once, more than once, or not at all.

172.16.15.0/24 : Office B
172.16.22.0/24 : Office C
172.16.34.0/24 : Office D
172.16.55.0/24: Office A


---

### Answer:

You should use the 172.16.15.0/24 address space when creating the local network gateway for Office B. Office B has an on-premises address space of 172.16.8.0/22 which includes the 172.16.8.1 to 172.16.11.254 address range. This means that the local network gateway cannot be within this address range. Office B needs to connect to the France Central region in the company's tenant, which has an existing virtual network with an address space of 172.16.12.0/22 and an existing subnet with a 172.16.12.0/24 address space. This means that the local network gateway for Office B in the France Central region must be within the 172.16.12.0/22 address space but after the 172.16.12.0/24 address range.

You should use the 172.16.22.0/24 address space when creating the local network gateway for Office C. Office C has an on-premises address space of 172.16.16.0/22 which includes the 172.16.16.1 to 172.16.19.254 address range. This means that the local network gateway cannot be within this address range. Office C needs to connect to the East US region in the company's tenant, which has an existing virtual network with an address space of 172.16.20.0/22 and an existing subnet with a 172.16.20.0/24 address space. This means that the local network gateway for Office C in the East US region must be within the 172.16.20.0/22 address space but after the 172.16.20.0/24 address range.

You should use the 172.16.34.0/24 address space when creation the local network gateway for Office D. Office D has an on-premises address space of 172.16.28.0/22 which includes the 172.16.28.1 to 172.16.31.254 address range. This means that the local network gateway cannot be within this address range. Office D needs to connect to the Italy North region in the company's tenant, which has an existing virtual network with an address space of 172.16.32.0/22 and an existing subnet with a 172.16.32.0/24 address space. This means that the local network gateway for Office D in the Italy North region must be within the 172.16.32.0/22 address space but after the 172.16.32.0/24 address range.
You should use the 172.16.55.0/24 address space when creating the local network gateway for Office A. Office A has an on-premises address space of 172.16.48.0/22 which includes the 172.16.48.1 to 172.16.51.254 address range. This means that the local network gateway cannot be within this address range. Office A needs to connect to the UK South Azure region in the company's tenant, which has an existing virtual network with an address space of 172.16.52.0/22 and an existing subnet with a 172.16.52.0/24 address space. This means that the local network gateway for Office A in the UK South region must be within the 172.16.52.0/22 address space but after the 172.16.52.0/24 address range.

---

### References


[Tutorial: Create a site-to-site VPN connection in the Azure portal](https://learn.microsoft.com/en-us/azure/vpn-gateway/tutorial-site-to-site-portal)  

[Modify local network gateway settings using the Azure portal](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-modify-local-network-gateway-portal)  

---

## Q053:

You are the Azure administrator in a organization.
You have configured a site-to-site VPN tunnel connecting the corporate on-premises network to Azure, which has been working without issues. However, many users report today that they cannot connect to Azure virtual machines.
You need to troubleshoot the site-to-site VPN connection and find out why it is not working.
Which troubleshooting step should you carry out?

Choose the correct answer

- Change the Origin response timeout (in seconds).
- Verify that the Provider status is showing as Provisioned.
- Check if Border Gateway Protocol (BGP) is enabled on the virtual network gateway.
- Verify the shared key between the on-premises VPN device and Azure.


---

### Answer:

- Verify the shared key between the on-premises VPN device and Azure.

You should verify the shared key between the on-premises VPN device and Azure. For a VPN connection to be successful, the pre-shared key for the on-premises network and in Azure must match. It is possible that a colleague could have changed the key in one of the locations causing the connection to fail.
You should not change the Origin response timeout (in seconds). This particular setting relates to Azure Front Door only. Changing the origin response timeout default settings is a valid troubleshooting step if you are faced with 503 error responses via Azure Front Door. 503 error codes are HTTP response codes that indicate that a web service is running as expected but, for whatever reason, the request could not be processed properly. This can often be a generic message and additional troubleshooting steps are required to resolve the issue.

You should not verify that the Provider status is showing as Provisioned. This is only a valid step for verifying Express Route circuits. Customers can work with connectivity providers to connect their on- premises networks to Azure. The two choices are Express Route connectivity provider or cloud exchange providers.
You should not check whether Border Gateway Protocol (BGP) is enabled on the virtual network gateway. BGP is an optional feature for VPN gateways that allows network routes to be advertised between Azure and on-premises networks. The on-premises routing device will also require BGP compatibility for this to work effectively. Enabling BGP will not allow an Azure administrator to effectively troubleshoot a site-to-site VPN connection.

---

### References

[Troubleshooting: An Azure site-to-site VPN connection cannot connect and stops working](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-troubleshoot-site-to-site-cannot-connect)

[Troubleshoot Azure Front Door common issues](https://learn.microsoft.com/en-us/azure/frontdoor/troubleshoot-issues)

[Verifying Express Route connectivity](https://learn.microsoft.com/en-us/azure/expressroute/expressroute-troubleshooting-expressroute-overview)  

[About BGP and VPN Gateway](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-bgp-overview)



---

## Q052:

Your customer needs to connect their on-premises network to their Azure subscription.
The customer's Azure subscription currently has a single Virtual Network (VNet). They would like a site-to- site VPN connection and they will handle the on-premises network configuration.
You need to configure the Azure site-to-site VPN tunnel and prove that it functions as expected.
Which four actions should you perform in sequence to meet the requirement with the least administrative effort? To answer, move the appropriate actions from the list of possible actions to the answer area and arrange them in the correct order.

Create a list in the correct order

Possible actions

Generate a root certificate.
Verify that 'Enabled' is showing under circuit status.
Download and configure the Azure VPN client.

Actions in order
Deploy and configure a Virtual Network Gateway and Local Network Gateway.
Instruct the customer to configure the on-premises VPN device and provide the shared key.
Create a VPN connection within the Virtual Network Gateway settings.
Connect to an Azure virtual machine from the on-premises network.

---

### Answer:

First, you should deploy and configure a Virtual Network Gateway and Local Network Gateway. As a VNet already exists in the subscription, there is no need to create a new one. A gateway needs to be created first, which will allow you to progress with the other steps. A Local Network Gateway is required in Azure as it references the on-premises network and allows Azure to communicate with the on-premises specified address ranges.
Next, you should instruct the customer to configure the on-premises VPN device and provide the shared key. Before a tunnel can be configured, the on-premises team must configure the on-premises VPN device. A shared key will also need to be created, which must be identical in Azure and on the on-premises VPN device.
Then, you should create a VPN connection within the Virtual Network Gateway settings. A VPN connection can only be created once the local network gateway and a shared key has been established.
Finally, you should connect to an Azure virtual machine from the on-premises network. The requirement states that you need to prove that the VPN tunnel works. Connecting to a virtual machine from the on- premises network is the best way to prove connectivity.
You should not generate a root certificate. This is used for point-to-site VPN connections only. When configuring a point-to-site VPN connection, you must upload the public key for a root certificate to Microsoft Azure. This ensures that the certificate will then be trusted for any point-to-site connectivity.
You should not download and configure the Azure VPN client. This is used for point-to-site VPN connections only.
You should not verify that 'Enabled' is showing under circuit status. This connection status is only a valid option for Express Route connections. Express Route is used to connect on-premises networks to Azure directly over a private connection.

---

### References

[Tutorial: Create a site-to-site VPN connection in the Azure portal](https://learn.microsoft.com/en-us/azure/vpn-gateway/tutorial-site-to-site-portal)  

[About Point-to-Site VPN](https://learn.microsoft.com/en-us/azure/vpn-gateway/point-to-site-about)

[Verify Express Route connectivity](https://learn.microsoft.com/en-us/azure/expressroute/expressroute-troubleshooting-expressroute-overview)  

---

## Q051:

You work at a company that has an Azure Virtual Network and an on-premises environment.
You need to allow the virtual network to communicate with the on-premises environment over the public internet while maintaining encryption.

Which solution should you use?

Choose the correct answer

- Azure VPN gateway
- Application security groups
- Azure Private Link
- Azure AD Application Proxy

---

### Answer:
- Azure VPN gateway

You should use an Azure VPN gateway to allow the virtual network to communicate with the on-premises environment. A Virtual Private Network (VPN) gateway is a solution provided by Azure that uses site-to-site VPN to connect virtual networks with on-premises networks. It sends traffic between Azure and the on- premises network over a public internet connection. Using a site-to-site VPN connection enables you to achieve traffic encryption when the connection is established between the virtual network and the on- premises environment. To add a VPN gateway connection, you should access the Azure portal, and navigate to the Virtual network gateways page, where you can create a new VPN gateway.
You should not use application security groups. Application security groups are used for configuring network security, but will not enable your virtual network to connect to the on-premises environment.
You should not use an Azure Active Directory (AD) Application Proxy. This service can be used by a company to publish on-premises applications to networks outside the company.
You should not use Azure Private Link. Azure Private Link provides private access from an Azure virtual network to Platform as a Service (PaaS) services and Microsoft Partner services in Azure. Azure Private Link cannot be used to connect virtual networks to on-premises environments.

---

### References

[Tutorial: Create and manage a VPN gateway using the Azure portal](https://learn.microsoft.com/en-us/azure/vpn-gateway/tutorial-create-gateway-portal)  

[Application security groups](https://learn.microsoft.com/en-us/azure/virtual-network/application-security-groups)

[Microsoft Entra application proxy documentation](https://learn.microsoft.com/en-us/entra/identity/app-proxy/)  

What is Azure VPN Gateway?
What is Azure pRIVATE lINK?

---

## Q050:

You plan to integrate your on-premises database server to Azure via an S2S VPN tunnel.
The on-premises VPN gateway supports specific IKE Phase 1 and IKE Phase 2 algorithms. You configured these parameters via the custom policy under the VPN gateway connection configuration. The VPN tunnel is still not able to get established between the Azure VPN gateway and the on-premises VPN device. You have already verified the IP information on the local VPN device, the VPN device IP/FQDN address on the Azure Local Network Gateway, and that the IKE Phase 1 and IKE Phase 2 information is configured correctly.
You need to identify the next troubleshooting steps to fix the issue.
Which three steps should you identify? Each correct answer presents part of the solution.

Choose the correct answers

- Verify the Shared Key.
- Reset the VPN Gateway.
- Reset the VPN Connection.
- Change the Virtual Network Gateway SKU.
- Change the Virtual Network Gateway type.


---

### Answer:

- Verify the Shared Key.
- Reset the VPN Gateway.
- Reset the VPN Connection.

When you reset the Virtual Private Network (VPN) Gateway, it will help to reboot the Active instance of the gateway. If this does not work, you should then reset the VPN Gateway again. This time, it will reset the standby instance also and will failover to the active instance. Note that the Azure VPN Gateway uses two instances that run an Active/Standby mode. When you simply reset the VPN connection, the VPN tunnel is disconnected and the connection is re-established. The VPN gateway is not rebooted in this operation. Lastly, you must ensure that you use the same pre-shared key on both Azure VPN Gateway and the on- premises VPN device.
You should not change the Virtual Network Gateway type. The Virtual Network Gateway type option is used to define the role of the gateway. You can either define VPN or Express Route. As the type is already set to VPN, you do not need to modify it to Express Route.
You should not change the Virtual Network Gateway SKU. You can select different virtual network gateway SKUs depending on your requirements for the number of IPSec tunnels and the throughput. In the current scenario, the gateway SKU selection is fine as you are troubleshooting the problem with basic VPN connectivity.

---

### References


[Troubleshooting: An Azure site-to-site VPN connection cannot connect and stops working](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-troubleshoot-site-to-site-cannot-connect)  

[Reset a VPN gateway or a connection](https://learn.microsoft.com/en-us/azure/vpn-gateway/reset-gateway)  

What is Azure VPN Gateway?

---

## Q049:

You plan to integrate your local network resources to Azure via an S2S VPN tunnel. You have already configured the Virtual Network Gateway, the Local Network Gateway and the Gateway Subnet on the Azure portal.
You need to configure the on-site VPN device so the VPN connection can be established.
Which three configuration items should you use? To answer, move the appropriate configuration item from the list of Configuration entities to the answer area and arrange them in any order.

Create a list in any order

Configuration entities

Virtual Network Gateway
Local Network Gateway

Configuration required for on-site VPN

VPN shared key
Public IP address of the VPN Gateway
VPN device configuration script

---

### Answer:

You should use the following items to configure the on-site Virtual Private Network (VPN) device:

- VPN shared key
- Public IP address of the VPN Gateway
- VPN device configuration script

The VPN shared key is the same key that you configured on the Virtual Network Gateway. First, you must ensure the same shared key is configured on the on-site VPN device and the Azure Virtual Network Gateway or the connection will not establish. Then, you need to get the Azure Virtual Network Gateway Public IP and configure the same on the on-site VPN device for the remote gateway. Lastly, you will need to download the VPN device configuration script. Azure provides device specific configuration for different vendors, which you can use to configure the local VPN device.
You should not use Virtual Network Gateway. The Virtual Network Gateway entity is needed on the Azure portal to configure a virtual VPN gateway that connects to your local VPN device. The Virtual Network Gateway is created inside the Gateway Subnet and there you can define the VPN type, the Gateway type and VPN SKU you are planning to use.
You should not use the Local Network Gateway item. The Local Network Gateway is a representation of the on-premises network and defines the VPN device access IP or FQDN and the private address space you would like to route from Azure to the local VPN device.

---

### References

[Tutorial: Create a site-to-site VPN connection in the Azure portal](https://learn.microsoft.com/en-us/azure/vpn-gateway/tutorial-site-to-site-portal)  

[Download VPN device configuration scripts for S2S VPN connections](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-download-vpndevicescript)  

---

## Q048:

An organization has connected its branch office via a site-to-site VPN connection to Azure VPN gateway.
They plan to change the branch office network address prefixes. They will also need to apply the prefix changes on Azure in order to use and access the Azure resource via the VPN tunnel and vice versa.
What should you configure in the Azure portal to meet the requirements?
Choose the correct answer

- GatewaySubnet
- Virtual Network Gateway
- Local Network Gateway
- Virtual Network

---

### Answer:
- Local Network Gateway

You should configure the Local Network Gateway in the Azure portal to update the new local network address prefix changes. The Local Network Gateway entity is used to configure the on-site VPN device public IP address and the local network prefix addresses. It is possible to edit the configuration after the entity is created.
You should not configure the Virtual Network Gateway in the Azure portal to update the new local network address prefix changes. The Virtual Network Gateway entity is the cloud VPN device in the Azure portal, which will establish the VPN tunnel with the on-premises VPN device.
You should not configure the Gateway Subnet in the Azure portal to update the new local network address prefix changes. The Gateway Subnet must be created for the VPN Gateway, and it contains the resources that will be used by the virtual network gateway resources and services.
You should not configure the Virtual Network in the Azure portal to update the new local network address prefix changes. The Azure virtual network provides the address space in a Classless Inter-Domain Routing (CIDR) block, which can be used to create different subnets.

---

### References

[Tutorial: Create a site-to-site VPN connection in the Azure portal](https://learn.microsoft.com/en-us/azure/vpn-gateway/tutorial-site-to-site-portal)  

[What is Azure VPN Gateway?](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-vpngateways)  

[About VPN Gateway configuration settings](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-vpn-gateway-settings)  

[Understanding CIDR Notation when designing Azure Virtual Networks and Subnets](https://devblogs.microsoft.com/premier-developer/understanding-cidr-notation-when-designing-azure-virtual-networks-and-subnets/)  

---

## Q047:

Your company migrated its infrastructure from on-premises to the cloud six months ago when you deployed multiple network security services including segmenting the virtual network, deploying an Azure Firewall, and disabling insecure protocols to mitigate threats.
The Head of Cloud Security has recommended a review of network security within the Azure tenant via Defender for Cloud to increase the security posture of the environment. They have recommended you to complete the NS-2 security control: Secure cloud services with network controls.
You need to configure the Azure Service as per the Microsoft Guidance to complete this security control.
Which Azure Service should you configure within your tenant to meet this security control?

Choose the correct answer

- Network Security Groups (NSGS)
- DDoS Protection
- Application Security Groups (ASGS)
- Private Endpoints

---

### Answer:

- Private Endpoints

You should configure Private Endpoints on the Azure services that support this to meet the NS-2 security control. The Azure guidance in the Defender for Cloud portal for NS-2 recommends deploying private endpoints for all Azure resources that support the Private Link feature, to establish a private access point for the resources.
You should not configure DDoS Protection on the Azure services. Enabling DDoS protection on your virtual network is covered within NS-5 security control: Deploy DDOS protection. The Azure guidance in the Defender for Cloud portal for NS-5 is to enable DDoS Network Protection plan on your VNet to protect resources that are exposed to the public networks.
You should not configure either Network Security Groups (NSGs) or Application Security Groups (ASGs) on Azure services. The NSG is a network layer control to restrict or monitor traffic by port, protocol, source IP
address, or destination IP address whereas the ASG allows you to configure network security as a natural extension of an application's structure, allowing you to group virtual machines and define network security policies based on those groups. Both of these configurations fall under the NS-1: Establish network segmentation boundaries security control which has already been implemented when the company initially migrated to Azure.

---

### References

[Secure score in Defender for Cloud](https://learn.microsoft.com/en-us/azure/defender-for-cloud/secure-score-security-controls)  

[Review security recommendations](https://learn.microsoft.com/en-us/azure/defender-for-cloud/review-security-recommendations)   

[Security recommendations](https://learn.microsoft.com/en-us/azure/defender-for-cloud/plan-multicloud-security-get-started)

[Get network security recommendations with Microsoft Defender for Cloud](https://learn.microsoft.com/en-us/training/modules/design-implement-network-security-monitoring/2-secure-your-virtual-networks-azure-portal)

---

## Q046:

Your company hosts its applications and infrastructure in Azure. There has been a recent attempt of distributed denial-of-service (DDoS) attack on your tenant, however the Firewall was able to prevent any major degradation in performance.
The Security Architect has created a new Azure DDoS protection plan named Ddos Protection PlanA to help mitigate this type of attack in the future and to ensure there is more defense against DDoS attacks. However, it is not enabled on the virtual network.
You need to use PowerShell to enable DDoS protection on the existing virtual network in your Azure tenant.
Which cmdlets should you use? To answer, select the appropriate options from the drop-down menus.

Choose the correct options

OPTIONS: 
Set-AzVirtualNetwork | Get-AzVirtualNetwork
New-AzDdosProtection | Get-AzDdosProtection

```
$ddosProtectionPlanID = OPTION-1 Plan -ResourceGroupName RG-A-Name Ddos ProtectionPlanA

$vnet = OPTION-2 -Name VNetA -ResourceGroupName RG-A

$vnet.DdosProtectionPlan New-Object Microsoft.Azure.Commands.Network.Models. PSResourceId

$vnet.DdosProtectionPlan. Id = $ddosProtectionPlanID. Id

$vnet.EnableDdosProtection = $true

$vnet | OPTION-3

```

```
$ddosProtectionPlanID = Get-AzDdosProtection Plan -ResourceGroupName RG-A-Name Ddos ProtectionPlanA

$vnet = Get-AzVirtualNetwork -Name VNetA -ResourceGroupName RG-A

$vnet.DdosProtectionPlan New-Object Microsoft.Azure.Commands.Network.Models. PSResourceId
$vnet.DdosProtectionPlan. Id = $ddosProtectionPlanID. Id
$vnet.EnableDdosProtection = $true
$vnet | Set-AzVirtualNetwork

```

---

### Answer:

You should complete the code as follows:

```
$ddosProtectionPlanID = Get-AzDdosProtectionPlan -ResourceGroupName RG-A-Name Ddos ProtectionPlanA
$vnet Get-AzVirtualNetwork -Name VNetA -ResourceGroupName RG-A
$vnet. DdosProtection Plan = New-Object
Microsoft.Azure.Commands.Network.Models. PSResourceId
$vnet. Ddos ProtectionPlan. Id = $ddosProtectionPlanID.Id
$vnet.EnableDdosProtection $true
$vnet Set-AzVirtualNetwork
```

This PowerShell script will configure a new DDoS protection plan on an existing virtual network. You first need to use the Get-AzDdos Protection Plan. This will retrieve a DDosS Protection plan ID.
You then need to use the Get-AzVirtual Network cmdlet to retrieve up-to-date information on the existing virtual network in the resource group you specify.
Finally, you need to use the Set-AzVirtual Network to update the properties of the virtual network and complete the task of enabling the DDoS Protection plan within it.
You should not use the New-AzDdos Protection Plan, as this is used to create a new DDoS Protection plan. In the scenario, the Security Architect has already created the DDoS Protection plan, therefore you need to enable an existing one with the virtual network rather than create a new plan.

---

### References

[QuickStart: Create and configure Azure DDoS Network Protection using the Azure portal](https://learn.microsoft.com/en-us/azure/ddos-protection/manage-ddos-protection)  

[QuickStart: Create and configure Azure DDoS Network Protection using Azure PowerShell](https://learn.microsoft.com/en-us/azure/ddos-protection/manage-ddos-protection-powershell)

[What is Azure DDoS Protection?](https://learn.microsoft.com/en-us/azure/ddos-protection/ddos-protection-overview)  

Set-AzVirtualNetwork 
Get-AzVirtualNetwork
New-AzDdosProtection 
[Get-AzDdosProtection](https://learn.microsoft.com/en-us/powershell/module/az.network/get-azddosprotectionplan?view=azps-12.1.0&viewFallbackFrom=azps-11.5.0)  

---

## Q045:

Your organization hosts its applications and infrastructure in Azure. They spread across multiple regions. including Italy North, West Europe, and UK South.
You have recently implemented a site-to-site VPN configuration between the UK South region and a new office that has opened in Manchester. During the initial testing, you were able to connect to virtual machines (VMs) hosted in the UK South region in your tenant from the Manchester office.
The Dev team has recently deployed a Linux server they are using to test a new application that they host on-premises, however they are unable to make a connection from the server. You are tasked with reviewing the configuration and troubleshoot the issue to find a resolution. You diagnose that a security rule on the NSG attached to the VM network card is the possible cause of the issue.
You need to use Network Watcher to confirm your diagnosis.

What feature should you use?

Choose the correct answer

- Next Hop
- IP Flow verify
- Packet Capture
- VPN Troubleshoot

---

### Answer:
- IP Flow verify

You should use the IP Flow verify to confirm your diagnosis. This feature allows you to diagnose connectivity issues from or to the internet and from or to the on-premises environment. An example of this is confirming if a security rule is blocking ingress or egress traffic to or from a virtual machine (VM) as in this scenario.
You should not use the Next Hop feature. This feature allows you to check if traffic is being directed to the intended destination by showing the next hop.
You should not use the Packet Capture feature. This feature enables you to create packet capture sessions to track traffic to and from a VM and helps to diagnose network anomalies both reactively and proactively. In this scenario, a NSG rule is causing the issue, therefore Packet Capture would not able to identify any NSG rule.
You should not use the VPN Troubleshoot feature. This feature allows you to troubleshoot gateways and connections to on-premises locations.

---

### References

[What is Azure Network Watcher?](https://learn.microsoft.com/en-us/azure/network-watcher/network-watcher-overview)

[Network insights](https://learn.microsoft.com/en-us/azure/network-watcher/network-insights-overview)

[Monitor your networks using Azure network watcher](https://learn.microsoft.com/en-us/training/modules/design-implement-network-monitoring/4-monitor-networks-using-azure-network-watcher)    

---

## Q044:

You plan to deploy an Azure virtual network for your company. You start designing the subnets by adding a load balancer.
You are tasked with adding a service that enables the company to connect its virtual machines through Remote Desktop Protocol (RDP) over Secure Sockets Layer (SSL) directly from the Azure site.
You need to find a solution to meet the requirements.

Which service should you use?
Choose the correct answer

- Azure Databricks
- Azure Front Door
- Azure Bastion
- RADIUS server

---

### Answer:
- Azure Bastion


You should use Azure Bastion. The Azure Bastion service is a fully managed PaaS service that you can deploy within your virtual network, It allows you to connect to your virtual machines through Remote Desktop Protocol/Secure Shell (RDP/SSH) over Secure Sockets Layer (SSL) directly from the Azure site.
You should not use a RADIUS server. Remote Authentication Dial-In User Service (RADIUS) is a network protocol that protects a network by allowing centralized dial-in user authentication and authorization.
You should not use Azure Front Door. This solution is used to elevate the global routing of your web, but cannot be used to connect virtual machines through RDP/SSH over SSL directly from the Azure site.
You should not use Azure Databricks. This service is a data analytics platform that contains applications related to Structured Query Language (SQL), data science, and machine learning. This solution cannot be used to connect virtual machines through RDP/SSH over SSL directly from the Azure site.

---

### References

[What is Azure Bastion?](https://learn.microsoft.com/en-us/azure/bastion/bastion-overview?toc=%2Fazure%2Fvirtual-network%2Ftoc.json)  

[RADIUS authentication with Azure Active Directory](https://learn.microsoft.com/en-us/entra/architecture/auth-radius)  

[What is Azure Front Door?](https://learn.microsoft.com/en-us/azure/frontdoor/front-door-overview)  

[What is Azure Databricks?](https://learn.microsoft.com/en-us/azure/databricks/introduction/?toc=%2Fazure%2Fvirtual-network%2Ftoc.json)  

---

## Q043:

![image info](./Q43_1.PNG)
![image info](./Q43_2.PNG)

Your organization has an existing hub and spoke network topology deployed within its Azure environment, as shown in Exhibit A.
The company has decided to host a new enterprise application in Azure which requires a mesh network topology, as shown in Exhibit B. You use the connectivity configuration in Azure Virtual Network Manager to deploy the mesh network and manage the hub and spoke network moving forward.
You need to configure the virtual networks to allow them to communicate with each other.
Which connectivity construct should you use to configure communication between the virtual networks?

Choose the correct answer

- Connected Group
- Direct Connectivity
- Network Peering
- Site-to-Site VPN

---

### Answer:

- Connected Group

When you create a mesh network topology with Azure Virtual Network Manager, it creates a connectivity construct named Connected Groups. Virtual networks within a connected group are able to communicate with each other in the same way manually connected networks communicate with each other. Connected Groups do not have a peering configuration which is normally listed under 'Peerings' of the virtual network.
Virtual network peering allows you to connect two or more virtual networks together in Azure. Traffic in networks which are virtual peered uses the Microsoft backbone infrastructure. This is the connectivity construct used in Hub and Spoke network topologies, however this is not used with Mesh networks when configuring the topology via Azure Network Manager.
The VPN Gateway is an Azure service that is used to connect virtual networks hosts in Azure with networks hosted in on-premises locations like data centers. It allows you to send encrypted traffic between the Azure hosted virtual network and on-premises locations, however it is not used to connect/peer virtual networks to other virtual networks.
Direct connectivity is used within hub and spoke topology network configurations where an overlay of a connected group is created on top of your topology. It allows a spoke virtual network to communicate directly to other virtual networks in its group, but no virtual networks in other spokes.

---

### References

[Azure Virtual Network Manager documentation](https://learn.microsoft.com/en-us/azure/virtual-network-manager/)  

[Connectivity configuration in Azure Virtual Network Manager](https://learn.microsoft.com/en-us/azure/virtual-network-manager/concept-connectivity-configuration) 

[Virtual network peering](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-peering-overview)  

[What is Azure VPN Gateway?](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-vpngateways)   

---

## Q042:

Your company has an Azure tenant with one virtual network (VNet). You have deployed an Azure NAT gateway called NAT-01. An Azure virtual machine named VM-01 has been deployed to the VNet. An unused public IPv4 address with a standard SKU was also deployed to the subscription.
An external virtual machine named VM-02 is hosted by a third party and needs to communicate with VM-01.
You need to analyze the current configuration and confirm whether it is compatible with this requirement.
For each of the following statements, select Yes if the statement is true. Otherwise, select No.

The existing public IP address can be assigned to NAT-01.
Yes

VM-02 can initiate a connection with VM-01.
No

VM-01 can send ICMP packets to VM-02.
No

---

### Answer:

The existing public IP address can be assigned to NAT-01. Public IP addresses with a Standard Stock- keeping Unit (SKU) or IP prefixes are compatible with an Azure Network Address Translation (NAT) gateway. Azure Virtual Network NAT ensures that virtual machines in an Azure virtual network (VNet) can communicate to external services using the NAT gateway's public IP address. This saves administrators assigning the virtual machines a public IP address, which would increase the security threats in an environment. IP addresses with a basic SKU cannot be configured with NAT gateway.
The external VM cannot initiate a connection with VM-01. With an Azure NAT gateway, the traffic must originate from VM-01. VM-02 does not have the ability to initiate a connection with VM-01. It can only communicate back to VM-01 via a NAT gateway, if it is already engaged in an active flow.
VM-01 cannot send ICMP packets to VM-02. Only TCP and UDP network packets can be transferred across a NAT gateway. For example, if an Azure virtual machine needs to contact an external API on port 80 (HTTP), Azure NAT can be used to support this scenario. ICMP is not a supported protocol.

---

### References

[What is Azure NAT Gateway?](https://learn.microsoft.com/en-us/azure/nat-gateway/nat-overview)  

---

## Q041:

Your company has an Azure tenant with one virtual network (VNet). A production virtual machine has been configured in one of the subnets.
You need to configure outbound IP connectivity from the virtual machine to an external HTTP API. The solution must minimize costs.

What solution should you recommend?

Choose the correct answer

- Deploy an internal Azure load balancer to the virtual network (VNet).
- Configure Azure Private Link.
- Configure Azure Virtual Network Address Translation (NAT).
- Configure Azure Firewall.


---

### Answer:
- Configure Azure Virtual Network Address Translation (NAT).

You should configure Azure Virtual NAT. A NAT gateway can be used to forward traffic from private Azure resources to external services. This can be done by linking the NAT gateway to subnets. When NAT is configured, it uses Source Network Address Translation (SNAT) to translate private IP addresses in an Azure network to a static public IP Address. This allows private IP addresses to communicate with public hosts using the internet. When Azure Virtual NAT has been deployed and configured, outbound connectivity is automatically managed, without the need for additional configuration or user defined routes (UDR). This would be the recommended solution as it minimizes costs and would fulfill the requirement.
You should not configure Azure Firewall. Azure Firewall is a fully stateful Firewall as a Service (FWaaS) and provides SNAT automatically for all outbound connectivity. SNAT essentially translates all outbound network traffic to the Azure Firewall public IP address. However, this would not meet the requirement as it is not the most cost-effective solution. Azure Firewall is costly in comparison to the other answer choices provided.
You should not configure Azure Private Link. Private links are commonly used to protect access to Azure Platform as a Service (PaaS) services. For example, if you created a storage account that can only be accessed from an on-premises network, then you would utilize Azure Private Link.
You should not deploy an internal Azure Load Balancer to the virtual network (VNet). Azure Load Balancers operate at layer 4 of the Open Systems Interconnection (OSI) model. An internal Azure load balancer is used to distribute traffic to a group of Azure resources or servers. An internal load balancer will only distribute traffic to resources in the Azure VNet and will not allow external outbound connectivity.

---

### References

[Azure NAT Gateway resource](https://learn.microsoft.com/en-us/azure/nat-gateway/nat-gateway-resource)  

[Azure Firewall SNAT private IP address ranges](https://learn.microsoft.com/en-us/azure/firewall/snat-private-range)  

What is Azure Firewall?
What is Azure Private Link?
Azure Firewall pricing
Virtual Network pricing
Virtual network traffic routing
What is Azure Load Balancer?

---

## Q040:

You are an Azure administrator for an insurance company. You have successfully established a Site-to-Site (S2S) VPN tunnel from the on-premises network to Azure. The on-premises network address space is 10.0.0.0/24. In Azure, there is one virtual network (VNet) with three subnets named Gateway Subnet, application, and database.
You need to force internet-bound traffic from the database subnet back to on-premises for auditing and inspection.

What should you do?

Choose the correct answer

- Create a route table, add a user-defined route for 0.0.0.0/0 with the next hop type as None, and associate the route table to the database subnet.

- Create a route table, add a user-defined route for 10.0.0.0/24 with the next hop type as Virtual network gateway, and associate the route table to the database subnet.

- Create a route table, add a user-defined route for 0.0.0.0/0 with the next hop type as Internet, and associate the route table to the GatewaySubnet.

- Create a route table, add a user-defined route for 0.0.0.0/0 with next hop type as Virtual network gateway, and associate the route table to the database subnet.

---

### Answer:

- Create a route table, add a user-defined route for 0.0.0.0/0 with next hop type as Virtual network gateway, and associate the route table to the database subnet.


You should create a route table, add a user defined route for 0.0.0.0/0 with the next hop type as Virtual network gateway, and associate the route table to the database subnet. The address prefix 0.0.0.0/0 will direct all traffic. The requirement states that all internet-bound traffic needs to traverse from the on-premises network first. Choosing the next hop type as virtual network gateway will force traffic to the VPN gateway and back to on-premises. The traffic that requires redirection is based in the database subnet, and thus the route should be associated in this subnet only.
You should not create a route table, add a user defined route for 10.0.0.0/24 with the next hop type as Virtual network gateway, and associate the route table to the database subnet. The address space 10.0.0.0/24 refers to the on-premises network. This will not encapsulate internet-bound traffic.
You should not create a route table, add a user defined route for 0.0.0.0/0 with the next hop type as
Internet, and associate the route table to the Gateway Subnet. If the routing rule is associated to the
Gateway Subnet it will not be able to redirect traffic from the database subnet, which is the key requirement
highlighted in the scenario.
You should not create a route table, add a user defined route for 0.0.0.0/0 with the next hop type as None,
and associate the route table to the database subnet. Choosing the next hop type as None will essentially
drop all the network traffic in this instance. This is the opposite of what needs to be achieved.

---

### References

[Virtual network traffic routing](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-udr-overview)  

---

## Q039:

![image info](./Q39_1.PNG)


Your organization recently acquired two new companies: Skrul Tech and Jinsey Electrics. As part of the merge, you were asked to connect the two virtual networks (VNets) to the parent hub VNet.
Please refer to the exhibit for the current Azure VNet configuration. Jinsey Electrics employees now need to connect to resources located on-premises but are unable to do so.
You need to allow Jinsey Electrics employees to connect to on-premises resources. The solution must be cost-effective. Which solution should you provide?
Choose the correct answer
Deploy a Network Virtual Appliance (NVA) in the Hub VNet and configure User-Defined Routes (UDR).
Deploy an Azure Firewall in the Hub VNet and configure User-Defined Routes (UDR).
Configure a User-Defined Route (UDR) from the Jinsey Electrics subnet to route traffic to the on-premises network.
Enable Use the remote virtual network's gateway property on the VNet peering connection.

---

### Answer:

You should enable Use the remote virtual network's gateway property on the VNet peering connection. The exhibit currently shows VNet peering as configured from both spoke VNets to the hub VNet. The reason why Jinsey Electrics employees cannot access on-premises resources is that traffic is currently prohibited along this route. Modifying the VNet peering and utilizing the remote virtual network gateway allows traffic to traverse via the VPN gateway to on-premises.
You should not deploy an Azure Firewall in the Hub VNet and configure UDR. Azure Firewall can technically be deployed in the Hub VNet and it can be used to route traffic back to the on-premises network. This does not meet the requirement of being cost-effective. Azure Firewall will impose additional monthly costs.
You should not deploy a NVA in the Hub VNet and configure User Defined Routes. This option is an alternative to using Azure Firewall. While it is technically possible to route traffic from the spoke VNets back to on-premises via an NVA, it does not meet the cost-effectiveness requirement.
You should not configure a UDR from the Jinsey Electrics subnet to route traffic to on-premises. The current
deployment highlighted in the exhibit will not allow traffic to traverse via the VPN gateway to the 
on-premises network. The VNet peering connection from the spoke needs to be modified to use the remote virtual network gateway.

---

### References

[Configure VPN gateway transit for virtual network peering](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-peering-gateway-transit)   

[Deploy and configure Azure Firewall in a hybrid network using Azure PowerShell](https://learn.microsoft.com/en-us/azure/firewall/tutorial-hybrid-ps)  

[Deploy highly available NVAS](https://learn.microsoft.com/en-us/azure/architecture/networking/guide/nva-ha)  

[virtual network traffic routing](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-udr-overview)    

[Tutorial: Route network traffic with a route table using the Azure portal](https://learn.microsoft.com/en-us/azure/virtual-network/tutorial-create-route-table-portal)  

---

## Q038:

You plan to configure your VNET for the middle tier of the web application that is not reachable from the public internet.
You need to configure a private address space for the middle tier VNET.
Which three private RFC 1918 IP address ranges should you use? Each correct answer presents a complete solution.

Choose the correct answers

172.16.0.0/12
192.168.0.0/16
10.0.0.0/8
172.15.0.0/24
192.167.0.0/24
224.0.0.0/4

---

### Answer:

172.16.0.0/12
192.168.0.0/16
10.0.0.0/8

You should use the following private RFC 1918 IP address ranges for the configuration of your VNET Address space:

10.0.0.0/8
172.16.0.0/12
192.168.0.0/16

As a best practice, Azure virtual resources (for example, virtual machines) should always be configured in an RFC 1918 private IP subnet. The IP address assignment will be controlled by Azure DHCP, which will lease the IPs as per the assigned subnet. The private IP address space is non-routable and cannot be used on the public internet.

You should not use the following:

192.167.0.0/24
172.15.0.0/24

These do not cover the complete range of the private RFC 1918 IP address space and just denote the public internet subnet range.
You should not use the 224.0.0.0/4 address range. It denotes the CIDR notation for the multicast address group. The complete range of addresses covered by this block is 224.0.0.0 to 239.255.255.255. Multicast addresses are used to send traffic to a group of devices, for example, a group of nodes that will listen to the multicast address. You should not use this address space as it does not cover the RFC 1918 IP address space required.

---

### References

[Azure Virtual Network concepts and best practices](https://learn.microsoft.com/en-us/azure/virtual-network/concepts-and-best-practices)  

[RFC1918 Private Address Space](https://datatracker.ietf.org/doc/html/rfc1918)  

[IP Multicast Addressing](http://www.tcpipguide.com/free/t_IPMulticastAddressing.htm)  

---

## Q037:

![image info](./Q37_1.PNG)

Your company has the Azure virtual network (VNet) shown in the Network Architecture exhibit.
Your manager wants to share a single IPv4 address with two VMs located at a subnet level.
You need to implement a solution that meets the requirement.

What solution should you use?
Choose the correct answer

- Azure Bastion
- Application Proxy
- ExpressRoute Direct
- A NAT gateway

---

### Answer:
- A NAT gateway

You should use a NAT gateway to share a single IPv4 address with two VMs located at a subnet level. A Network Address Translation (NAT) gateway is a solution provided by Azure that enables you to establish an outbound connection to the internet on a subnet level where you can attach the two VMs to a single IPv4 address. A NAT gateway can also be used to map a range of IP addresses, defined by an IP prefix, to internal resources.
You should not use Express Route Direct. Express Route Direct is used to connect you directly to the global network of Microsoft, but cannot be used to share a single IPv4 address with two VMs located at a subnet level.
You should not create an Application Proxy. This solution can be used to publish on-premises applications to networks outside the company.
You should not use Azure Bastion. The Azure Bastion service is a fully managed PaaS service that you can deploy within your virtual network. It allows you to connect to your virtual machines through Remote Desktop Protocol/Secure Shell (RDP/SSH) over Secure Sockets Layer (SSL) directly from the Azure site.

---

### References

[What is Azure NAT Gateway?](https://learn.microsoft.com/en-us/azure/nat-gateway/nat-overview)  

[About ExpressRoute Direct](https://learn.microsoft.com/en-us/azure/expressroute/expressroute-erdirect-about)  

[Microsoft Entra application proxy documentation](https://learn.microsoft.com/en-us/entra/identity/app-proxy/) 

[What is Azure Bastion?](https://learn.microsoft.com/en-us/azure/bastion/bastion-overview?toc=%2Fazure%2Fvirtual-network%2Ftoc.json)   

---

## Q036:

You have an Azure virtual network (VNet) that includes three separate subnets named SubnetA, SubnetB, and SubnetC. The subnets are configured as follows:
SubnetA contains a webserver.
SubnetB contains an API server.
SubnetC contains a Network Virtual Appliance (NVA).
You need to redirect the traffic from the webserver to a NVA and then to the API server.
What solution should you use?

Choose the correct answer

- Standard Load Balancer
- User-defined route
- Network security group (NSG)
- Application Gateway

---

### Answer:
- User-defined route

You should use a user-defined route (UDR) to direct the traffic from the webserver to a Network Virtual Appliance (NVA) and then to the API server. UDR is an Azure service that enables you to create and control network routes where your NVA can manage the traffic between separate subnets and direct them to the internet. When the traffic routes from the webserver to the NVA, through UDR, the firewall within the NVA will determine whether this traffic should be allowed or denied from being routed to the Application Programming Interface (API) server.
You should not use a network security group (NSG). A NSG is an Azure service that enables you to secure the premises of your network against threats. This inspects traffic and has the ability to allow or deny traffic from accessing a network packet.
You should not use a Standard Load Balancer. A Standard Load Balancer enables you to load balance protocol flows on all ports when using an internal load balancer through High Availability ports, but cannot be used to direct traffic.
You should not use Application Gateway. An application gateway is a load-balancing solution that is used to
load balance between servers at an application level. Application Gateway operates at layer 7 of the OSI model. The usage of an application gateway is beneficial in case you need to protect and secure the traffic sent and received by your app.

---

### References

[How to Configure Azure Route Tables (UDR) using Azure Portal and ARM](https://campus.barracuda.com/product/cloudgenfirewall/doc/170819589/overview)  

[Virtual network traffic routing](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-udr-overview)  

[What is Azure Application Gateway?](https://learn.microsoft.com/en-us/azure/application-gateway/overview)  

[What is Azure Load Balancer?](https://learn.microsoft.com/en-us/azure/load-balancer/load-balancer-overview)

[Network security groups](https://learn.microsoft.com/en-us/azure/virtual-network/network-security-groups-overview)  

---

## Q035:

You plan to deploy a distributed application on Azure and some services require delegation to dedicated subnets.
You need to identify which Azure Network services must be deployed in their own dedicated subnet.

Which two services should you identify? Each correct answer presents a complete solution.

Choose the correct answers

- Application Gateway - Web Application Firewall (WAF)
- Azure Firewall
- Virtual machine scale sets
- Azure Active Directory Domain Services (Azure AD DS)
- Azure Kubernetes Service (AKS)

---

### Answer:

- Application Gateway - Web Application Firewall (WAF)
- Azure Firewall

You should identify Application Gateway - Web Application Firewall (WAF). The Azure Application Gateway is a layer 7 load balancer that you can use to manage the incoming traffic to your web applications. You need a dedicated subnet to deploy an Application Gateway WAF. WAF is a component of the Application Gateway that can be used to add a security layer to filter web traffic. You can configure different custom rules and can use Azure managed rules under WAF policies to protect your infrastructure. WAF can also provide protection against all the Open Web Application Security Project (OWASP) top 10 vulnerabilities and supports Core Rule Set (CRS) 3.1, 3.0, or 2.2.9.
You should also identify Azure Firewall. Azure Firewall is a fully-managed cloud firewall solution that you can use to configure L3-L7 security policies. Azure Firewall will have its own public IP and all the internal virtual instances will talk to the external network via the firewall. You must assign a dedicated subnet to the firewall and then use User Defined Routes (UDP) to route the traffic from the internal virtual resources to Azure Firewall using the Next hop type as Virtual appliance.
You should not identify Azure Active Directory Domain Services (AD DS). Azure AD DS can be deployed in a shared subnet with other resources. It provides an option to end users to configure their authentication
domains on the Azure cloud in order to move their legacy applications to Azure that cannot use modern authentication methods. Note that for Azure Active Directory Federation Services (ADFS) deployment, a dedicated subnet will be required.

You should not identify Azure Kubernetes Service (AKS). AKS can be deployed in a shared subnet with other resources. Kubernetes can be used for the orchestration and management of the containers.
You should not identify virtual machine scale sets. Azure virtual machine scale sets can be deployed in a shared subnet with other resources. Virtual machine scale sets can be used to create a highly available application by creating a group of virtual machine instances that will scale up and down as per the incoming traffic.


---

### References

[What is subnet delegation?](https://learn.microsoft.com/en-us/azure/virtual-network/subnet-delegation-overview)  

[What are virtual machine scale sets?](https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/overview)    

[What is Azure Kubernetes Service?](https://learn.microsoft.com/en-us/azure/aks/what-is-aks)    

[What is Azure Active Directory Domain Services?](https://learn.microsoft.com/en-us/entra/identity/domain-services/overview)  

[What is Azure Firewall?](https://learn.microsoft.com/en-us/azure/firewall/overview)   

[OWASP Top Ten](https://owasp.org/www-project-top-ten/)

[What is Azure Web Application Firewall on Azure Application Gateway?](https://learn.microsoft.com/en-us/azure/web-application-firewall/ag/ag-overview)    

[Deploy dedicated Azure services into virtual networks](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-for-azure-services)  

---

## Q034:

You plan to configure a route table for CompanyA's core subnet. The table contains the user-defined routes (UDR) to override the Azure default system route table.

The required route table entries will be:

- The BLOCK_SUB route entry is used to block the traffic for destination prefix 192.168.0.0/16.

- The VNET_SUB route entry is used to send the destination prefix 10.7.0.0/24 traffic to the internal private network.

- the VNET_SUB2 route entry is used to send the destination prefix 10.8.0.0/24 traffic to the internal private network.

- The INT_0000 route entry is used to send all remaining traffic to the internet.

You need to complete the table with the correct destination prefix and next-hop address type.
How should you complete the table? To answer, select the appropriate options from the drop-down menus.

Choose the correct options:

OPTION-1: 0.0.0.0/0 | 0.0.0.0/32

OPTION-2: None | Internet | VirtualNetwork


| Name       | Address prefix | Next hop type | Next hop IP address |
|------------|----------------|--------------|---------------------|
| BLOCK_SUB  | 192.168.0.0/16 | OPTION-2        | -                  |
| INT_0000   | OPTION-1      | OPTION-2     | -                  |
| VNET_SUB   | 10.7.0.0/24     | OPTION-2 | -                  |
| VNET_SUB2  | 10.8.0.0/24     | OPTION-2 | -                  |

| Name     | Address range | Virtual network | Security group |
|----------|---------------|-----------------|----------------|
| default  | 10.7.0.0/24   | VNET-1         | -              |
| default  | 10.8.0.0/24   | VNET-2         | -              |


> Table with the right selections;

| Name       | Address prefix | Next hop type | Next hop IP address |
|------------|----------------|--------------|---------------------|
| BLOCK_SUB  | 192.168.0.0/16 | None        | -                  |
| INT_0000   | 0.0.0.0/0      | Internet     | -                  |
| VNET_SUB   | 10.7.0.0/24     | Virtual network | -                  |
| VNET_SUB2  | 10.8.0.0/24     | Virtual network | -                  |

| Name     | Address range | Virtual network | Security group |
|----------|---------------|-----------------|----------------|
| default  | 10.7.0.0/24   | VNET-1         | -              |
| default  | 10.8.0.0/24   | VNET-2         | -              |


---

### Answer:

| Name       | Address prefix | Next hop type |
|------------|----------------|--------------|
| BLOCK_SUB  | 192.168.0.0/16 | None        |
| INT_0000   | 0.0.0.0/0      | Internet     |
| VNET_SUB   | 10.7.0.0/24     | Virtual network |
| VNET_SUB2  | 10.8.0.0/24     | Virtual network |

The BLOCK_SUB route is sending all the traffic for destination prefix 192.168.0.0/16 to a None next-hop type. The None next-hop type is used to configure a sinkhole for an IP address or destination prefix. All of the traffic for this destination prefix will be dropped. The Internet next-hop type is used to send traffic to the public internet while the Virtual Network next-hop type is used to route traffic to the corresponding virtual network (VNet) subnet.
The INT-0000 route is used to send all the destination prefix 0.0.0.0/0 traffic to the next-hop type Internet. You should not use 0.0.0.0/32 for the INT_0000 route; it is an incorrect prefix to configure a default route towards the public internet. Moreover, for the public internet-bound traffic, the next-hop type should be always set to Internet.
The VNET_SUB route is used to send all the destination prefix 10.7.0.0/24 traffic towards the internal virtual network (VNet). You should not use the next-hop address of Internet or None here. The Internet next-hop type is used to send traffic to the public Internet while the None next-hope type is used to drop the traffic
The VNET_SUB2 route is used to send all the destination prefix 10.8.0.0/24 traffic towards the internal VNet. You should not set the next-hop address to Internet or None here. The Internet next-hop type is used to send traffic to the public Internet while the None next-hope type is used to drop the traffic.

---

### References

[Virtual network traffic routing](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-udr-overview)   

---

## Q033:

You plan to use Azure NAT Gateway to provide a consistent public IP address space to internal Azure resources.
The NAT Gateway needs to be configured with a Public IP address and a subnet.
What is the maximum number of Public IP addresses that you can assign to Azure NAT Gateway?

Choose the correct answer

- 16
- 12
- 2
- 1

---

### Answer:
16 

You can assign a maximum of 16 Public IP addresses to Azure NAT Gateway. Azure NAT Gateway provides an option to Azure internal resources with private IP addresses to access the internet. NAT Gateway can also be used to hide the internal network topology, which helps to protect the internal virtual resources from the attacks originating from the public internet. You can also assign a Public IP prefix to the NAT gateway; all the IPs from the prefix will be used by the gateway for the outbound internet connection. NAT Gateway uses a mechanism called Port Address Translation (PAT) to translate the internal private IP address and port to the outbound Public IP address and port number.

---

### References

[Manage a public IP address with a NAT gateway](https://learn.microsoft.com/en-us/azure/virtual-network/ip-services/configure-public-ip-nat-gateway)  

---

## Q032:

You plan to configure your application on Azure, but you want to hide the internal network. You decide to use Azure NAT Gateway.
For better performance of the application, you decide to assign a public IP address prefix to cover six public IP addresses. You name the public IP prefix PUBLIC_NAT_PREFIX.

Which of the following public IP prefixes should you choose?

Choose the correct answer

/31
/29
/28
/30

---

### Answer:
/29

You should use the /29 prefix for the six public IPv4 addresses. A /29 prefix will give you a total of eight IP addresses from which you can use six IP addresses for your public IP addressing need. You can either configure a single IPv4 public IP address or a complete IPv4 network prefix (which will comprise a set of IPv4 addresses) and then bind it to the Network Address Translation (NAT) gateway. The following public IP prefix sizes are available:

/28 (IPv4) or /124 (IPv6) = Total 16 addresses
/29 (IPv4) or /125 (IPv6) = Total 8 addresses
/30 (IPv4) or /126 (IPv6) = Total 4 addresses
/31 (IPv4) or /127 (IPv6) = Total 2 addresses

NAT functionality provides an option for Azure resources to communicate with the public internet without exposing their internal IP addresses. This provides an additional layer of security. Public internet users only see the NAT Gateway IP(s) and are not capable of retrieving any information regarding the internal network.

---

### References

[Public IP address prefix](https://learn.microsoft.com/en-us/azure/virtual-network/ip-services/public-ip-address-prefix)  

[Azure NAT Gateway resource](https://learn.microsoft.com/en-us/azure/nat-gateway/nat-gateway-resource)  

---

## Q031:

Your company has two Azure virtual networks (VNets), named VNET-1 and VNET-2. A Windows10 virtual machine (VM) is configured in each VNet, as shown in the exhibit. The Windows10 machine in VNET-1 can RDP the Windows10 machine in VNET-2 using its public IP address. However, the Windows10 machine in VNET-1 cannot RDP to the Windows 10 machine in VNET-2 using its private IP address.
You need to enable the VM in VNET-1 to access the VM in VNET-2, so they can access each other using Azure private subnet IPs.
What solution should you configure?
Choose the correct answer
Private endpoints
VNet peering
Network security groups (NSGs)
Service endpoints

---

### Answer:

You should configure virtual network (VNet) peering to allow VNET-1 to VNET-2 private connectivity. In a VNet peering set-up, the traffic flows via the Microsoft backbone private network instead of using the public internet.
You should not configure Azure private endpoints. Azure private endpoints can be used to connect to Azure services via a private IP interface. The private endpoints cannot be used to peer two VNets. The virtual machine connects through a private endpoint to a private link resource, which can be any Azure resource, like, for example, Cosmos DB, Azure Database for PostgreSQL, and Azure Service Bus.
You should not configure Azure service endpoints. Azure Service endpoints are used to connect to Azure services via an optimized path. The service endpoints cannot be used to peer two VNets. The virtual machine will use the public IP of the Azure service to communicate to it and the service will see only the private IP of the virtual machine. The virtual machines or resources do not need a public IP address to communicate with Azure services via a service endpoint.

You should not configure network security groups (NSGs). NSGs are used to secure the virtual resources on Azure. NSGs are not used to peer two VNets. Instead, they are used to protect Azure resources by configuring inbound and outbound rules to filter the traffic. The NSG is a stateful firewall; any outbound connection by default allows the reverse traffic for that connection flow.

---

### References

[Virtual Network service endpoints](https://learn.microsoft.com/en-us/azure/vpn-gateway/point-to-site-about)  

[Choosing between Azure VNet Peering and VNet Gateways](https://azure.microsoft.com/en-us/blog/vnet-peering-and-vpn-gateways/)  

[Transport Layer Security protocol](https://learn.microsoft.com/en-us/windows-server/security/tls/transport-layer-security-protocol)   

[The HTTPS protocol explained! — Under the Hood](https://anushadasari.medium.com/the-https-protocol-explained-under-the-hood-c7bd9f9aaa7b)  

---

## Q030:

![image info](./Q30_1.PNG)

Your company has two Azure virtual networks (VNets), named VNET-1 and VNET-2. A Windows10 virtual machine (VM) is configured in each VNet, as shown in the exhibit. The Windows10 machine in VNET-1 can RDP the Windows10 machine in VNET-2 using its public IP address. However, the Windows10 machine in VNET-1 cannot RDP to the Windows 10 machine in VNET-2 using its private IP address.
You need to enable the VM in VNET-1 to access the VM in VNET-2, so they can access each other using Azure private subnet IPs.

What solution should you configure?

Choose the correct answer

- Private endpoints
- VNet peering
- Network security groups (NSGs)
- Service endpoints

---

### Answer:
- VNet peering

You should configure virtual network (VNet) peering to allow VNET-1 to VNET-2 private connectivity. In a VNet peering set-up, the traffic flows via the Microsoft backbone private network instead of using the public internet.
You should not configure Azure private endpoints. Azure private endpoints can be used to connect to Azure services via a private IP interface. The private endpoints cannot be used to peer two VNets. The virtual machine connects through a private endpoint to a private link resource, which can be any Azure resource, like, for example, Cosmos DB, Azure Database for PostgreSQL, and Azure Service Bus.
You should not configure Azure service endpoints. Azure Service endpoints are used to connect to Azure services via an optimized path. The service endpoints cannot be used to peer two VNets. The virtual machine will use the public IP of the Azure service to communicate to it and the service will see only the private IP of the virtual machine. The virtual machines or resources do not need a public IP address to communicate with Azure services via a service endpoint.
You should not configure network security groups (NSGs). NSGs are used to secure the virtual resources on Azure. NSGs are not used to peer two VNets. Instead, they are used to protect Azure resources by configuring inbound and outbound rules to filter the traffic. The NSG is a stateful firewall; any outbound connection by default allows the reverse traffic for that connection flow.

---

### References

[Virtual Network service endpoints](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview)  

[Network security groups](https://learn.microsoft.com/en-us/azure/virtual-network/network-security-groups-overview)  

[What is a private endpoint](https://learn.microsoft.com/en-us/azure/private-link/private-endpoint-overview) 

[Tutorial: Connect virtual networks with virtual network peering using the Azure portal](https://learn.microsoft.com/en-us/azure/virtual-network/tutorial-connect-virtual-networks-portal)   

---

## Q029:

You work at a company that has an Azure subscription. You create a DNS zone so that your company can host its DNS domain within Azure DNS.
You retrieve the name servers of your created DNS zone.
You need to delegate the DNS domain.
For each of the following statements, select Yes if the statement is true. Otherwise, select No.


You should use the Azure name servers to substitute the Name Server (NS) records.
Yes

You should query the Start of Authority (SOA) record using the nslookup tool.
No

You should establish a test virtual machine.
No

---

### Answer:

You should use the Azure name servers to substitute the NS records to delegate the DNS domain. Delegating your domain is a required action to do so that you can host your Domain Name System (DNS) domain within Azure DNS. DNS zones are used by companies to host records of their companies' domain names.
You should not query the SOA record using the nslookup tool. This is done to verify whether the delegation to your domain is successfully done. You can use the nslookup command within the command prompt so that you can query the SOA record for the DNS zone you have created.
You should not establish a test virtual machine. This action will not allow you to delegate your DNS domain but would enable you to test if your private DNS zone is working properly.

---

### References

[Tutorial: Host your domain in Azure DNS](https://learn.microsoft.com/en-us/azure/dns/dns-delegate-domain-azure-dns)  

[Quickstart: Create an Azure private DNS zone using the Azure portal](https://learn.microsoft.com/en-us/azure/dns/private-dns-getstarted-portal)  

---

## Q028:

You plan to configure a 10.1.0.0/24 subnet under your VNet, which is configured with an address space of 10.1.0.0/16 for your web application.
You should only use non-reserved IP addresses in your solution so it does not conflict with Azure resources.

You need to identify which addresses from this subnet are reserved and cannot be used.
Which three addresses should you identify? Each correct answer presents a complete solution.

Choose the correct answers

- 10.1.0.230
- 10.1.0.0
- 10.1.0.255
- 10.1.0.1 
- 10.1.0.251

---

### Answer:

- 10.1.0.0
- 10.1.0.255
- 10.1.0.1 


The following addresses will be reserved from the subnet (10.1.0.0/24):

- 10.1.0.0 Network Address
- 10.1.0.1 Default Gateway Address
- 10.1.0.255 Broadcast Address

These addresses will not be allocated by Azure Dynamic host configuration protocol (DHCP) to any Azure virtual machine. By default, Azure will reserve five addresses from each subnet.

A few other addresses that will be reserved from a subnet are: x.x.x.2, x.x.x.3: Reserved by Azure to map the Azure DNS IPs to the virtual network (VNet) space.

The following are valid addresses and can be assigned to Azure virtual resources:

- 10.1.0.251
- 10.1.0.230

---

### References

[Azure Virtual Network frequently asked questions (FAQ)](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-faq)    

---

## Q027:

You plan to configure two Azure virtual networks: VNet1 and Vnet2.

| Vnet | Address space | Subnet assigned |
|---|---|---|
| VNet1 | 10.1.0.0/16 | 10.1.1.0/24 |
| VNet2 | 10.1.0.0/16 | 10.1.2.0/24 |


VNet1 is the Front web tier and will receive the incoming connections from the internet. It has virtual machine VM1 configured as a web server.
VNet2 is the Backend tier and will receive all the database connections from the front end web server. It has virtual machine VM2 configured as a database server.

The following table shows the virtual machine details and their corresponding private IP addresses:


| Virtual machine | Function | IP Address |
|---|---|---|
| VM1 | Web Server | 10.1.1.10 |
| VM2 | Database Server | 10.1.2.10 |

Network security groups (NSGs) in each virtual network are configured with the default RDP (3389) rule and
assigned to each virtual machine network interface.
For each of the following statements, select Yes if the statement is true. Otherwise, select No.


You can configure virtual network peering between VNet1 and VNet2.
No

Virtual machines in VNet1 are able to ping virtual machines in VNet2.
No

On initial creation, the subnet in VNet1 will be assigned the Default (Azure-provided) DNS servers.
Yes

---

### Answer:

You cannot configure virtual network peering between VNet1 and VNet2. You cannot configure virtual network peering for overlapping Classless Inter-Domain Routing (CIDR) blocks. In this scenario, both VNet1 and VNet2 have an address space of 10.1.0.0/16. Therefore, they cannot peer with each other.
Virtual machines in VNet1 are not able to ping virtual machines in VNet2. Both virtual networks are isolated, and therefore the resources inside these networks are not able to communicate with each other.
On initial creation, the subnet in VNet1 will be assigned the Default (Azure-provided) DNS servers. When you create a subnet, Azure will assign a default DNS server to it. These default DNS servers can be changed with custom DNS servers later on.

---

### References

[Azure Virtual Network concepts and best practices](https://learn.microsoft.com/en-us/azure/virtual-network/concepts-and-best-practices)  

[Name resolution for resources in Azure virtual networks](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-name-resolution-for-vms-and-role-instances?tabs=redhat)  

[Virtual network peering](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-peering-overview)  

---

## Q026:

You plan to migrate your organization domain name companyA.com from a third party domain registrar to Azure.
You must create the parent domain name entry on the Azure portal under the Domain Name System (DNS) zones named companyA.com.
What further action should you take to complete the domain name migration?

Choose the correct answer

- Update the Start of Authority (SOA) record for the parent domain name under Azure DNS zone with the third party domain registrar SOA details.

- Update the SOA record for the third party domain registrar with Azure DNS zone Start of Authority (SOA record) for the parent record.

- Update the parent domain registrar DNS name servers under the Azure DNS zone.

- Update the parent domain registrar DNS settings with the Azure DNS name servers.

---

### Answer:
- Update the parent domain registrar DNS settings with the Azure DNS name servers.

You should update the parent domain registrar Domain Name System (DNS) settings with the Azure DNS name servers. When you create the parent domain name entry under the Azure DNS zone, the following four Name Servers (NS) are assigned by default to the zone:

- Name server 1 ns1-35.azure-dns.com.
- Name server 2 ns2-35.azure-dns.net.
- Name server 3 ns3-35.azure-dns.org.
- Name server 4 ns4-35.azure-dns.info.

You will need to copy these four NS records to the third party registrar to complete the domain name migration to the Azure DNS zone. NS records are used to configure the authoritative DNS server detail that contains the actual domain information. You will always see these NS servers in Azure Public DNS zones and they cannot be deleted or edited. Should you like, additional name servers can be added.
You should not update the parent domain registrar DNS name servers under the Azure DNS zone. The domain is supposed to be delegated to the Azure DNS; therefore, there is no need to perform this configuration.
You should not update the Start of Authority (SOA) record for the third party domain registrar with Azure DNS zone SOA record for the parent record. This step is not required and you are not advised to modify the SOA information under the DNS settings.
You should not update the SOA record for the parent domain name under Azure DNS zone with the third party domain registrar SOA details. This step is not required. The SOA record is automatically populated by Azure when the parent domain zone is created. The SOA record defines the main NS for the domain name.

---

### References

[Tutorial: Host your domain in Azure DNS](https://learn.microsoft.com/en-us/azure/dns/dns-delegate-domain-azure-dns)  

---

## Q023-Q025:

You are one of four Azure administrators in your organization. You have deployed a web app in West Europe and configured it as a backend pool in Azure Front Door. Your co-workers have created a Web Application Firewall (WAF) policy and applied it to Azure Front Door. The rules engine has also been modified.
Users of the web app have recently complained that they are being presented with the following error message: "The request is blocked".

You need to promptly resolve this issue. The solution must not compromise security.

---

## Q025:

Solution: Remove the WAF policy from Azure Front Door.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. You should not remove the WAF policy from Azure Front Door. Removing the WAF policy will restore traffic flow, but doing so will go against the compromising security requirement, as the web app will be exposed to security threats.

---

### References


[Policy settings for Web Application Firewall on Azure Front Door](https://learn.microsoft.com/en-us/azure/web-application-firewall/afds/waf-front-door-policy-settings)  

---

## Q024:

Solution: Verify that there are no conflicting rules in the WAF policy associated with Azure Front Door.

Does this solution meet the goal?

---

### Answer:
Yes

This solution meets the goal. You should verify that there are no conflicting rules in the WAF policy associated with Azure Front Door. Custom WAF rules take priority over Microsoft managed rules. Administrators can block incoming traffic to Azure Front Door using custom rules, based on conditions such as geolocation and IP address. If a blocked error message is presented, then it will be related to an Azure Front Door WAF policy.

---

### References

[Custom rules for Azure Web Application Firewall on Azure Front Door](https://learn.microsoft.com/en-us/azure/web-application-firewall/afds/waf-front-door-custom-rules)  


---

## Q023:

Solution: Verify that there are no conflicting rules in rules engine for Azure Front Door.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. You should not verify that there are no conflicting rules in the rules engine for Azure Front Door. Rules engine can be used to provide a more granular control on how HTTP traffic is handled by Azure Front Door. For example, if a user is browsing on a mobile device, then a rule can be configured to re-direct users to a mobile friendly site. Rules engine will not, however, present users with blocked messages.

---

### References

[What is a rule set in Azure Front Door?](https://learn.microsoft.com/en-us/azure/frontdoor/front-door-rules-engine?pivots=front-door-standard-premium)  

---

## Q020-Q022:

You are an Azure network administrator for a transport company. Azure Firewall has been deployed to filter traffic in a hub and spoke topology. The Azure Firewall rules are currently empty and require configuration.
Your colleague has requested external network connectivity for one of the application servers, which is in one of the spoke virtual networks (VNets).
You need to allow the application server to connect to www.company1.com using Azure Firewall and custom Domain Name System (DNS) servers.

---

## Q022:

Solution: create a DNAT (Destination Network Address Translation) rule collection AND THEN CREATE A dnat RULE.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. Destination Network Address Translation (DNAT) rules allow users to connect to private IP addresses behind Azure Firewall via the public interface (IP address). A common scenario for this type of rule is for Remote Desktop Protocol (RDP) connections to an Azure virtual machine from the internet. For instance, a business need could surface that requires a third party support provider to connect to one of your Azure virtual machines over the internet using RDP. This would be needed so that the third party support provider could efficiently support the application that is running on the virtual machine and to hit any agreed Service Level Agreements (SLAs). All the third party would require is the public IP address in order to connect via RDP to the virtual machine from their headquarters.

---

### References

[Azure Firewall Policy rule sets](https://learn.microsoft.com/en-us/azure/firewall/policy-rule-sets)
[Filter inbound Internet traffic with Azure Firewall DNAT using the Azure portal](https://learn.microsoft.com/en-us/azure/firewall/tutorial-firewall-dnat)  


---

## Q021:

Solution: Add an application and network rule collection, and then create an application network rule.

Does this solution meet the goal?

---

### Answer:
Yes

This solution meets the goal. An application rule alone will not meet the requirement of the request. DNS connectivity on port 53 is also required, which must be configured as a network rule. As a result, you need to configure both an application and a network rule. During the network rule creation, you must map port 53 to the custom DNS servers.

---

### References

[Configure Azure Firewall rules](https://learn.microsoft.com/en-us/azure/firewall/rule-processing)  

[Deploy and configure Azure Firewall using the Azure portal](https://learn.microsoft.com/en-us/azure/firewall/tutorial-firewall-deploy-portal)  


---

## Q020:

Solution: Create an application rule collection, and then create an application rule.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. An application rule is based on Layer 7 of the Network OSI model. This will allow administrators to add a fully qualified domain name (FQDN) in the rule. For connectivity to www.company1.com to work, DNS on port 53 is also required, in the form of a network rule.

---

### References

[Azure Firewall Policy rule sets](https://learn.microsoft.com/en-us/azure/firewall/policy-rule-sets)  



--- 

## Q017-Q019:

You work as an Azure administrator for a clothing company. You have two virtual machines configured with the below network settings. Network Security Groups (NSGs) have been assigned to the individual virtual machine Network Interface Cards (NICs) with the default rules.

| VM Name | VNET | Subnet | NSG |
|---|---|---|---|
| VM01 | VNET1 | SN1 | NSG1 |
| VM02 | VNET1 | SN2 | NSG2 |

Your colleague needs to connect to VMO2 from VM01 using Remote Desktop Protocol (RDP) to test an application. You need to ensure that RDP access from VM01 to VMO2 will work.
The solution must not include any unnecessary administrative effort.

---

### References

[Network security groups](https://learn.microsoft.com/en-us/azure/virtual-network/network-security-groups-overview) 

---

## Q019:

Solution: Do Nothing.

Does this solution meet the goal?

---

### Answer:
Yes


This solution meets the goal. You should do nothing. The Remote Desktop Protocol allows remote users to connect to another Microsoft Windows machine from another location. This can either be over the public internet or a local network. The AllowVNetInbound rule allows any traffic between virtual networks by default. This includes RDP connectivity between virtual machines.

---

### References

---

## Q018:

Solution: Create an inbound rule for port 3389 on NSG1 and NSG1.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. You should not create inbound and outgoing rules for port 3389 on both NSG1 and NSG2. The Remote Desktop Protocol allows remote users to connect to another Microsoft Windows machine from another location. This can either be over the public internet or a local network. NSGs consist of a rule labelled AllowVNetInBound. This rule allows all hosts inside the virtual network (including subnets) to communicate with each other.

---

## Q017:


Solution: Create an inbound rule for port 3389 on NSG2.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. You should not create an inbound rule for port 3389 on NSG2. The Remote Desktop Protocol allows remote users to connect to another Microsoft Windows machine from another location. This can either be over the public internet or a local network. An additional rule to explicitly allow RDP traffic is not required. This is due to the default Network Security Group (NSG) rules already permitting any traffic between virtual networks and virtual machines.

---

## Q014-Q016:

You work as an Azure administrator for a logistics company. You have an Azure subscription with the following resources:

| Resource Type | Resource Name | Azure Region |
|---|---|---|
| Virtual Network | Vnet1 | UK South |
| Virtual Machine | Vm1 | UK South |
| Storage Account | Storage1 | UK South |
| Storage Account | Storage2 | UK South |

You need to meet the following requirements:

- Vm1 needs to securely connect to Storage1 over the Azure backbone network.
- Resources in Vnet1 can only connect to Storage1 and no other storage accounts.

---

## Q016:


Solution: You deploy Azure Front Door and create a custom rules engine rule.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. You should not deploy Azure Front Door and create a custom rules engine rule. Azure Front Door is a global Layer 7 load-balancing service. Layer 7 refers to the Application layer of the Open Systems Interconnect model (OSI model). This can be useful if you have a number of virtual machines in different regions. Azure Front Door can be used to direct traffic (load balance) to the most appropriate virtual machine based on the source region of the end user. This ensures that the end user is always connecting to the closest virtual machine. Azure Front Door can be further customized by adding custom rules using the rules engine. This would not apply in this scenario as Azure Front Door is a service that is accessible from the internet. A rules engine rule can be used to redirect users to a mobile friendly website if the source device is a mobile.

---

### References

[What is Azure Front Door?](https://learn.microsoft.com/en-us/azure/frontdoor/front-door-overview)  



---

## Q015:

Solution: You deploy a service endpoint and service endpoint policy.

Does this solution meet the goal?

---

### Answer:
Yes

This solution meets the goal. You should deploy a service endpoint and service endpoint policy. A service endpoint allows you to directly connect a subnet to a public Azure service such as storage accounts. This means that the virtual machine does not require an outbound connection to the internet, which is often a security concern. The relevant virtual network and subnet can then be associated to the storage account under the networking blade. This ensures that the first requirement is met, as Vm1 securely connects to the storage account over the Azure backbone network without making outgoing public calls via the internet. The secondary requirement is met by creating a service endpoint policy. If you create a service endpoint policy you can ensure that data exfiltration is not possible. For instance, during the service endpoint policy creation, you would need to ensure that you explicitly state that only Storage1 is accessible over the service endpoint. Access to other storage accounts will be denied from the subnet.

---

### References

[Virtual Network service endpoints](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoints-overview)  

[Virtual network service endpoint policies for Azure Storage](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoint-policies-overview)  

[Create, change, or delete service endpoint policy using the Azure portal](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-service-endpoint-policies-portal)  

---

## Q014:

Solution: You deploy a private endpoint and Private Link service.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. You should not deploy a private endpoint and Private Link service. A private endpoint allows you to completely isolate an Azure Platform as a Service (PaaS) service, such as a web app, so that it can only be contacted by an internal Azure resource. A private endpoint also allows traffic from on-premises networks to securely connect to the resource without traversing via the internet. This answer is not applicable for this scenario as the requirement does not state that private access from an on-premises network or virtual network is necessary. The scenario states that Vm1 needs to connect to Storage1 over the Azure backbone network only. For this reason, a private endpoint and private link service is an incorrect solution.

---

### References

[What is a private endpoint?](https://learn.microsoft.com/en-us/azure/private-link/private-endpoint-overview)  

---

## Q010-013:

You are the Azure administrator in your organization. A virtual network (VNet) with three subnets has been deployed with three virtual machines. A Site-to-Site VPN tunnel was also configured to connect Azure to the on-premises data center.
You have received reports of latency issues between on-premises clients and the Azure virtual machines. You run Network Watcher VPN diagnostics.

You need to analyze the ingress and egress bytes for the VPN connection.

---

## Q013:

Solution: You configure and analyze Network Security Group Flow Logs.
Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. You should not configure and analyze Network Security Group (NSG) Flow Logs. Network Security Group flow logs is an optional feature that comes bundled with Network Watcher. These logs will allow you to analyze network traffic that passes through a Network Security Group. This diagnostic test does not apply to the requirement as it specifically requests ingress and egress bytes for the VPN tunnel. This specifically relates to all data that passes through a given Network Security Group. Analyzing the ingress and egress data can be useful to verify whether data is actually reaching the Network Security Group in the first place.

---

### References

[Configuring Network Security Group Flow logs with PowerShell](https://learn.microsoft.com/en-us/azure/network-watcher/nsg-flow-logs-powershell)  

---

## Q012:

Solution: From Network Watcher, inspect the Connectiontats.txt file.
Does this solution meet the goal?

---

### Answer:
Yes

This solution meets the goal. From Network Watcher, you should inspect the 'ConnectionStats.txt' file. When you troubleshoot VPN connectivity, this file will contain statistics for the connection, which includes ingress and egress byte data.

---

### References


[Introduction to resource troubleshooting in Azure Network Watcher](https://learn.microsoft.com/en-us/azure/network-watcher/vpn-troubleshoot-overview)  

---

## Q011:

Solution: From Network Watcher, inspect the CPUStats.txt file.
Does this solution meet the goal?

---

### Answer:
No

---

### References

[Introduction to resource troubleshooting in Azure Network Watcher](https://learn.microsoft.com/en-us/azure/network-watcher/vpn-troubleshoot-overview)  

---

## Q010:

Solution: From Network Watcher, inspect the IKEErrors.txt file.
Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. From Network Watcher, you should not inspect the 'IKEErrors.txt' file. This file will only report issues and errors relating to the Internet Key Exchange (IKE) component of the VPN tunnel. The IKE process allows VPN peers at both ends to successfully encrypt and decrypt network packets traveling over the VPN tunnel, using a mutually agreed pre-shared key or certificate. This process consists of two phases: phase 1 and phase 2. Each phase uses encryption algorithms and keys. The IKEErrors.txt file will list any issues encountered during either phase initiation.

---

### References

[Introduction to resource troubleshooting in Azure Network Watcher](https://learn.microsoft.com/en-us/azure/network-watcher/vpn-troubleshoot-overview)  

---

## Q007-009:


![image info](./Q7_1.PNG)

Your company has the Azure environment shown in the Network Architecture exhibit.
The North US Windows user and the North US IOS user can only access VnetA.
You need to implement a solution that enables both users to access VnetB.

---

### References

[What is Azure Network Watcher?](https://learn.microsoft.com/en-us/azure/network-watcher/network-watcher-overview)  

[About BGP and VPN Gateway](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-bgp-overview)  

[How to configure BGP for Azure VPN Gateway](https://learn.microsoft.com/en-us/azure/vpn-gateway/bgp-howto)  

[About Point-to-Site VPN routing](https://learn.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-point-to-site-routing)  

---

## Q009:

Solution: re-download the VPN client configuration fpr the North US Windows user and the North US IOS user.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. Downloading the VPN client configuration for users should only be done if the topology of a network is modified so that the changes of the topology can be implemented again to the client.

---

## Q008:

Solution: You use BGP on the gateway of VnetA.

Does this solution meet the goal?

---

### Answer:
Yes

This solution meets the goal. The Border Gateway Protocol (BGP) is the routing protocol for exchanging routing and reachability information between networks. When this protocol is used within VNets, it enables your Virtual Private Network (VPN) devices to exchange routes with your VPN gateways. BGP will tell the VPN gateways that the prefixes of the VPN devices are allowed to go through them.

---

## Q007:

Solution: Configure Azure Network Watcher

Does this solution meet the goal?

---

### Answer:
No

The solution does not meet the goal. Azure Network Watcher service enables you to monitor conditions at a network level in and from Azure. Configuring Azure Network Watcher will not allow both users to access VnetB.

---

### References

---

## Q004-006:


Your company has a virtual network VNet1 configured as shown in the exhibit with an address space of 10.1.0.0/16.
There are three subnets inside this virtual network:

• 10.1.1.0/24
• 10.1.2.0/24
• 10.1.3.0/24

The following resources are configured under these subnets:

| Virtual Machine | IP Address |
|-----------------|------------|
| VM1 | 10.1.1.9 |
| Proxy-VM | 10.1.2.9 |
| Backend Database | 10.1.3.9 |


No custom route table is attached to any of the subnets.
The VM1 is the front end server, where all the initial requests will be received from the public Internet users. The backend database is only reachable via the Proxy-VM.
VM1 wants to reach the backend database, but all the requests should proxy through the Proxy-VM configured in the subnet 10.1.2.0/24.

---

### References

[Network security groups](https://learn.microsoft.com/en-us/azure/virtual-network/network-security-groups-overview)  

[Virtual network traffic routing](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-networks-udr-overview)  

---

## Q006:

Solution: In order to relay all the traffic from VM1 via Proxy-VM, you enable the IP forwarding on the Proxy- VM virtual machine Virtual Network Interface under the IP configuration. You also configure a custom route table and attach it to the VM1 subnet. The route table is configured to route all the traffic to IP address 10.1.2.9/32 as the next hop address and the route type set to virtual appliance.

Does this solution meet the goal?

---

### Answer:
Yes

This solution meets the goal. You should enable the IP forwarding on the Proxy-VM virtual machine Virtual Network Interface under the IP configuration. You should also configure a custom route table and attach it to VM1 subnet. The route table should be configured to route all the traffic to IP address 10.1.2.9/32 as the next hop address and route type set to virtual appliance. With this set-up in place, all the traffic from VM1 will be routed to Proxy-VM, which will be then forwarded to the next hop as per the IP packet destination IP address


---

## Q005:

Solution: In order to relay all the traffic from VM1 via Proxy-VM, you create a Network Security Group (NSG), which allows the traffic from VM1 subnet to the Backend Database subnet.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. Simply creating a Network Security Group (NSG) to allow traffic from VM1 subnet to the Backend Database subnet will not help in relaying the traffic via the Proxy-VM. The NSG is used to configure different security rules for the inbound and the outbound traffic, and you can associate a subnet or a network interface to it.

---

## Q004:

Solution: In order to relay all the traffic from VM1 via Proxy-VM, you enable IP Forwarding on the Backend database virtual machine, Virtual Network Interface.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. Simply enabling the IP forwarding on the Backend Database virtual machine Virtual Network Interface will not force the VM1 to send all its traffic to Proxy-VM.

---

## Q001-003:

![image info](./Q1_1.PNG)
![image info](./Q1_2.PNG)
![image info](./Q1_3.PNG)


You have a private DNS Zone named az700.practice.com. You have two VNets, each running a Windows 10 virtual machine:

• Windows10 in Vnet1
• Windows10-2 in Vnet2

Each virtual machine only has private IP addresses. Refer to exhibits 1, 2, 3 and the table below for current
set-up details.

![image info](./Q1_0.PNG)

You discover that Windows10 in VNet1 cannot communicate with Windows10-2 in VNet2 using domain names.

You need to ensure that both virtual machines can communicate with each other using their corresponding private domain names.

---

### References

[Virtual network peering](https://learn.microsoft.com/en-us/azure/virtual-network/virtual-network-peering-overview)  

---


## Q003:

Solution: You create two virtual network links with the private DNS Zone for VNet1 and VNet2 with auto registration set to Enabled. Additionally, you assign a public IP address to each virtual machine network interface.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. Just creating two virtual network links with the private DNS Zone for VNet1 and VNet2 with auto registration set to Enabled will not enable communication between the two virtual machines. Moreover, assigning public IP addresses to each virtual machine network interfaces will not help to enable communication between the virtual machines by using their private domain names. The public IP may help in accessing the virtual machine via the public internet, but it will not help in the private domain name resolution and reachability between the two virtual machines.

---

## Q002:

Solution: You create two virtual network links with the private DNS Zone for VNet1 and VNet2. Additionally, you also configure peering between VNet1 and VNet2.

Does this solution meet the goal?

---

### Answer:
Yes

This solution meets the goal. In order to enable inter-VNet communication, you need to configure virtual network peering between VNet1 and VNet2. The virtual network links with the private DNS Zone for VNet1 and VNet2 will enable hostname registration with the private zone. Once the virtual machine is created, the private IP will be automatically registered against the hostname in the private zone. To ensure actual connectivity between the virtual machines in different VNets, you need to configure peering between them.

---

## Q001:

Solution: 
You create two virtual network links with the private DNS Zone for VNet1 and VNet2 with auto registration set to Enabled.

Does this solution meet the goal?

---

### Answer:
No

This solution does not meet the goal. Just creating two virtual network links with the private DNS Zone for VNet1 and VNet2 with auto registration set to Enabled will not enable the communication between the two virtual machines. With this configuration, the hostname of the virtual machine will be automatically added to the private DNS Zone if the VM is spin up inside VNet1 or VNet2.

---